{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e13195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /gpfs/commons/home/kisaev/Leaflet-analysis/Human_Splicing_Foundation/metadata\n",
      "Processing date: 2025-09-20\n",
      "=== STARTING METADATA PROCESSING PIPELINE ===\n",
      "\n",
      "=== FILE VALIDATION ===\n",
      "‚úÖ Allen Brain file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data//ab_adata_exons_2025-09-20.h5ad\n",
      "‚úÖ Tabula Sapiens file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data//tabsap_adata_2025-09-20.h5ad\n",
      "\n",
      "=== LOADING ANNDATA OBJECTS ===\n",
      "‚è≥ Loading Allen Brain data...\n",
      "\n",
      "=== VALIDATING ALLEN BRAIN ADATA ===\n",
      "Shape: (49417, 50281)\n",
      "Obs columns: ['sample_name', 'specimen_type', 'cluster_color', 'cluster_order', 'cluster_label', 'class_color', 'class_order', 'class_label', 'subclass_color', 'subclass_order', 'subclass_label', 'full_genotype_color', 'full_genotype_order', 'full_genotype_label', 'donor_sex_color', 'donor_sex_order', 'donor_sex_label', 'region_color', 'region_order', 'region_label', 'cortical_layer_color', 'cortical_layer_order', 'cortical_layer_label', 'cell_type_accession_color', 'cell_type_accession_order', 'cell_type_accession_label', 'cell_type_alias_color', 'cell_type_order', 'cell_type_alias_label', 'cell_type_alt_alias_color', 'cell_type_alt_alias_order', 'cell_type_alt_alias_label', 'cell_type_designation_color', 'cell_type_designation_order', 'cell_type_designation_label', 'external_donor_name_color', 'external_donor_name_order', 'external_donor_name_label', 'outlier_call', 'outlier_type']\n",
      "Var columns: ['gene_symbol']\n",
      "‚ùå Missing required obs columns: ['dataset']\n",
      "‚è≥ Loading Tabula Sapiens data...\n",
      "\n",
      "=== VALIDATING TABULA SAPIENS ADATA ===\n",
      "Shape: (41501, 59412)\n",
      "Obs columns: ['donor', 'tissue', 'anatomical_position', 'method', 'cdna_plate', 'library_plate', 'notes', 'cdna_well', 'old_index', 'assay', 'sample_id', 'replicate', '10X_run', '10X_barcode', 'ambient_removal', 'donor_method', 'donor_assay', 'donor_tissue', 'donor_tissue_assay', 'cell_ontology_class', 'cell_ontology_id', 'compartment', 'broad_cell_class', 'free_annotation', 'manually_annotated', 'published_2022', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ercc', 'pct_counts_ercc', '_scvi_batch', '_scvi_labels', 'scvi_leiden_donorassay_full', 'age', 'sex', 'ethnicity', 'scvi_leiden_res05_tissue', 'sample_number', 'dataset']\n",
      "Var columns: ['ensembl_id', 'gene_symbol', 'genome', 'mt', 'ercc', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'mean', 'std', 'gene_name']\n",
      "‚úÖ Tabula Sapiens AnnData structure validated\n",
      "\n",
      "=== PROCESSING ALLEN BRAIN METADATA ===\n",
      "\n",
      "=== EXTRACTING ALLEN_BRAIN METADATA ===\n",
      "‚ö†Ô∏è  Missing values in allen_brain:\n",
      "  cell_type_designation_label: 1985 missing (4.0%)\n",
      "  cell_type_alias_label: 1985 missing (4.0%)\n",
      "  subclass_label: 1985 missing (4.0%)\n",
      "  class_label: 1985 missing (4.0%)\n",
      "‚úÖ Extracted 49417 records from allen_brain\n",
      "\n",
      "--- Allen Brain Donor Validation ---\n",
      "Donors found: ['H200.1030', 'H200.1023', 'H200.1025']\n",
      "Cells per donor:\n",
      "external_donor_name_label\n",
      "H200.1030    19575\n",
      "H200.1023    18518\n",
      "H200.1025    11324\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Adding Age Information ---\n",
      "‚úÖ Set age 54 for 19,575 cells from donor H200.1030\n",
      "‚úÖ Set age 43 for 18,518 cells from donor H200.1023\n",
      "‚úÖ Set age 50 for 11,324 cells from donor H200.1025\n",
      "Total cells with age assigned: 49,417 / 49,417\n",
      "Age distribution:\n",
      "age\n",
      "43    18518\n",
      "50    11324\n",
      "54    19575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== PROCESSING TABULA SAPIENS METADATA ===\n",
      "\n",
      "=== EXTRACTING TABULA_SAPIENS METADATA ===\n",
      "‚úÖ Extracted 41501 records from tabula_sapiens\n",
      "\n",
      "--- Validating Tabula Sapiens Cell ID Generation ---\n",
      "Sample old_index format: 'TSP14_smartseq2_B134547_B20_D101532_B20_LI_proximal_Epithelial'\n",
      "‚úÖ Cell ID generation successful\n",
      "Sample generated cell IDs:\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_B20_D101532_B20_LI_proximal_Epithelial\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_L10_D101532_L10_LI_proximal_Epithelial\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_G16_D101532_G16_LI_proximal_Epithelial\n",
      "\n",
      "=== VALIDATING TABULA SAPIENS CELL IDS ===\n",
      "‚úÖ All 41501 cell IDs are valid and unique\n",
      "\n",
      "=== STANDARDIZING METADATA FORMATS ===\n",
      "--- Pre-standardization shapes ---\n",
      "Tabula Sapiens: (41501, 15)\n",
      "Allen Brain: (49417, 11)\n",
      "‚úÖ Converted categorical columns to strings: ['donor', 'sex', 'tissue', 'cell_type']\n",
      "‚úÖ Converted categorical columns to strings: ['donor', 'sex', 'tissue', 'cell_type']\n",
      "‚úÖ Metadata standardization complete\n",
      "\n",
      "=== COMBINING AND CLEANING METADATA ===\n",
      "\n",
      "=== VALIDATING METADATA CONSISTENCY ===\n",
      "Comparing Tabula Sapiens vs Allen Brain\n",
      "Common columns: 7\n",
      "sex values across datasets: ['F', 'M', 'female', 'male']\n",
      "dataset values across datasets: ['allen_brain', 'tabula_sapiens']\n",
      "‚úÖ Combined metadata shape: (90918, 7)\n",
      "--- Post-combination validation ---\n",
      "Dataset distribution:\n",
      "dataset\n",
      "allen_brain       49417\n",
      "tabula_sapiens    41501\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Cleaning Sex Column ---\n",
      "Sex values before cleaning:\n",
      "sex\n",
      "M         30899\n",
      "female    24355\n",
      "F         18518\n",
      "male      17146\n",
      "Name: count, dtype: int64\n",
      "Sex values after cleaning:\n",
      "sex\n",
      "M    48045\n",
      "F    42873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== CELL TYPE MAPPING ===\n",
      "--- Cell Type Mapping Validation ---\n",
      "‚úÖ Cell type mapping created: 211 mappings\n",
      "‚ö†Ô∏è  3934 cells with unmapped cell types\n",
      "Top unmapped cell types:\n",
      "cell_type\n",
      "nan                                                     1985\n",
      "basal cell                                              1523\n",
      "kidney epithelial cell                                   154\n",
      "lung ciliated cell                                       130\n",
      "Endothelial                                               70\n",
      "unciliated epithelium                                     47\n",
      "colon macrophage                                          18\n",
      "transit amplifying cell of small intestine                 4\n",
      "naive thymus-derived cd8-positive, alpha-beta t cell       3\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Used original cell_type for unmapped cells\n",
      "\n",
      "--- Broad Cell Type Distribution ---\n",
      "Number of broad cell types: 60\n",
      "Top 10 broad cell types:\n",
      "broad_cell_type\n",
      "Excitatory_Neuron     31229\n",
      "Inhibitory_Neuron     11125\n",
      "General_Fibroblast     4223\n",
      "CNS_Glia               3902\n",
      "CD4_T_cell             3289\n",
      "Granulocyte            2639\n",
      "B_cell                 2630\n",
      "Monocyte               2563\n",
      "Macrophage             2432\n",
      "CD8_T_cell             2397\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SHARED CELL TYPE ANALYSIS ===\n",
      "Finding cell types with ‚â•50 cells per dataset...\n",
      "‚úÖ Shared broad cell types (‚â•50 per dataset): 1\n",
      "Shared cell types: ['Microglia']\n",
      "\n",
      "--- Detailed Shared Cell Type Analysis ---\n",
      "Cell counts for shared types:\n",
      "dataset          allen_brain  tabula_sapiens\n",
      "broad_cell_type                             \n",
      "Microglia                750              56\n",
      "\n",
      "Shared cell type summary:\n",
      "  Total cells: 90,918\n",
      "  Cells in shared types: 806\n",
      "  Percentage in shared types: 0.9%\n",
      "\n",
      "Excluded cell types (59):\n",
      "  Alveolar_cell: AB=0, TS=866\n",
      "  Arterial_Endothelial: AB=0, TS=176\n",
      "  B_cell: AB=0, TS=2630\n",
      "  CD4_T_cell: AB=0, TS=3289\n",
      "  CD8_T_cell: AB=0, TS=2397\n",
      "  CNS_Glia: AB=3890, TS=12\n",
      "  Capillary_Endothelial: AB=0, TS=864\n",
      "  Cardiac_Muscle: AB=0, TS=49\n",
      "  Dendritic_cell: AB=0, TS=194\n",
      "  Endothelial: AB=70, TS=0\n",
      "  ... and 49 more\n",
      "\n",
      "=== SAVING METADATA ===\n",
      "--- Pre-save Validation ---\n",
      "Final metadata shape: (90918, 8)\n",
      "Columns: ['cell_id', 'donor', 'sex', 'age', 'dataset', 'tissue', 'cell_type', 'broad_cell_type']\n",
      "‚úÖ No missing values in 'cell_id'\n",
      "‚úÖ No missing values in 'dataset'\n",
      "‚úÖ No missing values in 'broad_cell_type'\n",
      "‚úÖ All 90,918 cell IDs are unique\n",
      "‚úÖ Metadata saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\n",
      "File size: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import scipy.sparse as sp\n",
    "from pathlib import Path\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)\n",
    "\n",
    "# Configuration\n",
    "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Processing date: {today}\")\n",
    "\n",
    "# %%\n",
    "def validate_file_exists(filepath, description=\"\"):\n",
    "    \"\"\"Validate that a file exists and is readable.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"‚ùå {description} file not found: {filepath}\")\n",
    "    if not os.access(filepath, os.R_OK):\n",
    "        raise PermissionError(f\"‚ùå {description} file not readable: {filepath}\")\n",
    "    print(f\"‚úÖ {description} file found: {filepath}\")\n",
    "    return True\n",
    "\n",
    "def validate_adata_structure(adata, dataset_name):\n",
    "    \"\"\"Validate AnnData object structure and content.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING {dataset_name.upper()} ADATA ===\")\n",
    "    \n",
    "    print(f\"Shape: {adata.shape}\")\n",
    "    print(f\"Obs columns: {list(adata.obs.columns)}\")\n",
    "    print(f\"Var columns: {list(adata.var.columns)}\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_obs = ['dataset']\n",
    "    missing_obs = [col for col in required_obs if col not in adata.obs.columns]\n",
    "    \n",
    "    if missing_obs:\n",
    "        print(f\"‚ùå Missing required obs columns: {missing_obs}\")\n",
    "        return False\n",
    "    \n",
    "    # Check data integrity\n",
    "    if adata.obs.index.duplicated().any():\n",
    "        dup_count = adata.obs.index.duplicated().sum()\n",
    "        print(f\"‚ùå {dup_count} duplicate cell indices found!\")\n",
    "        return False\n",
    "    \n",
    "    if adata.var.index.duplicated().any():\n",
    "        dup_count = adata.var.index.duplicated().sum()\n",
    "        print(f\"‚ùå {dup_count} duplicate gene indices found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"‚úÖ {dataset_name} AnnData structure validated\")\n",
    "    return True\n",
    "\n",
    "def extract_metadata_with_validation(adata, dataset_name, required_columns):\n",
    "    \"\"\"Extract metadata from AnnData with validation.\"\"\"\n",
    "    print(f\"\\n=== EXTRACTING {dataset_name.upper()} METADATA ===\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    missing_cols = [col for col in required_columns if col not in adata.obs.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ùå Missing columns in {dataset_name}: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(adata.obs.columns)}\")\n",
    "        raise ValueError(f\"Required columns missing from {dataset_name}\")\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = adata.obs[required_columns].reset_index(drop=True)\n",
    "    metadata[\"dataset\"] = dataset_name\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_counts = metadata.isnull().sum()\n",
    "    if missing_counts.any():\n",
    "        print(f\"‚ö†Ô∏è  Missing values in {dataset_name}:\")\n",
    "        for col, count in missing_counts[missing_counts > 0].items():\n",
    "            print(f\"  {col}: {count} missing ({count/len(metadata)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"‚úÖ Extracted {len(metadata)} records from {dataset_name}\")\n",
    "    return metadata\n",
    "\n",
    "def validate_cell_id_format(metadata, dataset_name, cell_id_col=\"cell_id\"):\n",
    "    \"\"\"Validate cell ID format and uniqueness.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING {dataset_name.upper()} CELL IDS ===\")\n",
    "    \n",
    "    if cell_id_col not in metadata.columns:\n",
    "        print(f\"‚ùå Cell ID column '{cell_id_col}' not found!\")\n",
    "        return False\n",
    "    \n",
    "    cell_ids = metadata[cell_id_col]\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = cell_ids.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"‚ùå {duplicates} duplicate cell IDs found!\")\n",
    "        # Show examples\n",
    "        dup_examples = cell_ids[cell_ids.duplicated()].head(3).tolist()\n",
    "        print(f\"Examples: {dup_examples}\")\n",
    "        return False\n",
    "    \n",
    "    # Check for missing/null IDs\n",
    "    missing = cell_ids.isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"‚ùå {missing} missing cell IDs found!\")\n",
    "        return False\n",
    "    \n",
    "    # Check for empty strings\n",
    "    empty = (cell_ids == \"\").sum()\n",
    "    if empty > 0:\n",
    "        print(f\"‚ùå {empty} empty cell IDs found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"‚úÖ All {len(cell_ids)} cell IDs are valid and unique\")\n",
    "    return True\n",
    "\n",
    "def convert_categoricals_to_strings(df):\n",
    "    \"\"\"Convert categorical columns to strings for consistency.\"\"\"\n",
    "    converted_cols = []\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, CategoricalDtype):\n",
    "            df[col] = df[col].astype(str)\n",
    "            converted_cols.append(col)\n",
    "    \n",
    "    if converted_cols:\n",
    "        print(f\"‚úÖ Converted categorical columns to strings: {converted_cols}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_metadata_consistency(metadata1, metadata2, dataset1_name, dataset2_name):\n",
    "    \"\"\"Validate consistency between two metadata datasets.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING METADATA CONSISTENCY ===\")\n",
    "    print(f\"Comparing {dataset1_name} vs {dataset2_name}\")\n",
    "    \n",
    "    # Check column consistency\n",
    "    cols1, cols2 = set(metadata1.columns), set(metadata2.columns)\n",
    "    common_cols = cols1.intersection(cols2)\n",
    "    unique_to_1 = cols1 - cols2\n",
    "    unique_to_2 = cols2 - cols1\n",
    "    \n",
    "    print(f\"Common columns: {len(common_cols)}\")\n",
    "    if unique_to_1:\n",
    "        print(f\"Unique to {dataset1_name}: {unique_to_1}\")\n",
    "    if unique_to_2:\n",
    "        print(f\"Unique to {dataset2_name}: {unique_to_2}\")\n",
    "    \n",
    "    # Check value consistency for common categorical columns\n",
    "    categorical_cols = ['sex', 'dataset']\n",
    "    for col in categorical_cols:\n",
    "        if col in common_cols:\n",
    "            vals1 = set(metadata1[col].unique())\n",
    "            vals2 = set(metadata2[col].unique())\n",
    "            all_vals = vals1.union(vals2)\n",
    "            print(f\"{col} values across datasets: {sorted(all_vals)}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "print(\"=== STARTING METADATA PROCESSING PIPELINE ===\")\n",
    "\n",
    "# File paths\n",
    "outdir = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data/\"\n",
    "ab_file = f\"{outdir}/ab_adata_exons_2025-09-20.h5ad\"\n",
    "ts_file = f\"{outdir}/tabsap_adata_2025-09-20.h5ad\"\n",
    "\n",
    "# Validate input files\n",
    "print(\"\\n=== FILE VALIDATION ===\")\n",
    "validate_file_exists(ab_file, \"Allen Brain\")\n",
    "validate_file_exists(ts_file, \"Tabula Sapiens\")\n",
    "\n",
    "# Load data with validation\n",
    "print(\"\\n=== LOADING ANNDATA OBJECTS ===\")\n",
    "print(\"‚è≥ Loading Allen Brain data...\")\n",
    "ab_exons = sc.read_h5ad(ab_file)\n",
    "validate_adata_structure(ab_exons, \"Allen Brain\")\n",
    "\n",
    "print(\"‚è≥ Loading Tabula Sapiens data...\")\n",
    "ts_adata = sc.read_h5ad(ts_file)\n",
    "validate_adata_structure(ts_adata, \"Tabula Sapiens\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== PROCESSING ALLEN BRAIN METADATA ===\")\n",
    "\n",
    "# Define required columns for Allen Brain\n",
    "ab_required_cols = [\n",
    "    \"sample_name\", \"cell_type_designation_label\", \"cell_type_alias_label\", \n",
    "    \"specimen_type\", \"subclass_label\", \"donor_sex_label\", \n",
    "    \"external_donor_name_label\", \"class_label\", \"region_label\"\n",
    "]\n",
    "\n",
    "# Extract Allen Brain metadata\n",
    "ab_metadata = extract_metadata_with_validation(ab_exons, \"allen_brain\", ab_required_cols)\n",
    "\n",
    "# SANITY CHECK 1: Validate donor information\n",
    "print(\"\\n--- Allen Brain Donor Validation ---\")\n",
    "donor_counts = ab_metadata[\"external_donor_name_label\"].value_counts()\n",
    "print(f\"Donors found: {list(donor_counts.index)}\")\n",
    "print(f\"Cells per donor:\\n{donor_counts}\")\n",
    "\n",
    "# Add age information with validation\n",
    "print(\"\\n--- Adding Age Information ---\")\n",
    "\n",
    "# adding age manuall for donors using https://pmc.ncbi.nlm.nih.gov/articles/PMC6919571/table/T1/\n",
    "age_mapping = {\n",
    "    \"H200.1030\": 54,  # Caucasian\n",
    "    \"H200.1023\": 43,  # Iranian descent  \n",
    "    \"H200.1025\": 50   # Caucasian\n",
    "}\n",
    "\n",
    "ab_metadata[\"age\"] = 0\n",
    "cells_with_age = 0\n",
    "\n",
    "for donor, age in age_mapping.items():\n",
    "    donor_mask = ab_metadata[\"external_donor_name_label\"] == donor\n",
    "    donor_count = donor_mask.sum()\n",
    "    if donor_count > 0:\n",
    "        ab_metadata.loc[donor_mask, \"age\"] = age\n",
    "        cells_with_age += donor_count\n",
    "        print(f\"‚úÖ Set age {age} for {donor_count:,} cells from donor {donor}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No cells found for donor {donor}\")\n",
    "\n",
    "print(f\"Total cells with age assigned: {cells_with_age:,} / {len(ab_metadata):,}\")\n",
    "\n",
    "# SANITY CHECK 2: Validate age assignment\n",
    "age_dist = ab_metadata[\"age\"].value_counts().sort_index()\n",
    "print(f\"Age distribution:\\n{age_dist}\")\n",
    "\n",
    "if (ab_metadata[\"age\"] == 0).any():\n",
    "    cells_without_age = (ab_metadata[\"age\"] == 0).sum()\n",
    "    print(f\"‚ö†Ô∏è  {cells_without_age} cells still have age = 0\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== PROCESSING TABULA SAPIENS METADATA ===\")\n",
    "\n",
    "# Define required columns for Tabula Sapiens\n",
    "ts_required_cols = [\n",
    "    \"old_index\", \"sample_id\", \"donor\", \"tissue\", \"cell_ontology_class\", \n",
    "    \"compartment\", \"broad_cell_class\", \"age\", \"sex\", \"dataset\", \"free_annotation\"\n",
    "]\n",
    "\n",
    "# Extract Tabula Sapiens metadata\n",
    "ts_metadata = extract_metadata_with_validation(ts_adata, \"tabula_sapiens\", ts_required_cols)\n",
    "\n",
    "# SANITY CHECK 3: Validate old_index format for cell ID generation\n",
    "print(\"\\n--- Validating Tabula Sapiens Cell ID Generation ---\")\n",
    "sample_old_index = ts_metadata[\"old_index\"].iloc[0]\n",
    "print(f\"Sample old_index format: '{sample_old_index}'\")\n",
    "\n",
    "# Parse old_index components\n",
    "ts_metadata[\"project_id\"] = ts_metadata[\"sample_id\"].str.extract(r'^(TSP\\d+)')\n",
    "parts = ts_metadata[\"old_index\"].str.split(\"_\")\n",
    "\n",
    "# Check if splitting worked correctly\n",
    "if len(parts.iloc[0]) < 8:\n",
    "    print(f\"‚ùå ERROR: old_index format unexpected. Expected 8+ parts, got {len(parts.iloc[0])}\")\n",
    "    print(f\"Sample parts: {parts.iloc[0]}\")\n",
    "    raise ValueError(\"old_index parsing failed\")\n",
    "\n",
    "# Generate cell ID components with validation\n",
    "try:\n",
    "    ts_metadata[\"junc_prefix_core\"] = (\n",
    "        parts.str[0] + \"_\" +  # TSP1\n",
    "        parts.str[1] + \"_\" +  # smartseq2\n",
    "        parts.str[2] + \"_\" +  # NA\n",
    "        parts.str[4] + \"_\" +  # B107921\n",
    "        parts.str[6] + \"_\" +  # Muscle\n",
    "        parts.str[7]          # NA\n",
    "    )\n",
    "    \n",
    "    ts_metadata[\"cell_id_prefix\"] = (\n",
    "        ts_metadata[\"project_id\"] + \"_\" +\n",
    "        ts_metadata[\"junc_prefix_core\"] +\n",
    "        \".multi_star.output_raw.output_raw_per_\"\n",
    "    )\n",
    "    \n",
    "    ts_metadata[\"cell_id\"] = ts_metadata[\"cell_id_prefix\"] + ts_metadata[\"old_index\"]\n",
    "    \n",
    "    print(\"‚úÖ Cell ID generation successful\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"Sample generated cell IDs:\")\n",
    "    for i in range(min(3, len(ts_metadata))):\n",
    "        print(f\"  {ts_metadata['cell_id'].iloc[i]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR in cell ID generation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Validate generated cell IDs\n",
    "validate_cell_id_format(ts_metadata, \"Tabula Sapiens\", \"cell_id\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== STANDARDIZING METADATA FORMATS ===\")\n",
    "\n",
    "# Create working copies\n",
    "ts_meta = ts_metadata.copy()\n",
    "ab_meta = ab_metadata.copy()\n",
    "\n",
    "# SANITY CHECK 4: Pre-standardization validation\n",
    "print(\"--- Pre-standardization shapes ---\")\n",
    "print(f\"Tabula Sapiens: {ts_meta.shape}\")\n",
    "print(f\"Allen Brain: {ab_meta.shape}\")\n",
    "\n",
    "# Rename columns to match target structure\n",
    "ts_meta = ts_meta.rename(columns={\n",
    "    \"donor\": \"donor\",\n",
    "    \"sex\": \"sex\", \n",
    "    \"free_annotation\": \"cell_type\",\n",
    "})\n",
    "\n",
    "ab_meta = ab_meta.rename(columns={\n",
    "    \"sample_name\": \"cell_id\",\n",
    "    \"external_donor_name_label\": \"donor\",\n",
    "    \"donor_sex_label\": \"sex\",\n",
    "    \"region_label\": \"tissue\",\n",
    "    \"subclass_label\": \"cell_type\"\n",
    "})\n",
    "\n",
    "# Define final column structure\n",
    "final_columns = [\"cell_id\", \"donor\", \"sex\", \"age\", \"dataset\", \"tissue\", \"cell_type\"]\n",
    "\n",
    "# SANITY CHECK 5: Check for missing final columns\n",
    "for dataset_name, df in [(\"Tabula Sapiens\", ts_meta), (\"Allen Brain\", ab_meta)]:\n",
    "    missing_cols = [col for col in final_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ùå Missing final columns in {dataset_name}: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        raise ValueError(f\"Column standardization failed for {dataset_name}\")\n",
    "\n",
    "# Select and reorder columns\n",
    "ts_meta = ts_meta[final_columns].reset_index(drop=True)\n",
    "ab_meta = ab_meta[final_columns].reset_index(drop=True)\n",
    "\n",
    "# Convert categoricals to strings\n",
    "ts_meta = convert_categoricals_to_strings(ts_meta)\n",
    "ab_meta = convert_categoricals_to_strings(ab_meta)\n",
    "\n",
    "print(\"‚úÖ Metadata standardization complete\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== COMBINING AND CLEANING METADATA ===\")\n",
    "\n",
    "# Validate consistency before combining\n",
    "validate_metadata_consistency(ts_meta, ab_meta, \"Tabula Sapiens\", \"Allen Brain\")\n",
    "\n",
    "# Combine metadata\n",
    "combined_metadata = pd.concat([ts_meta, ab_meta], ignore_index=True)\n",
    "print(f\"‚úÖ Combined metadata shape: {combined_metadata.shape}\")\n",
    "\n",
    "# SANITY CHECK 6: Post-combination validation\n",
    "print(\"--- Post-combination validation ---\")\n",
    "dataset_counts = combined_metadata[\"dataset\"].value_counts()\n",
    "print(f\"Dataset distribution:\\n{dataset_counts}\")\n",
    "\n",
    "expected_total = len(ts_meta) + len(ab_meta)\n",
    "if len(combined_metadata) != expected_total:\n",
    "    print(f\"‚ùå ERROR: Expected {expected_total} rows, got {len(combined_metadata)}\")\n",
    "    raise ValueError(\"Row count mismatch after combination\")\n",
    "\n",
    "# Clean sex column with validation\n",
    "print(\"\\n--- Cleaning Sex Column ---\")\n",
    "sex_before = combined_metadata[\"sex\"].value_counts()\n",
    "print(f\"Sex values before cleaning:\\n{sex_before}\")\n",
    "\n",
    "combined_metadata[\"sex\"] = combined_metadata[\"sex\"].astype(str)\n",
    "combined_metadata.loc[combined_metadata[\"sex\"] == \"male\", \"sex\"] = \"M\"\n",
    "combined_metadata.loc[combined_metadata[\"sex\"] == \"female\", \"sex\"] = \"F\"\n",
    "\n",
    "sex_after = combined_metadata[\"sex\"].value_counts()\n",
    "print(f\"Sex values after cleaning:\\n{sex_after}\")\n",
    "\n",
    "# Check for unexpected sex values\n",
    "unexpected_sex = combined_metadata[~combined_metadata[\"sex\"].isin([\"M\", \"F\"])]\n",
    "if len(unexpected_sex) > 0:\n",
    "    print(f\"‚ö†Ô∏è  {len(unexpected_sex)} cells with unexpected sex values:\")\n",
    "    print(unexpected_sex[\"sex\"].value_counts())\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== CELL TYPE MAPPING ===\")\n",
    "\n",
    "# Define refined cell type mapping\n",
    "grouped_refined_map = {\n",
    "    # === NEURONS - Split by major functional classes ===\n",
    "    'Excitatory_Neuron': [\n",
    "        'IT', 'L4 IT', 'L5 ET', 'L6 CT', 'L6b', 'L5/6 IT Car3', 'L5/6 NP'\n",
    "    ],\n",
    "    'Inhibitory_Neuron': [\n",
    "        'VIP', 'PVALB', 'SST', 'LAMP5'\n",
    "    ],\n",
    "    'Other_Neuron': [\n",
    "        'PAX6', 'retinal bipolar neuron'\n",
    "    ],\n",
    "    \n",
    "    # === T CELLS - Organized by major functional subsets ===\n",
    "    'CD4_T_cell': [\n",
    "        'cd4-positive, alpha-beta t cell', 'cd4-positive helper t cell', \n",
    "        'cd4-positive, alpha-beta memory t cell', 'naive thymus-derived cd4-positive, alpha-beta t cell',\n",
    "        'activated cd4-positive, alpha-beta t cell', 'cd4-positive, alpha-beta thymocyte',\n",
    "        'cd4-positive memory t cell', 't follicular helper cell'\n",
    "    ],\n",
    "    'CD8_T_cell': [\n",
    "        'cd8-positive, alpha-beta t cell', 'cd8-positive, alpha-beta memory t cell',\n",
    "        'cd8-positive, alpha-beta thymocyte', 'naive cd8-positive t cell',\n",
    "        'activated cd8-positive, alpha-beta t cell', 'cd8-positive cytotoxic t cell',\n",
    "        'cd8+, alpha-beta cytokine secreting effector t cell'\n",
    "    ],\n",
    "    'Regulatory_T_cell': [\n",
    "        'regulatory t cell', 'naive regulatory t cell'\n",
    "    ],\n",
    "    'Other_T_cell': [\n",
    "        't cell', 'gamma-delta t cell', 'thymocyte'\n",
    "    ],\n",
    "    \n",
    "    # === B CELLS ===\n",
    "    'B_cell': [\n",
    "        'b cell', 'memory b cell', 'naive b cell'\n",
    "    ],\n",
    "    'Plasma_cell': [\n",
    "        'plasma cell', 'antibody secreting cell'\n",
    "    ],\n",
    "    \n",
    "    # === MYELOID CELLS - Split by major lineages ===\n",
    "    'Microglia': [\n",
    "        'Microglia', 'microglial cell', 'retina - microglia'\n",
    "    ],\n",
    "    'Macrophage': [\n",
    "        'macrophage', 'Monocyte_Macrophage', 'tissue-resident macrophage', \n",
    "        'muscle macrophage'\n",
    "    ],\n",
    "    'Monocyte': [\n",
    "        'monocyte', 'classical monocyte', 'non-classical monocyte', 'intermediate monocyte'\n",
    "    ],\n",
    "    'Dendritic_cell': [\n",
    "        'dendritic cell', 'myeloid dendritic cell', 'plasmacytoid dendritic cell',\n",
    "        'cd1c-positive myeloid dendritic cell', 'cd141-positive myeloid dendritic cell',\n",
    "        'cdc1', 'cdc2', 'conventional dendritic cell'\n",
    "    ],\n",
    "    'Granulocyte': [\n",
    "        'neutrophil', 'cd24 neutrophil', 'nampt neutrophil', 'granulocyte',\n",
    "        'basophil', 'mast cell'\n",
    "    ],\n",
    "    \n",
    "    # === NK/ILC ===\n",
    "    'NK_ILC': [\n",
    "        'nk cell', 'natural killer cell', 'nk t cell', 'innate lymphoid cell', \n",
    "        'mature nk t cell', 'type i nk t cell', 'uterine nk cell', \n",
    "        'proliferating nk cell', 'immature natural killer cell'\n",
    "    ],\n",
    "    \n",
    "    # === EPITHELIAL - Split by organ system ===\n",
    "    'Respiratory_Epithelial': [\n",
    "        'club cell', 'ionocyte', 'goblet cell', 'ciliated epithelial cell',\n",
    "        'pulmonary ionocyte', 'serous cell of epithelium of bronchus',\n",
    "        'respiratory goblet cell', 'ciliated columnar cell of tracheobronchial tree',\n",
    "        'tracheal goblet cell'\n",
    "    ],\n",
    "    'GI_Epithelial': [\n",
    "        'enterocyte of epithelium of large intestine', \n",
    "        'enterocyte of epithelium proper of small intestine',\n",
    "        'large intestine goblet cell', 'best4+ intestinal epithelial cell',\n",
    "        'small intestine goblet cell', 'enterocyte of epithelium proper of ileum',\n",
    "        'enterocyte of epithelium proper of duodenum', \n",
    "        'paneth cell of epithelium of small intestine', 'paneth cell of colon',\n",
    "        'mature enterocyte', 'intestinal tuft cell', 'tuft cell of colon'\n",
    "    ],\n",
    "    'Urogenital_Epithelial': [\n",
    "        'bladder urothelial cell', 'basal bladder urothelial cell', \n",
    "        'intermediate bladder urothelial cell', 'epithelial cell of uterus'\n",
    "    ],\n",
    "    'Mammary_Epithelial': [\n",
    "        'HR positive luminal epithelial cell of mammary gland',\n",
    "        'secretory luminal epithelial cell of mammary gland',\n",
    "        'luminal epithelial cell'\n",
    "    ],\n",
    "    'Other_Epithelial': [\n",
    "        'epithelial cell', 'duct epithelial cell', 'ltf+ epithelial cell',\n",
    "        'basal epithelial cell', 'salivary gland cell', 'medullary thymic epithelial cell',\n",
    "        'conjunctival epithelial cell', 'corneal epithelial cell', 'glandular epithelial cell',\n",
    "        'cycling epithelial cell', 'mucus secreting cell', 'biliary epithelial cell',\n",
    "        'pancreatic ductal cell', 'stratified squamous epithelial cell', 'sebum secreting cell'\n",
    "    ],\n",
    "    \n",
    "    # === ENDOTHELIAL - Split by vessel type ===\n",
    "    'Arterial_Endothelial': [\n",
    "        'arterial endothelial cell', 'endothelial cell of arteriole', 'endothelial cell of artery'\n",
    "    ],\n",
    "    'Venous_Endothelial': [\n",
    "        'vein endothelial cell', 'venous capillary endothelial cell', 'endothelial cell of venule'\n",
    "    ],\n",
    "    'Capillary_Endothelial': [\n",
    "        'capillary endothelial cell', 'blood vessel endothelial cell'\n",
    "    ],\n",
    "    'Lymphatic_Endothelial': [\n",
    "        'endothelial cell of lymphatic vessel'\n",
    "    ],\n",
    "    'Specialized_Endothelial': [\n",
    "        'endothelial cell', 'endothelial cell of vascular tree', 'cardiac endothelial cell',\n",
    "        'colon endothelial cell', 'retinal blood vessel endothelial cell', 'vascular endothelial cell'\n",
    "    ],\n",
    "    \n",
    "    # === GLIA - Split by CNS vs PNS ===\n",
    "    'CNS_Glia': [\n",
    "        'Astrocyte', 'OPC', 'Oligodendrocyte', 'retina - muller glia', 'mueller cell'\n",
    "    ],\n",
    "    'PNS_Glia': [\n",
    "        'enteroglial cell', 'schwann cell'\n",
    "    ],\n",
    "    'Glia_Other': [\n",
    "        'glial cell'\n",
    "    ],\n",
    "    \n",
    "    # === MUSCLE - Split by muscle type ===\n",
    "    'Smooth_Muscle': [\n",
    "        'smooth muscle cell', 'airway smooth muscle cell', 'vascular associated smooth muscle cell'\n",
    "    ],\n",
    "    'Cardiac_Muscle': [\n",
    "        'atrial cardiac muscle cell', 'ventricular cardiac muscle cell'\n",
    "    ],\n",
    "    'Skeletal_Muscle': [\n",
    "        'skeletal muscle satellite stem cell', 'fast muscle cell', 'slow muscle cell',\n",
    "        'tongue muscle cell'\n",
    "    ],\n",
    "    'Muscle_Other': [\n",
    "        'muscle cell', 'tendon cell'\n",
    "    ],\n",
    "    \n",
    "    # === STROMAL/FIBROBLAST - More specific organ groupings ===\n",
    "    'General_Fibroblast': [\n",
    "        'fibroblast', 'stromal cell', 'myofibroblast cell', 'adventitial fibroblast',\n",
    "        'cd34+ fibroblasts', 'VLMC', 'adventitial cell', 'connective tissue cell'\n",
    "    ],\n",
    "    'Organ_Specific_Fibroblast': [\n",
    "        'alveolar fibroblast', 'fibroblast of breast', 'fibroblast of cardiac tissue',\n",
    "        'uterine fibroblast', 'stellate_fibroblast', 'endometrial stromal fibroblast'\n",
    "    ],\n",
    "    'Specialized_Stromal': [\n",
    "        'fat cell', 'cornea - mesenchymal cell - stromal keratinocytes',\n",
    "        'limbal stromal cell', 'follicle', 'granulosa cell', 'mesothelial cell', 'theca cell'\n",
    "    ],\n",
    "    \n",
    "    # === LIVER - Split by major cell types ===\n",
    "    'Hepatocyte': [\n",
    "        'hepatocyte'\n",
    "    ],\n",
    "    'Liver_Non_Parenchymal': [\n",
    "        'hepatic stellate cell', 'intrahepatic cholangiocyte'\n",
    "    ],\n",
    "    \n",
    "    # === SPECIALIZED CELLS ===\n",
    "    'Pericyte': [\n",
    "        'pericyte', 'Pericyte', 'myofibroblast cell and pericyte', 'mural cell'\n",
    "    ],\n",
    "    \n",
    "    'Photoreceptor': [\n",
    "        'retinal pigment epithelial cell', 'retina - photoreceptor cell', 'eye photoreceptor cell'\n",
    "    ],\n",
    "    \n",
    "    'Alveolar_cell': [\n",
    "        'type ii pneumocyte', 'type i pneumocyte', 'capillary aerocyte'\n",
    "    ],\n",
    "    \n",
    "    'Enteroendocrine': [\n",
    "        'enteroendocrine cell of small intestine', 'type l enteroendocrine cell',\n",
    "        'enterochromaffin-like cell'\n",
    "    ],\n",
    "    \n",
    "    'Hematopoietic_Mature': [\n",
    "        'platelet', 'erythrocyte'\n",
    "    ],\n",
    "    \n",
    "    'Hematopoietic_Progenitor': [\n",
    "        'erythroid progenitor cell', 'hematopoietic stem cell', 'myeloid progenitor',\n",
    "        'common myeloid progenitor'\n",
    "    ],\n",
    "    \n",
    "    'Mesenchymal_Stem': [\n",
    "        'mesenchymal stem cell', 'mesenchymal stem cell of adipose tissue'\n",
    "    ],\n",
    "    \n",
    "    'Stem_Progenitor_Other': [\n",
    "        'oocyte', 'radial glia progenitor cell', 'intestinal crypt stem cell of small intestine',\n",
    "        'intestinal crypt stem cell of large intestine'\n",
    "    ],\n",
    "    \n",
    "    'Secretory_Gland': [\n",
    "        'acinar cell of salivary gland', 'lacrimal gland functional unit cell', 'myoepithelial cell'\n",
    "    ],\n",
    "    \n",
    "    'Pigment_cell': [\n",
    "        'melanocyte', 'melanocyte or limbal stem cell'\n",
    "    ],\n",
    "    \n",
    "    'Sensory_cell': [\n",
    "        'taste receptor cell'\n",
    "    ],\n",
    "    \n",
    "    'Skin_cell': [\n",
    "        'keratocyte'\n",
    "    ],\n",
    "    \n",
    "    'Myeloid_Other': [\n",
    "        'myeloid cell', 'mononuclear phagocyte'\n",
    "    ],\n",
    "    \n",
    "    'Immune_Other': [\n",
    "        'leukocyte', 'langerhans cell', 'immune cell'\n",
    "    ],\n",
    "    \n",
    "    'Unknown': [\n",
    "        'unknown'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# SANITY CHECK 7: Validate cell type mapping\n",
    "print(\"--- Cell Type Mapping Validation ---\")\n",
    "\n",
    "# Flatten the mapping\n",
    "def flatten_grouped_map(grouped_map):\n",
    "    flattened = {}\n",
    "    for broad_type, labels in grouped_map.items():\n",
    "        for label in labels:\n",
    "            if label in flattened:\n",
    "                print(f\"‚ö†Ô∏è  WARNING: '{label}' appears in multiple categories: {flattened[label]} and {broad_type}\")\n",
    "            flattened[label] = broad_type\n",
    "    return flattened\n",
    "\n",
    "grouped_broad_map_flat = flatten_grouped_map(grouped_refined_map)\n",
    "print(f\"‚úÖ Cell type mapping created: {len(grouped_broad_map_flat)} mappings\")\n",
    "\n",
    "# Apply mapping\n",
    "combined_metadata['broad_cell_type'] = (\n",
    "    combined_metadata['cell_type']\n",
    "    .map(grouped_broad_map_flat)\n",
    "    .fillna('Other')\n",
    ")\n",
    "\n",
    "# Handle unmapped cell types\n",
    "unmapped_mask = combined_metadata[\"broad_cell_type\"] == \"Other\"\n",
    "unmapped_count = unmapped_mask.sum()\n",
    "\n",
    "if unmapped_count > 0:\n",
    "    print(f\"‚ö†Ô∏è  {unmapped_count} cells with unmapped cell types\")\n",
    "    unmapped_types = combined_metadata[unmapped_mask][\"cell_type\"].value_counts()\n",
    "    print(f\"Top unmapped cell types:\\n{unmapped_types.head(10)}\")\n",
    "    \n",
    "    # Use original cell_type for unmapped\n",
    "    combined_metadata.loc[unmapped_mask, \"broad_cell_type\"] = combined_metadata.loc[unmapped_mask, \"cell_type\"]\n",
    "    print(\"‚úÖ Used original cell_type for unmapped cells\")\n",
    "\n",
    "# SANITY CHECK 8: Analyze broad cell type distribution\n",
    "print(\"\\n--- Broad Cell Type Distribution ---\")\n",
    "broad_type_counts = combined_metadata[\"broad_cell_type\"].value_counts()\n",
    "print(f\"Number of broad cell types: {len(broad_type_counts)}\")\n",
    "print(f\"Top 10 broad cell types:\\n{broad_type_counts.head(10)}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== SHARED CELL TYPE ANALYSIS ===\")\n",
    "\n",
    "# Determine shared cell types with at least 50 cells per dataset\n",
    "min_cells_per_dataset = 50\n",
    "\n",
    "print(f\"Finding cell types with ‚â•{min_cells_per_dataset} cells per dataset...\")\n",
    "\n",
    "broad_counts = (\n",
    "    combined_metadata.groupby([\"dataset\", \"broad_cell_type\"])\n",
    "    .size().reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "pivot_counts = broad_counts.pivot(\n",
    "    index=\"broad_cell_type\", \n",
    "    columns=\"dataset\", \n",
    "    values=\"count\"\n",
    ").fillna(0)\n",
    "\n",
    "# Find shared cell types meeting threshold\n",
    "shared_mask = (pivot_counts >= min_cells_per_dataset).all(axis=1)\n",
    "shared_broad_cell_types = pivot_counts[shared_mask].index.tolist()\n",
    "\n",
    "print(f\"‚úÖ Shared broad cell types (‚â•{min_cells_per_dataset} per dataset): {len(shared_broad_cell_types)}\")\n",
    "print(f\"Shared cell types: {shared_broad_cell_types}\")\n",
    "\n",
    "# SANITY CHECK 9: Detailed shared cell type analysis\n",
    "print(\"\\n--- Detailed Shared Cell Type Analysis ---\")\n",
    "print(\"Cell counts for shared types:\")\n",
    "shared_counts_df = pivot_counts.loc[shared_broad_cell_types].round(0).astype(int)\n",
    "print(shared_counts_df)\n",
    "\n",
    "# Calculate total cells in shared types\n",
    "total_shared_cells = combined_metadata[\n",
    "    combined_metadata[\"broad_cell_type\"].isin(shared_broad_cell_types)\n",
    "].shape[0]\n",
    "total_cells = len(combined_metadata)\n",
    "shared_percentage = (total_shared_cells / total_cells) * 100\n",
    "\n",
    "print(f\"\\nShared cell type summary:\")\n",
    "print(f\"  Total cells: {total_cells:,}\")\n",
    "print(f\"  Cells in shared types: {total_shared_cells:,}\")\n",
    "print(f\"  Percentage in shared types: {shared_percentage:.1f}%\")\n",
    "\n",
    "# Show cells excluded from shared analysis\n",
    "excluded_types = pivot_counts[~shared_mask]\n",
    "if len(excluded_types) > 0:\n",
    "    print(f\"\\nExcluded cell types ({len(excluded_types)}):\")\n",
    "    for cell_type in excluded_types.index[:10]:  # Show first 10\n",
    "        ab_count = excluded_types.loc[cell_type, \"allen_brain\"]\n",
    "        ts_count = excluded_types.loc[cell_type, \"tabula_sapiens\"] \n",
    "        print(f\"  {cell_type}: AB={ab_count:.0f}, TS={ts_count:.0f}\")\n",
    "    if len(excluded_types) > 10:\n",
    "        print(f\"  ... and {len(excluded_types) - 10} more\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== SAVING METADATA ===\")\n",
    "\n",
    "# Output path\n",
    "output_path = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\"\n",
    "\n",
    "# Create output directory if needed\n",
    "output_dir = os.path.dirname(output_path)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# SANITY CHECK 10: Pre-save validation\n",
    "print(\"--- Pre-save Validation ---\")\n",
    "print(f\"Final metadata shape: {combined_metadata.shape}\")\n",
    "print(f\"Columns: {list(combined_metadata.columns)}\")\n",
    "\n",
    "# Check for missing values in critical columns\n",
    "critical_cols = [\"cell_id\", \"dataset\", \"broad_cell_type\"]\n",
    "for col in critical_cols:\n",
    "    missing = combined_metadata[col].isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"‚ùå {missing} missing values in critical column '{col}'\")\n",
    "    else:\n",
    "        print(f\"‚úÖ No missing values in '{col}'\")\n",
    "\n",
    "# Check for duplicate cell IDs\n",
    "total_cell_ids = len(combined_metadata)\n",
    "unique_cell_ids = combined_metadata[\"cell_id\"].nunique()\n",
    "if total_cell_ids != unique_cell_ids:\n",
    "    duplicates = total_cell_ids - unique_cell_ids\n",
    "    print(f\"‚ùå {duplicates} duplicate cell IDs found!\")\n",
    "    \n",
    "    # Show duplicate examples\n",
    "    dup_ids = combined_metadata[combined_metadata[\"cell_id\"].duplicated()][\"cell_id\"].head(3)\n",
    "    print(f\"Example duplicates: {dup_ids.tolist()}\")\n",
    "else:\n",
    "    print(f\"‚úÖ All {total_cell_ids:,} cell IDs are unique\")\n",
    "\n",
    "# Save metadata\n",
    "try:\n",
    "    combined_metadata.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "    file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
    "    print(f\"‚úÖ Metadata saved to: {output_path}\")\n",
    "    print(f\"File size: {file_size:.1f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving metadata: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de94b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FILTERING JUNCTION FILES ===\n",
      "--- Junction File Validation ---\n",
      "‚úÖ Allen Brain junction list file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_20250920.txt\n",
      "‚úÖ Tabula Sapiens junction list file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_20250920.txt\n",
      "Valid cell IDs for filtering: 90,918\n",
      "\n",
      "--- Filtering Allen Brain Junction Files ---\n",
      "Total junction files in list: 50,625\n",
      "Junction filtering results for Allen Brain:\n",
      "  Original files: 50,625\n",
      "  Files with metadata: 49,356\n",
      "  Files excluded: 1,269\n",
      "  Retention rate: 97.5%\n",
      "  Example excluded cell IDs: ['F1S4_170302_092_B01', 'F1S4_160831_074_H01', 'F2S4_170405_052_C01']\n",
      "‚úÖ Filtered Allen Brain list saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\n",
      "‚úÖ Verification passed: 49356 lines saved correctly\n",
      "\n",
      "--- Filtering Tabula Sapiens Junction Files ---\n",
      "Total junction files in list: 93,994\n",
      "Junction filtering results for Tabula Sapiens:\n",
      "  Original files: 93,994\n",
      "  Files with metadata: 39,229\n",
      "  Files excluded: 54,765\n",
      "  Retention rate: 41.7%\n",
      "  Example excluded cell IDs: ['TSP3_TSP3_smartseq2_B114669_B133703_Eye_noCornea.multi_star.output_raw.output_raw_per_TSP3_smartseq2_B114669_G3_B133703_G3_Eye_noCornea_Epithelial', 'TSP14_TSP14_smartseq2_B134540_B002625_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134540_L9_B002625_L9_LI_proximal_Immune', 'TSP14_TSP14_smartseq2_B134101_D102110_Salivary_Sublingual.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134101_K21_D102110_K21_Salivary_Sublingual_Stromal']\n",
      "‚úÖ Filtered Tabula Sapiens list saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\n",
      "‚úÖ Verification passed: 39229 lines saved correctly\n",
      "\n",
      "=== POST-PROCESSING VERIFICATION ===\n",
      "--- Metadata Verification ---\n",
      "‚úÖ Metadata file readable: (90918, 8)\n",
      "‚úÖ Shape matches original\n",
      "‚úÖ Columns match original\n",
      "‚úÖ All cell IDs unique in saved file\n",
      "\n",
      "=== FINAL PROCESSING SUMMARY ===\n",
      "üéâ METADATA PROCESSING PIPELINE COMPLETE!\n",
      "üìÖ Processing date: 2025-09-20\n",
      "\n",
      "üìä DATASET SUMMARY:\n",
      "               cell_id   donor broad_cell_type age    \n",
      "                 count nunique         nunique min max\n",
      "dataset                                               \n",
      "allen_brain      49417       3               9  43  54\n",
      "tabula_sapiens   41501      17              56  22  74\n",
      "\n",
      "üî¨ CELL TYPE SUMMARY:\n",
      "Total broad cell types: 60\n",
      "Shared cell types (‚â•50 cells/dataset): 1\n",
      "Cells in shared types: 806 (0.9%)\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "‚úÖ Combined metadata: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\n",
      "‚úÖ Allen Brain junction list: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\n",
      "‚úÖ Tabula Sapiens junction list: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\n",
      "\n",
      "üìà JUNCTION FILTERING SUMMARY:\n",
      "allen_brain:\n",
      "  Original: 50,625\n",
      "  Retained: 49,356\n",
      "  Retention rate: 97.5%\n",
      "tabula_sapiens:\n",
      "  Original: 93,994\n",
      "  Retained: 39,229\n",
      "  Retention rate: 41.7%\n",
      "\n",
      "üéØ NEXT STEPS:\n",
      "1. Use filtered junction files for Leaflet and ATSEmapper pipeline\n",
      "2. Filter expression data to shared cell types for cross-dataset analysis\n",
      "3. Validate junction file existence before running downstream analysis\n",
      "\n",
      "‚úÖ ALL PROCESSING COMPLETE WITH COMPREHENSIVE VALIDATION!\n",
      "================================================================================\n",
      "\n",
      "=== FINAL METADATA SAMPLE ===\n",
      "First 5 rows:\n",
      "                                             cell_id  donor sex  age  \\\n",
      "0  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "1  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "2  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "3  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "4  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "\n",
      "          dataset           tissue  \\\n",
      "0  tabula_sapiens  Large_Intestine   \n",
      "1  tabula_sapiens  Large_Intestine   \n",
      "2  tabula_sapiens  Large_Intestine   \n",
      "3  tabula_sapiens  Large_Intestine   \n",
      "4  tabula_sapiens  Large_Intestine   \n",
      "\n",
      "                                     cell_type broad_cell_type  \n",
      "0  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "1  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "2  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "3                         paneth cell of colon   GI_Epithelial  \n",
      "4  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "\n",
      "Final metadata statistics:\n",
      "Shape: (90918, 8)\n",
      "Memory usage: 46.6 MB\n",
      "\n",
      "Data types:\n",
      "  cell_id: object (90,918 unique values)\n",
      "  donor: object (20 unique values)\n",
      "  sex: object (2 unique values)\n",
      "  age: int64 (18 unique values)\n",
      "  dataset: object (2 unique values)\n",
      "  tissue: object (33 unique values)\n",
      "  cell_type: object (219 unique values)\n",
      "  broad_cell_type: object (60 unique values)\n",
      "\n",
      "Sample values for key columns:\n",
      "  dataset: {'allen_brain': 49417, 'tabula_sapiens': 41501}\n",
      "  sex: {'M': 48045, 'F': 42873}\n",
      "  tissue: {'MTG': 16155, 'V1C': 8052, 'A1C': 6703}\n",
      "  broad_cell_type: {'Excitatory_Neuron': 31229, 'Inhibitory_Neuron': 11125, 'General_Fibroblast': 4223}\n",
      "\n",
      "üìã Processing complete - all data validated and ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"\\n=== FILTERING JUNCTION FILES ===\")\n",
    "\n",
    "# Junction file paths\n",
    "ab_junc_filelist = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_20250920.txt\"\n",
    "ts_junc_filelist = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_20250920.txt\"\n",
    "\n",
    "# Output paths\n",
    "clean_ts = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\"\n",
    "clean_ab = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\"\n",
    "\n",
    "# Validate junction file lists exist\n",
    "print(\"--- Junction File Validation ---\")\n",
    "for filepath, desc in [(ab_junc_filelist, \"Allen Brain\"), (ts_junc_filelist, \"Tabula Sapiens\")]:\n",
    "    try:\n",
    "        validate_file_exists(filepath, f\"{desc} junction list\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  {desc} junction list not found, skipping junction filtering\")\n",
    "        continue\n",
    "\n",
    "# Get valid cell IDs from metadata\n",
    "valid_cell_ids = set(combined_metadata[\"cell_id\"])\n",
    "print(f\"Valid cell IDs for filtering: {len(valid_cell_ids):,}\")\n",
    "\n",
    "def filter_junction_paths(filelist_path, output_path, valid_ids, dataset_name):\n",
    "    \"\"\"Filter junction file paths to only include cells with metadata.\"\"\"\n",
    "    print(f\"\\n--- Filtering {dataset_name} Junction Files ---\")\n",
    "    \n",
    "    if not os.path.exists(filelist_path):\n",
    "        print(f\"‚ö†Ô∏è  {dataset_name} junction list not found: {filelist_path}\")\n",
    "        return\n",
    "    \n",
    "    # Read junction file list\n",
    "    with open(filelist_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    print(f\"Total junction files in list: {len(lines):,}\")\n",
    "    \n",
    "    # Function to extract cell ID from file path\n",
    "    def extract_cell_id_from_path(path):\n",
    "        fname = Path(path).name\n",
    "        return fname.replace(\"_junctions_with_barcodes.bed\", \"\")\n",
    "    \n",
    "    # Filter paths and track statistics\n",
    "    filtered_lines = []\n",
    "    missing_metadata = []\n",
    "    \n",
    "    for path in lines:\n",
    "        cell_id = extract_cell_id_from_path(path)\n",
    "        if cell_id in valid_ids:\n",
    "            filtered_lines.append(path)\n",
    "        else:\n",
    "            missing_metadata.append(cell_id)\n",
    "    \n",
    "    # SANITY CHECK 11: Junction filtering validation\n",
    "    print(f\"Junction filtering results for {dataset_name}:\")\n",
    "    print(f\"  Original files: {len(lines):,}\")\n",
    "    print(f\"  Files with metadata: {len(filtered_lines):,}\")\n",
    "    print(f\"  Files excluded: {len(missing_metadata):,}\")\n",
    "    print(f\"  Retention rate: {len(filtered_lines)/len(lines)*100:.1f}%\")\n",
    "    \n",
    "    if len(missing_metadata) > 0:\n",
    "        print(f\"  Example excluded cell IDs: {missing_metadata[:3]}\")\n",
    "    \n",
    "    # Save filtered list\n",
    "    try:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(filtered_lines))\n",
    "        print(f\"‚úÖ Filtered {dataset_name} list saved to: {output_path}\")\n",
    "        \n",
    "        # Verify saved file\n",
    "        with open(output_path) as f:\n",
    "            saved_lines = f.read().splitlines()\n",
    "        \n",
    "        if len(saved_lines) != len(filtered_lines):\n",
    "            print(f\"‚ùå ERROR: Saved file has {len(saved_lines)} lines, expected {len(filtered_lines)}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Verification passed: {len(saved_lines)} lines saved correctly\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving filtered {dataset_name} list: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return {\n",
    "        'original_count': len(lines),\n",
    "        'filtered_count': len(filtered_lines),\n",
    "        'excluded_count': len(missing_metadata),\n",
    "        'retention_rate': len(filtered_lines)/len(lines) if len(lines) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Filter both junction file lists\n",
    "filtering_results = {}\n",
    "\n",
    "# Filter Allen Brain junctions\n",
    "if os.path.exists(ab_junc_filelist):\n",
    "    filtering_results['allen_brain'] = filter_junction_paths(\n",
    "        ab_junc_filelist, clean_ab, valid_cell_ids, \"Allen Brain\"\n",
    "    )\n",
    "\n",
    "# Filter Tabula Sapiens junctions  \n",
    "if os.path.exists(ts_junc_filelist):\n",
    "    filtering_results['tabula_sapiens'] = filter_junction_paths(\n",
    "        ts_junc_filelist, clean_ts, valid_cell_ids, \"Tabula Sapiens\"\n",
    "    )\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== POST-PROCESSING VERIFICATION ===\")\n",
    "\n",
    "# Verify saved metadata can be read back\n",
    "print(\"--- Metadata Verification ---\")\n",
    "try:\n",
    "    test_metadata = pd.read_csv(output_path, sep=\"\\t\")\n",
    "    print(f\"‚úÖ Metadata file readable: {test_metadata.shape}\")\n",
    "    \n",
    "    # Check key properties\n",
    "    if test_metadata.shape == combined_metadata.shape:\n",
    "        print(\"‚úÖ Shape matches original\")\n",
    "    else:\n",
    "        print(f\"‚ùå Shape mismatch: saved {test_metadata.shape} vs original {combined_metadata.shape}\")\n",
    "    \n",
    "    # Check column consistency\n",
    "    if list(test_metadata.columns) == list(combined_metadata.columns):\n",
    "        print(\"‚úÖ Columns match original\")\n",
    "    else:\n",
    "        print(\"‚ùå Column mismatch detected\")\n",
    "    \n",
    "    # Check cell ID uniqueness\n",
    "    if test_metadata[\"cell_id\"].nunique() == len(test_metadata):\n",
    "        print(\"‚úÖ All cell IDs unique in saved file\")\n",
    "    else:\n",
    "        print(\"‚ùå Duplicate cell IDs found in saved file\")\n",
    "        \n",
    "    del test_metadata  # Free memory\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading saved metadata: {e}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== FINAL PROCESSING SUMMARY ===\")\n",
    "print(\"üéâ METADATA PROCESSING PIPELINE COMPLETE!\")\n",
    "print(f\"üìÖ Processing date: {today}\")\n",
    "\n",
    "print(f\"\\nüìä DATASET SUMMARY:\")\n",
    "dataset_summary = combined_metadata.groupby(\"dataset\").agg({\n",
    "    'cell_id': 'count',\n",
    "    'donor': 'nunique', \n",
    "    'broad_cell_type': 'nunique',\n",
    "    'age': ['min', 'max']\n",
    "}).round(1)\n",
    "\n",
    "print(dataset_summary)\n",
    "\n",
    "print(f\"\\nüî¨ CELL TYPE SUMMARY:\")\n",
    "print(f\"Total broad cell types: {combined_metadata['broad_cell_type'].nunique():,}\")\n",
    "print(f\"Shared cell types (‚â•{min_cells_per_dataset} cells/dataset): {len(shared_broad_cell_types)}\")\n",
    "print(f\"Cells in shared types: {total_shared_cells:,} ({shared_percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"‚úÖ Combined metadata: {output_path}\")\n",
    "if 'allen_brain' in filtering_results:\n",
    "    print(f\"‚úÖ Allen Brain junction list: {clean_ab}\")\n",
    "if 'tabula_sapiens' in filtering_results:\n",
    "    print(f\"‚úÖ Tabula Sapiens junction list: {clean_ts}\")\n",
    "\n",
    "print(f\"\\nüìà JUNCTION FILTERING SUMMARY:\")\n",
    "for dataset, results in filtering_results.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Original: {results['original_count']:,}\")\n",
    "    print(f\"  Retained: {results['filtered_count']:,}\")\n",
    "    print(f\"  Retention rate: {results['retention_rate']*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"1. Use filtered junction files for Leaflet and ATSEmapper pipeline\")\n",
    "print(\"2. Filter expression data to shared cell types for cross-dataset analysis\")\n",
    "print(\"3. Validate junction file existence before running downstream analysis\")\n",
    "\n",
    "print(\"\\n‚úÖ ALL PROCESSING COMPLETE WITH COMPREHENSIVE VALIDATION!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %%\n",
    "# Optional: Display final metadata sample and statistics\n",
    "print(\"\\n=== FINAL METADATA SAMPLE ===\")\n",
    "print(\"First 5 rows:\")\n",
    "print(combined_metadata.head())\n",
    "\n",
    "print(f\"\\nFinal metadata statistics:\")\n",
    "print(f\"Shape: {combined_metadata.shape}\")\n",
    "print(f\"Memory usage: {combined_metadata.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Show data types\n",
    "print(f\"\\nData types:\")\n",
    "for col in combined_metadata.columns:\n",
    "    dtype = combined_metadata[col].dtype\n",
    "    unique_vals = combined_metadata[col].nunique()\n",
    "    print(f\"  {col}: {dtype} ({unique_vals:,} unique values)\")\n",
    "\n",
    "# Show sample values for categorical columns\n",
    "categorical_cols = ['dataset', 'sex', 'tissue', 'broad_cell_type']\n",
    "print(f\"\\nSample values for key columns:\")\n",
    "for col in categorical_cols:\n",
    "    if col in combined_metadata.columns:\n",
    "        values = combined_metadata[col].value_counts().head(3)\n",
    "        print(f\"  {col}: {dict(values)}\")\n",
    "\n",
    "print(f\"\\nüìã Processing complete - all data validated and ready for analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeafletSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
