{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script loads in the publicly available tabula sapien anndata object with gene expression which also contains cell metadata...\n",
    "\n",
    "### The main purpose is to subset the number of junction regtools output files we obtained from raw data (WAY more raw data/BAM files than final number reported in their paper and the publicly available gene expression Anndata file)\n",
    "\n",
    "### Final number ends up being 40884 cells with metadata/gene expression reported in paper and splice junction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /gpfs/commons/home/kisaev/Leaflet-analysis/Human_Splicing_Foundation/metadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt # import matplotlib to visualize our qc metrics\n",
    "import subprocess\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scanpy.external as sce\n",
    "from sklearn.metrics import silhouette_score\n",
    "import datetime\n",
    "import numpy as np\n",
    "import harmonypy as hm\n",
    "import scanorama\n",
    "import gffutils\n",
    "from collections import defaultdict\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading in Tabula Sapiens V2 data...\n"
     ]
    }
   ],
   "source": [
    "# load in tabula sapien data \n",
    "# tabsap_adata = sc.read_h5ad(\"/gpfs/commons/datasets/controlled/CZI/tabula-sapiens/TS_figshare/TabulaSapiens.h5ad\") # original tabula sapiens \n",
    "print(f\"Now reading in Tabula Sapiens V2 data...\")\n",
    "tabsap_adata = sc.read_h5ad(\"/gpfs/commons/datasets/controlled/CZI/tabula-sapiens/TabulaSapiens_v2/GeneExpressionMatrices/merged_tabula_sapiens.h5ad\")\n",
    "tabsap_adata.obs[\"dataset\"] = \"tabula_sapiens\"\n",
    "tabsap_adata.layers[\"raw_counts\"] = tabsap_adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tabula sapien metadata to easily link back with BAM files and junction files \n",
    "output_dir = \"/gpfs/commons/datasets/controlled/CZI/tabula-sapiens/TabulaSapiens_v2/\"\n",
    "ts_metadata = tabsap_adata.obs[[\"old_index\", \"donor\", \"tissue\", \"anatomical_position\", \"library_plate\", \"cdna_well\", \"assay\"]]\n",
    "# save metadata to file\n",
    "ts_metadata.to_csv(os.path.join(output_dir, \"metadata.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           full_path  \\\n",
      "0  /gpfs/commons/projects/CZI-tabula-sapiens/Leaf...   \n",
      "1  /gpfs/commons/projects/CZI-tabula-sapiens/Leaf...   \n",
      "2  /gpfs/commons/projects/CZI-tabula-sapiens/Leaf...   \n",
      "3  /gpfs/commons/projects/CZI-tabula-sapiens/Leaf...   \n",
      "4  /gpfs/commons/projects/CZI-tabula-sapiens/Leaf...   \n",
      "\n",
      "                                           old_index  \n",
      "0  TSP3_smartseq2_B114669_G3_B133703_G3_Eye_noCor...  \n",
      "1  TSP14_smartseq2_B134540_L9_B002625_L9_LI_proxi...  \n",
      "2  TSP14_smartseq2_B134101_K21_D102110_K21_Saliva...  \n",
      "3  TSP14_smartseq2_B134025_F7_D101267_F7_LymphNod...  \n",
      "4  TSP7_smartseq2_B134144_O8_B133911_O8_Tongue_an...  \n"
     ]
    }
   ],
   "source": [
    "# list of junction files \n",
    "juncs = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_20250920.txt\"\n",
    "juncs_df = pd.read_csv(juncs, sep=\"\\t\", header=None)\n",
    "juncs_df.columns = [\"full_path\"]\n",
    "\n",
    "# Extract clean name between _raw_per_ and _junctions_with_barcodes\n",
    "def extract_core_id(path):\n",
    "    match = re.search(r\"_raw_per_(.+?)_junctions_with_barcodes\", path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract from {path}\")\n",
    "        return None\n",
    "\n",
    "# Apply to get 'old_index'\n",
    "juncs_df[\"old_index\"] = juncs_df[\"full_path\"].apply(extract_core_id)\n",
    "\n",
    "# Show a few\n",
    "print(juncs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_paths = juncs_df.merge(ts_metadata, on=\"old_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save just the full paths to a file\n",
    "full_paths[[\"full_path\"]].to_csv(\"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40884, 8)\n"
     ]
    }
   ],
   "source": [
    "print(full_paths.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeafletSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
