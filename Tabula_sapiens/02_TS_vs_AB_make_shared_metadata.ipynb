{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e13195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /gpfs/commons/home/kisaev/Leaflet-analysis/Human_Splicing_Foundation/metadata\n",
      "Processing date: 2025-09-20\n",
      "=== STARTING METADATA PROCESSING PIPELINE ===\n",
      "\n",
      "=== FILE VALIDATION ===\n",
      "✅ Allen Brain file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data//ab_adata_exons_2025-09-20.h5ad\n",
      "✅ Tabula Sapiens file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data//tabsap_adata_2025-09-20.h5ad\n",
      "\n",
      "=== LOADING ANNDATA OBJECTS ===\n",
      "⏳ Loading Allen Brain data...\n",
      "\n",
      "=== VALIDATING ALLEN BRAIN ADATA ===\n",
      "Shape: (49417, 50281)\n",
      "Obs columns: ['sample_name', 'specimen_type', 'cluster_color', 'cluster_order', 'cluster_label', 'class_color', 'class_order', 'class_label', 'subclass_color', 'subclass_order', 'subclass_label', 'full_genotype_color', 'full_genotype_order', 'full_genotype_label', 'donor_sex_color', 'donor_sex_order', 'donor_sex_label', 'region_color', 'region_order', 'region_label', 'cortical_layer_color', 'cortical_layer_order', 'cortical_layer_label', 'cell_type_accession_color', 'cell_type_accession_order', 'cell_type_accession_label', 'cell_type_alias_color', 'cell_type_order', 'cell_type_alias_label', 'cell_type_alt_alias_color', 'cell_type_alt_alias_order', 'cell_type_alt_alias_label', 'cell_type_designation_color', 'cell_type_designation_order', 'cell_type_designation_label', 'external_donor_name_color', 'external_donor_name_order', 'external_donor_name_label', 'outlier_call', 'outlier_type']\n",
      "Var columns: ['gene_symbol']\n",
      "❌ Missing required obs columns: ['dataset']\n",
      "⏳ Loading Tabula Sapiens data...\n",
      "\n",
      "=== VALIDATING TABULA SAPIENS ADATA ===\n",
      "Shape: (41501, 59412)\n",
      "Obs columns: ['donor', 'tissue', 'anatomical_position', 'method', 'cdna_plate', 'library_plate', 'notes', 'cdna_well', 'old_index', 'assay', 'sample_id', 'replicate', '10X_run', '10X_barcode', 'ambient_removal', 'donor_method', 'donor_assay', 'donor_tissue', 'donor_tissue_assay', 'cell_ontology_class', 'cell_ontology_id', 'compartment', 'broad_cell_class', 'free_annotation', 'manually_annotated', 'published_2022', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ercc', 'pct_counts_ercc', '_scvi_batch', '_scvi_labels', 'scvi_leiden_donorassay_full', 'age', 'sex', 'ethnicity', 'scvi_leiden_res05_tissue', 'sample_number', 'dataset']\n",
      "Var columns: ['ensembl_id', 'gene_symbol', 'genome', 'mt', 'ercc', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'mean', 'std', 'gene_name']\n",
      "✅ Tabula Sapiens AnnData structure validated\n",
      "\n",
      "=== PROCESSING ALLEN BRAIN METADATA ===\n",
      "\n",
      "=== EXTRACTING ALLEN_BRAIN METADATA ===\n",
      "⚠️  Missing values in allen_brain:\n",
      "  cell_type_designation_label: 1985 missing (4.0%)\n",
      "  cell_type_alias_label: 1985 missing (4.0%)\n",
      "  subclass_label: 1985 missing (4.0%)\n",
      "  class_label: 1985 missing (4.0%)\n",
      "✅ Extracted 49417 records from allen_brain\n",
      "\n",
      "--- Allen Brain Donor Validation ---\n",
      "Donors found: ['H200.1030', 'H200.1023', 'H200.1025']\n",
      "Cells per donor:\n",
      "external_donor_name_label\n",
      "H200.1030    19575\n",
      "H200.1023    18518\n",
      "H200.1025    11324\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Adding Age Information ---\n",
      "✅ Set age 54 for 19,575 cells from donor H200.1030\n",
      "✅ Set age 43 for 18,518 cells from donor H200.1023\n",
      "✅ Set age 50 for 11,324 cells from donor H200.1025\n",
      "Total cells with age assigned: 49,417 / 49,417\n",
      "Age distribution:\n",
      "age\n",
      "43    18518\n",
      "50    11324\n",
      "54    19575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== PROCESSING TABULA SAPIENS METADATA ===\n",
      "\n",
      "=== EXTRACTING TABULA_SAPIENS METADATA ===\n",
      "✅ Extracted 41501 records from tabula_sapiens\n",
      "\n",
      "--- Validating Tabula Sapiens Cell ID Generation ---\n",
      "Sample old_index format: 'TSP14_smartseq2_B134547_B20_D101532_B20_LI_proximal_Epithelial'\n",
      "✅ Cell ID generation successful\n",
      "Sample generated cell IDs:\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_B20_D101532_B20_LI_proximal_Epithelial\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_L10_D101532_L10_LI_proximal_Epithelial\n",
      "  TSP14_TSP14_smartseq2_B134547_D101532_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134547_G16_D101532_G16_LI_proximal_Epithelial\n",
      "\n",
      "=== VALIDATING TABULA SAPIENS CELL IDS ===\n",
      "✅ All 41501 cell IDs are valid and unique\n",
      "\n",
      "=== STANDARDIZING METADATA FORMATS ===\n",
      "--- Pre-standardization shapes ---\n",
      "Tabula Sapiens: (41501, 15)\n",
      "Allen Brain: (49417, 11)\n",
      "✅ Converted categorical columns to strings: ['donor', 'sex', 'tissue', 'cell_type']\n",
      "✅ Converted categorical columns to strings: ['donor', 'sex', 'tissue', 'cell_type']\n",
      "✅ Metadata standardization complete\n",
      "\n",
      "=== COMBINING AND CLEANING METADATA ===\n",
      "\n",
      "=== VALIDATING METADATA CONSISTENCY ===\n",
      "Comparing Tabula Sapiens vs Allen Brain\n",
      "Common columns: 7\n",
      "sex values across datasets: ['F', 'M', 'female', 'male']\n",
      "dataset values across datasets: ['allen_brain', 'tabula_sapiens']\n",
      "✅ Combined metadata shape: (90918, 7)\n",
      "--- Post-combination validation ---\n",
      "Dataset distribution:\n",
      "dataset\n",
      "allen_brain       49417\n",
      "tabula_sapiens    41501\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Cleaning Sex Column ---\n",
      "Sex values before cleaning:\n",
      "sex\n",
      "M         30899\n",
      "female    24355\n",
      "F         18518\n",
      "male      17146\n",
      "Name: count, dtype: int64\n",
      "Sex values after cleaning:\n",
      "sex\n",
      "M    48045\n",
      "F    42873\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== CELL TYPE MAPPING ===\n",
      "--- Cell Type Mapping Validation ---\n",
      "✅ Cell type mapping created: 211 mappings\n",
      "⚠️  3934 cells with unmapped cell types\n",
      "Top unmapped cell types:\n",
      "cell_type\n",
      "nan                                                     1985\n",
      "basal cell                                              1523\n",
      "kidney epithelial cell                                   154\n",
      "lung ciliated cell                                       130\n",
      "Endothelial                                               70\n",
      "unciliated epithelium                                     47\n",
      "colon macrophage                                          18\n",
      "transit amplifying cell of small intestine                 4\n",
      "naive thymus-derived cd8-positive, alpha-beta t cell       3\n",
      "Name: count, dtype: int64\n",
      "✅ Used original cell_type for unmapped cells\n",
      "\n",
      "--- Broad Cell Type Distribution ---\n",
      "Number of broad cell types: 60\n",
      "Top 10 broad cell types:\n",
      "broad_cell_type\n",
      "Excitatory_Neuron     31229\n",
      "Inhibitory_Neuron     11125\n",
      "General_Fibroblast     4223\n",
      "CNS_Glia               3902\n",
      "CD4_T_cell             3289\n",
      "Granulocyte            2639\n",
      "B_cell                 2630\n",
      "Monocyte               2563\n",
      "Macrophage             2432\n",
      "CD8_T_cell             2397\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SHARED CELL TYPE ANALYSIS ===\n",
      "Finding cell types with ≥50 cells per dataset...\n",
      "✅ Shared broad cell types (≥50 per dataset): 1\n",
      "Shared cell types: ['Microglia']\n",
      "\n",
      "--- Detailed Shared Cell Type Analysis ---\n",
      "Cell counts for shared types:\n",
      "dataset          allen_brain  tabula_sapiens\n",
      "broad_cell_type                             \n",
      "Microglia                750              56\n",
      "\n",
      "Shared cell type summary:\n",
      "  Total cells: 90,918\n",
      "  Cells in shared types: 806\n",
      "  Percentage in shared types: 0.9%\n",
      "\n",
      "Excluded cell types (59):\n",
      "  Alveolar_cell: AB=0, TS=866\n",
      "  Arterial_Endothelial: AB=0, TS=176\n",
      "  B_cell: AB=0, TS=2630\n",
      "  CD4_T_cell: AB=0, TS=3289\n",
      "  CD8_T_cell: AB=0, TS=2397\n",
      "  CNS_Glia: AB=3890, TS=12\n",
      "  Capillary_Endothelial: AB=0, TS=864\n",
      "  Cardiac_Muscle: AB=0, TS=49\n",
      "  Dendritic_cell: AB=0, TS=194\n",
      "  Endothelial: AB=70, TS=0\n",
      "  ... and 49 more\n",
      "\n",
      "=== SAVING METADATA ===\n",
      "--- Pre-save Validation ---\n",
      "Final metadata shape: (90918, 8)\n",
      "Columns: ['cell_id', 'donor', 'sex', 'age', 'dataset', 'tissue', 'cell_type', 'broad_cell_type']\n",
      "✅ No missing values in 'cell_id'\n",
      "✅ No missing values in 'dataset'\n",
      "✅ No missing values in 'broad_cell_type'\n",
      "✅ All 90,918 cell IDs are unique\n",
      "✅ Metadata saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\n",
      "File size: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import scipy.sparse as sp\n",
    "from pathlib import Path\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)\n",
    "\n",
    "# Configuration\n",
    "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Processing date: {today}\")\n",
    "\n",
    "# %%\n",
    "def validate_file_exists(filepath, description=\"\"):\n",
    "    \"\"\"Validate that a file exists and is readable.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"❌ {description} file not found: {filepath}\")\n",
    "    if not os.access(filepath, os.R_OK):\n",
    "        raise PermissionError(f\"❌ {description} file not readable: {filepath}\")\n",
    "    print(f\"✅ {description} file found: {filepath}\")\n",
    "    return True\n",
    "\n",
    "def validate_adata_structure(adata, dataset_name):\n",
    "    \"\"\"Validate AnnData object structure and content.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING {dataset_name.upper()} ADATA ===\")\n",
    "    \n",
    "    print(f\"Shape: {adata.shape}\")\n",
    "    print(f\"Obs columns: {list(adata.obs.columns)}\")\n",
    "    print(f\"Var columns: {list(adata.var.columns)}\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_obs = ['dataset']\n",
    "    missing_obs = [col for col in required_obs if col not in adata.obs.columns]\n",
    "    \n",
    "    if missing_obs:\n",
    "        print(f\"❌ Missing required obs columns: {missing_obs}\")\n",
    "        return False\n",
    "    \n",
    "    # Check data integrity\n",
    "    if adata.obs.index.duplicated().any():\n",
    "        dup_count = adata.obs.index.duplicated().sum()\n",
    "        print(f\"❌ {dup_count} duplicate cell indices found!\")\n",
    "        return False\n",
    "    \n",
    "    if adata.var.index.duplicated().any():\n",
    "        dup_count = adata.var.index.duplicated().sum()\n",
    "        print(f\"❌ {dup_count} duplicate gene indices found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"✅ {dataset_name} AnnData structure validated\")\n",
    "    return True\n",
    "\n",
    "def extract_metadata_with_validation(adata, dataset_name, required_columns):\n",
    "    \"\"\"Extract metadata from AnnData with validation.\"\"\"\n",
    "    print(f\"\\n=== EXTRACTING {dataset_name.upper()} METADATA ===\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    missing_cols = [col for col in required_columns if col not in adata.obs.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"❌ Missing columns in {dataset_name}: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(adata.obs.columns)}\")\n",
    "        raise ValueError(f\"Required columns missing from {dataset_name}\")\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = adata.obs[required_columns].reset_index(drop=True)\n",
    "    metadata[\"dataset\"] = dataset_name\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_counts = metadata.isnull().sum()\n",
    "    if missing_counts.any():\n",
    "        print(f\"⚠️  Missing values in {dataset_name}:\")\n",
    "        for col, count in missing_counts[missing_counts > 0].items():\n",
    "            print(f\"  {col}: {count} missing ({count/len(metadata)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"✅ Extracted {len(metadata)} records from {dataset_name}\")\n",
    "    return metadata\n",
    "\n",
    "def validate_cell_id_format(metadata, dataset_name, cell_id_col=\"cell_id\"):\n",
    "    \"\"\"Validate cell ID format and uniqueness.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING {dataset_name.upper()} CELL IDS ===\")\n",
    "    \n",
    "    if cell_id_col not in metadata.columns:\n",
    "        print(f\"❌ Cell ID column '{cell_id_col}' not found!\")\n",
    "        return False\n",
    "    \n",
    "    cell_ids = metadata[cell_id_col]\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = cell_ids.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"❌ {duplicates} duplicate cell IDs found!\")\n",
    "        # Show examples\n",
    "        dup_examples = cell_ids[cell_ids.duplicated()].head(3).tolist()\n",
    "        print(f\"Examples: {dup_examples}\")\n",
    "        return False\n",
    "    \n",
    "    # Check for missing/null IDs\n",
    "    missing = cell_ids.isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"❌ {missing} missing cell IDs found!\")\n",
    "        return False\n",
    "    \n",
    "    # Check for empty strings\n",
    "    empty = (cell_ids == \"\").sum()\n",
    "    if empty > 0:\n",
    "        print(f\"❌ {empty} empty cell IDs found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"✅ All {len(cell_ids)} cell IDs are valid and unique\")\n",
    "    return True\n",
    "\n",
    "def convert_categoricals_to_strings(df):\n",
    "    \"\"\"Convert categorical columns to strings for consistency.\"\"\"\n",
    "    converted_cols = []\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, CategoricalDtype):\n",
    "            df[col] = df[col].astype(str)\n",
    "            converted_cols.append(col)\n",
    "    \n",
    "    if converted_cols:\n",
    "        print(f\"✅ Converted categorical columns to strings: {converted_cols}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_metadata_consistency(metadata1, metadata2, dataset1_name, dataset2_name):\n",
    "    \"\"\"Validate consistency between two metadata datasets.\"\"\"\n",
    "    print(f\"\\n=== VALIDATING METADATA CONSISTENCY ===\")\n",
    "    print(f\"Comparing {dataset1_name} vs {dataset2_name}\")\n",
    "    \n",
    "    # Check column consistency\n",
    "    cols1, cols2 = set(metadata1.columns), set(metadata2.columns)\n",
    "    common_cols = cols1.intersection(cols2)\n",
    "    unique_to_1 = cols1 - cols2\n",
    "    unique_to_2 = cols2 - cols1\n",
    "    \n",
    "    print(f\"Common columns: {len(common_cols)}\")\n",
    "    if unique_to_1:\n",
    "        print(f\"Unique to {dataset1_name}: {unique_to_1}\")\n",
    "    if unique_to_2:\n",
    "        print(f\"Unique to {dataset2_name}: {unique_to_2}\")\n",
    "    \n",
    "    # Check value consistency for common categorical columns\n",
    "    categorical_cols = ['sex', 'dataset']\n",
    "    for col in categorical_cols:\n",
    "        if col in common_cols:\n",
    "            vals1 = set(metadata1[col].unique())\n",
    "            vals2 = set(metadata2[col].unique())\n",
    "            all_vals = vals1.union(vals2)\n",
    "            print(f\"{col} values across datasets: {sorted(all_vals)}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "print(\"=== STARTING METADATA PROCESSING PIPELINE ===\")\n",
    "\n",
    "# File paths\n",
    "outdir = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/processed_data/\"\n",
    "ab_file = f\"{outdir}/ab_adata_exons_2025-09-20.h5ad\"\n",
    "ts_file = f\"{outdir}/tabsap_adata_2025-09-20.h5ad\"\n",
    "\n",
    "# Validate input files\n",
    "print(\"\\n=== FILE VALIDATION ===\")\n",
    "validate_file_exists(ab_file, \"Allen Brain\")\n",
    "validate_file_exists(ts_file, \"Tabula Sapiens\")\n",
    "\n",
    "# Load data with validation\n",
    "print(\"\\n=== LOADING ANNDATA OBJECTS ===\")\n",
    "print(\"⏳ Loading Allen Brain data...\")\n",
    "ab_exons = sc.read_h5ad(ab_file)\n",
    "validate_adata_structure(ab_exons, \"Allen Brain\")\n",
    "\n",
    "print(\"⏳ Loading Tabula Sapiens data...\")\n",
    "ts_adata = sc.read_h5ad(ts_file)\n",
    "validate_adata_structure(ts_adata, \"Tabula Sapiens\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== PROCESSING ALLEN BRAIN METADATA ===\")\n",
    "\n",
    "# Define required columns for Allen Brain\n",
    "ab_required_cols = [\n",
    "    \"sample_name\", \"cell_type_designation_label\", \"cell_type_alias_label\", \n",
    "    \"specimen_type\", \"subclass_label\", \"donor_sex_label\", \n",
    "    \"external_donor_name_label\", \"class_label\", \"region_label\"\n",
    "]\n",
    "\n",
    "# Extract Allen Brain metadata\n",
    "ab_metadata = extract_metadata_with_validation(ab_exons, \"allen_brain\", ab_required_cols)\n",
    "\n",
    "# SANITY CHECK 1: Validate donor information\n",
    "print(\"\\n--- Allen Brain Donor Validation ---\")\n",
    "donor_counts = ab_metadata[\"external_donor_name_label\"].value_counts()\n",
    "print(f\"Donors found: {list(donor_counts.index)}\")\n",
    "print(f\"Cells per donor:\\n{donor_counts}\")\n",
    "\n",
    "# Add age information with validation\n",
    "print(\"\\n--- Adding Age Information ---\")\n",
    "\n",
    "# adding age manuall for donors using https://pmc.ncbi.nlm.nih.gov/articles/PMC6919571/table/T1/\n",
    "age_mapping = {\n",
    "    \"H200.1030\": 54,  # Caucasian\n",
    "    \"H200.1023\": 43,  # Iranian descent  \n",
    "    \"H200.1025\": 50   # Caucasian\n",
    "}\n",
    "\n",
    "ab_metadata[\"age\"] = 0\n",
    "cells_with_age = 0\n",
    "\n",
    "for donor, age in age_mapping.items():\n",
    "    donor_mask = ab_metadata[\"external_donor_name_label\"] == donor\n",
    "    donor_count = donor_mask.sum()\n",
    "    if donor_count > 0:\n",
    "        ab_metadata.loc[donor_mask, \"age\"] = age\n",
    "        cells_with_age += donor_count\n",
    "        print(f\"✅ Set age {age} for {donor_count:,} cells from donor {donor}\")\n",
    "    else:\n",
    "        print(f\"⚠️  No cells found for donor {donor}\")\n",
    "\n",
    "print(f\"Total cells with age assigned: {cells_with_age:,} / {len(ab_metadata):,}\")\n",
    "\n",
    "# SANITY CHECK 2: Validate age assignment\n",
    "age_dist = ab_metadata[\"age\"].value_counts().sort_index()\n",
    "print(f\"Age distribution:\\n{age_dist}\")\n",
    "\n",
    "if (ab_metadata[\"age\"] == 0).any():\n",
    "    cells_without_age = (ab_metadata[\"age\"] == 0).sum()\n",
    "    print(f\"⚠️  {cells_without_age} cells still have age = 0\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== PROCESSING TABULA SAPIENS METADATA ===\")\n",
    "\n",
    "# Define required columns for Tabula Sapiens\n",
    "ts_required_cols = [\n",
    "    \"old_index\", \"sample_id\", \"donor\", \"tissue\", \"cell_ontology_class\", \n",
    "    \"compartment\", \"broad_cell_class\", \"age\", \"sex\", \"dataset\", \"free_annotation\"\n",
    "]\n",
    "\n",
    "# Extract Tabula Sapiens metadata\n",
    "ts_metadata = extract_metadata_with_validation(ts_adata, \"tabula_sapiens\", ts_required_cols)\n",
    "\n",
    "# SANITY CHECK 3: Validate old_index format for cell ID generation\n",
    "print(\"\\n--- Validating Tabula Sapiens Cell ID Generation ---\")\n",
    "sample_old_index = ts_metadata[\"old_index\"].iloc[0]\n",
    "print(f\"Sample old_index format: '{sample_old_index}'\")\n",
    "\n",
    "# Parse old_index components\n",
    "ts_metadata[\"project_id\"] = ts_metadata[\"sample_id\"].str.extract(r'^(TSP\\d+)')\n",
    "parts = ts_metadata[\"old_index\"].str.split(\"_\")\n",
    "\n",
    "# Check if splitting worked correctly\n",
    "if len(parts.iloc[0]) < 8:\n",
    "    print(f\"❌ ERROR: old_index format unexpected. Expected 8+ parts, got {len(parts.iloc[0])}\")\n",
    "    print(f\"Sample parts: {parts.iloc[0]}\")\n",
    "    raise ValueError(\"old_index parsing failed\")\n",
    "\n",
    "# Generate cell ID components with validation\n",
    "try:\n",
    "    ts_metadata[\"junc_prefix_core\"] = (\n",
    "        parts.str[0] + \"_\" +  # TSP1\n",
    "        parts.str[1] + \"_\" +  # smartseq2\n",
    "        parts.str[2] + \"_\" +  # NA\n",
    "        parts.str[4] + \"_\" +  # B107921\n",
    "        parts.str[6] + \"_\" +  # Muscle\n",
    "        parts.str[7]          # NA\n",
    "    )\n",
    "    \n",
    "    ts_metadata[\"cell_id_prefix\"] = (\n",
    "        ts_metadata[\"project_id\"] + \"_\" +\n",
    "        ts_metadata[\"junc_prefix_core\"] +\n",
    "        \".multi_star.output_raw.output_raw_per_\"\n",
    "    )\n",
    "    \n",
    "    ts_metadata[\"cell_id\"] = ts_metadata[\"cell_id_prefix\"] + ts_metadata[\"old_index\"]\n",
    "    \n",
    "    print(\"✅ Cell ID generation successful\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"Sample generated cell IDs:\")\n",
    "    for i in range(min(3, len(ts_metadata))):\n",
    "        print(f\"  {ts_metadata['cell_id'].iloc[i]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR in cell ID generation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Validate generated cell IDs\n",
    "validate_cell_id_format(ts_metadata, \"Tabula Sapiens\", \"cell_id\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== STANDARDIZING METADATA FORMATS ===\")\n",
    "\n",
    "# Create working copies\n",
    "ts_meta = ts_metadata.copy()\n",
    "ab_meta = ab_metadata.copy()\n",
    "\n",
    "# SANITY CHECK 4: Pre-standardization validation\n",
    "print(\"--- Pre-standardization shapes ---\")\n",
    "print(f\"Tabula Sapiens: {ts_meta.shape}\")\n",
    "print(f\"Allen Brain: {ab_meta.shape}\")\n",
    "\n",
    "# Rename columns to match target structure\n",
    "ts_meta = ts_meta.rename(columns={\n",
    "    \"donor\": \"donor\",\n",
    "    \"sex\": \"sex\", \n",
    "    \"free_annotation\": \"cell_type\",\n",
    "})\n",
    "\n",
    "ab_meta = ab_meta.rename(columns={\n",
    "    \"sample_name\": \"cell_id\",\n",
    "    \"external_donor_name_label\": \"donor\",\n",
    "    \"donor_sex_label\": \"sex\",\n",
    "    \"region_label\": \"tissue\",\n",
    "    \"subclass_label\": \"cell_type\"\n",
    "})\n",
    "\n",
    "# Define final column structure\n",
    "final_columns = [\"cell_id\", \"donor\", \"sex\", \"age\", \"dataset\", \"tissue\", \"cell_type\"]\n",
    "\n",
    "# SANITY CHECK 5: Check for missing final columns\n",
    "for dataset_name, df in [(\"Tabula Sapiens\", ts_meta), (\"Allen Brain\", ab_meta)]:\n",
    "    missing_cols = [col for col in final_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"❌ Missing final columns in {dataset_name}: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        raise ValueError(f\"Column standardization failed for {dataset_name}\")\n",
    "\n",
    "# Select and reorder columns\n",
    "ts_meta = ts_meta[final_columns].reset_index(drop=True)\n",
    "ab_meta = ab_meta[final_columns].reset_index(drop=True)\n",
    "\n",
    "# Convert categoricals to strings\n",
    "ts_meta = convert_categoricals_to_strings(ts_meta)\n",
    "ab_meta = convert_categoricals_to_strings(ab_meta)\n",
    "\n",
    "print(\"✅ Metadata standardization complete\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== COMBINING AND CLEANING METADATA ===\")\n",
    "\n",
    "# Validate consistency before combining\n",
    "validate_metadata_consistency(ts_meta, ab_meta, \"Tabula Sapiens\", \"Allen Brain\")\n",
    "\n",
    "# Combine metadata\n",
    "combined_metadata = pd.concat([ts_meta, ab_meta], ignore_index=True)\n",
    "print(f\"✅ Combined metadata shape: {combined_metadata.shape}\")\n",
    "\n",
    "# SANITY CHECK 6: Post-combination validation\n",
    "print(\"--- Post-combination validation ---\")\n",
    "dataset_counts = combined_metadata[\"dataset\"].value_counts()\n",
    "print(f\"Dataset distribution:\\n{dataset_counts}\")\n",
    "\n",
    "expected_total = len(ts_meta) + len(ab_meta)\n",
    "if len(combined_metadata) != expected_total:\n",
    "    print(f\"❌ ERROR: Expected {expected_total} rows, got {len(combined_metadata)}\")\n",
    "    raise ValueError(\"Row count mismatch after combination\")\n",
    "\n",
    "# Clean sex column with validation\n",
    "print(\"\\n--- Cleaning Sex Column ---\")\n",
    "sex_before = combined_metadata[\"sex\"].value_counts()\n",
    "print(f\"Sex values before cleaning:\\n{sex_before}\")\n",
    "\n",
    "combined_metadata[\"sex\"] = combined_metadata[\"sex\"].astype(str)\n",
    "combined_metadata.loc[combined_metadata[\"sex\"] == \"male\", \"sex\"] = \"M\"\n",
    "combined_metadata.loc[combined_metadata[\"sex\"] == \"female\", \"sex\"] = \"F\"\n",
    "\n",
    "sex_after = combined_metadata[\"sex\"].value_counts()\n",
    "print(f\"Sex values after cleaning:\\n{sex_after}\")\n",
    "\n",
    "# Check for unexpected sex values\n",
    "unexpected_sex = combined_metadata[~combined_metadata[\"sex\"].isin([\"M\", \"F\"])]\n",
    "if len(unexpected_sex) > 0:\n",
    "    print(f\"⚠️  {len(unexpected_sex)} cells with unexpected sex values:\")\n",
    "    print(unexpected_sex[\"sex\"].value_counts())\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== CELL TYPE MAPPING ===\")\n",
    "\n",
    "# Define refined cell type mapping\n",
    "grouped_refined_map = {\n",
    "    # === NEURONS - Split by major functional classes ===\n",
    "    'Excitatory_Neuron': [\n",
    "        'IT', 'L4 IT', 'L5 ET', 'L6 CT', 'L6b', 'L5/6 IT Car3', 'L5/6 NP'\n",
    "    ],\n",
    "    'Inhibitory_Neuron': [\n",
    "        'VIP', 'PVALB', 'SST', 'LAMP5'\n",
    "    ],\n",
    "    'Other_Neuron': [\n",
    "        'PAX6', 'retinal bipolar neuron'\n",
    "    ],\n",
    "    \n",
    "    # === T CELLS - Organized by major functional subsets ===\n",
    "    'CD4_T_cell': [\n",
    "        'cd4-positive, alpha-beta t cell', 'cd4-positive helper t cell', \n",
    "        'cd4-positive, alpha-beta memory t cell', 'naive thymus-derived cd4-positive, alpha-beta t cell',\n",
    "        'activated cd4-positive, alpha-beta t cell', 'cd4-positive, alpha-beta thymocyte',\n",
    "        'cd4-positive memory t cell', 't follicular helper cell'\n",
    "    ],\n",
    "    'CD8_T_cell': [\n",
    "        'cd8-positive, alpha-beta t cell', 'cd8-positive, alpha-beta memory t cell',\n",
    "        'cd8-positive, alpha-beta thymocyte', 'naive cd8-positive t cell',\n",
    "        'activated cd8-positive, alpha-beta t cell', 'cd8-positive cytotoxic t cell',\n",
    "        'cd8+, alpha-beta cytokine secreting effector t cell'\n",
    "    ],\n",
    "    'Regulatory_T_cell': [\n",
    "        'regulatory t cell', 'naive regulatory t cell'\n",
    "    ],\n",
    "    'Other_T_cell': [\n",
    "        't cell', 'gamma-delta t cell', 'thymocyte'\n",
    "    ],\n",
    "    \n",
    "    # === B CELLS ===\n",
    "    'B_cell': [\n",
    "        'b cell', 'memory b cell', 'naive b cell'\n",
    "    ],\n",
    "    'Plasma_cell': [\n",
    "        'plasma cell', 'antibody secreting cell'\n",
    "    ],\n",
    "    \n",
    "    # === MYELOID CELLS - Split by major lineages ===\n",
    "    'Microglia': [\n",
    "        'Microglia', 'microglial cell', 'retina - microglia'\n",
    "    ],\n",
    "    'Macrophage': [\n",
    "        'macrophage', 'Monocyte_Macrophage', 'tissue-resident macrophage', \n",
    "        'muscle macrophage'\n",
    "    ],\n",
    "    'Monocyte': [\n",
    "        'monocyte', 'classical monocyte', 'non-classical monocyte', 'intermediate monocyte'\n",
    "    ],\n",
    "    'Dendritic_cell': [\n",
    "        'dendritic cell', 'myeloid dendritic cell', 'plasmacytoid dendritic cell',\n",
    "        'cd1c-positive myeloid dendritic cell', 'cd141-positive myeloid dendritic cell',\n",
    "        'cdc1', 'cdc2', 'conventional dendritic cell'\n",
    "    ],\n",
    "    'Granulocyte': [\n",
    "        'neutrophil', 'cd24 neutrophil', 'nampt neutrophil', 'granulocyte',\n",
    "        'basophil', 'mast cell'\n",
    "    ],\n",
    "    \n",
    "    # === NK/ILC ===\n",
    "    'NK_ILC': [\n",
    "        'nk cell', 'natural killer cell', 'nk t cell', 'innate lymphoid cell', \n",
    "        'mature nk t cell', 'type i nk t cell', 'uterine nk cell', \n",
    "        'proliferating nk cell', 'immature natural killer cell'\n",
    "    ],\n",
    "    \n",
    "    # === EPITHELIAL - Split by organ system ===\n",
    "    'Respiratory_Epithelial': [\n",
    "        'club cell', 'ionocyte', 'goblet cell', 'ciliated epithelial cell',\n",
    "        'pulmonary ionocyte', 'serous cell of epithelium of bronchus',\n",
    "        'respiratory goblet cell', 'ciliated columnar cell of tracheobronchial tree',\n",
    "        'tracheal goblet cell'\n",
    "    ],\n",
    "    'GI_Epithelial': [\n",
    "        'enterocyte of epithelium of large intestine', \n",
    "        'enterocyte of epithelium proper of small intestine',\n",
    "        'large intestine goblet cell', 'best4+ intestinal epithelial cell',\n",
    "        'small intestine goblet cell', 'enterocyte of epithelium proper of ileum',\n",
    "        'enterocyte of epithelium proper of duodenum', \n",
    "        'paneth cell of epithelium of small intestine', 'paneth cell of colon',\n",
    "        'mature enterocyte', 'intestinal tuft cell', 'tuft cell of colon'\n",
    "    ],\n",
    "    'Urogenital_Epithelial': [\n",
    "        'bladder urothelial cell', 'basal bladder urothelial cell', \n",
    "        'intermediate bladder urothelial cell', 'epithelial cell of uterus'\n",
    "    ],\n",
    "    'Mammary_Epithelial': [\n",
    "        'HR positive luminal epithelial cell of mammary gland',\n",
    "        'secretory luminal epithelial cell of mammary gland',\n",
    "        'luminal epithelial cell'\n",
    "    ],\n",
    "    'Other_Epithelial': [\n",
    "        'epithelial cell', 'duct epithelial cell', 'ltf+ epithelial cell',\n",
    "        'basal epithelial cell', 'salivary gland cell', 'medullary thymic epithelial cell',\n",
    "        'conjunctival epithelial cell', 'corneal epithelial cell', 'glandular epithelial cell',\n",
    "        'cycling epithelial cell', 'mucus secreting cell', 'biliary epithelial cell',\n",
    "        'pancreatic ductal cell', 'stratified squamous epithelial cell', 'sebum secreting cell'\n",
    "    ],\n",
    "    \n",
    "    # === ENDOTHELIAL - Split by vessel type ===\n",
    "    'Arterial_Endothelial': [\n",
    "        'arterial endothelial cell', 'endothelial cell of arteriole', 'endothelial cell of artery'\n",
    "    ],\n",
    "    'Venous_Endothelial': [\n",
    "        'vein endothelial cell', 'venous capillary endothelial cell', 'endothelial cell of venule'\n",
    "    ],\n",
    "    'Capillary_Endothelial': [\n",
    "        'capillary endothelial cell', 'blood vessel endothelial cell'\n",
    "    ],\n",
    "    'Lymphatic_Endothelial': [\n",
    "        'endothelial cell of lymphatic vessel'\n",
    "    ],\n",
    "    'Specialized_Endothelial': [\n",
    "        'endothelial cell', 'endothelial cell of vascular tree', 'cardiac endothelial cell',\n",
    "        'colon endothelial cell', 'retinal blood vessel endothelial cell', 'vascular endothelial cell'\n",
    "    ],\n",
    "    \n",
    "    # === GLIA - Split by CNS vs PNS ===\n",
    "    'CNS_Glia': [\n",
    "        'Astrocyte', 'OPC', 'Oligodendrocyte', 'retina - muller glia', 'mueller cell'\n",
    "    ],\n",
    "    'PNS_Glia': [\n",
    "        'enteroglial cell', 'schwann cell'\n",
    "    ],\n",
    "    'Glia_Other': [\n",
    "        'glial cell'\n",
    "    ],\n",
    "    \n",
    "    # === MUSCLE - Split by muscle type ===\n",
    "    'Smooth_Muscle': [\n",
    "        'smooth muscle cell', 'airway smooth muscle cell', 'vascular associated smooth muscle cell'\n",
    "    ],\n",
    "    'Cardiac_Muscle': [\n",
    "        'atrial cardiac muscle cell', 'ventricular cardiac muscle cell'\n",
    "    ],\n",
    "    'Skeletal_Muscle': [\n",
    "        'skeletal muscle satellite stem cell', 'fast muscle cell', 'slow muscle cell',\n",
    "        'tongue muscle cell'\n",
    "    ],\n",
    "    'Muscle_Other': [\n",
    "        'muscle cell', 'tendon cell'\n",
    "    ],\n",
    "    \n",
    "    # === STROMAL/FIBROBLAST - More specific organ groupings ===\n",
    "    'General_Fibroblast': [\n",
    "        'fibroblast', 'stromal cell', 'myofibroblast cell', 'adventitial fibroblast',\n",
    "        'cd34+ fibroblasts', 'VLMC', 'adventitial cell', 'connective tissue cell'\n",
    "    ],\n",
    "    'Organ_Specific_Fibroblast': [\n",
    "        'alveolar fibroblast', 'fibroblast of breast', 'fibroblast of cardiac tissue',\n",
    "        'uterine fibroblast', 'stellate_fibroblast', 'endometrial stromal fibroblast'\n",
    "    ],\n",
    "    'Specialized_Stromal': [\n",
    "        'fat cell', 'cornea - mesenchymal cell - stromal keratinocytes',\n",
    "        'limbal stromal cell', 'follicle', 'granulosa cell', 'mesothelial cell', 'theca cell'\n",
    "    ],\n",
    "    \n",
    "    # === LIVER - Split by major cell types ===\n",
    "    'Hepatocyte': [\n",
    "        'hepatocyte'\n",
    "    ],\n",
    "    'Liver_Non_Parenchymal': [\n",
    "        'hepatic stellate cell', 'intrahepatic cholangiocyte'\n",
    "    ],\n",
    "    \n",
    "    # === SPECIALIZED CELLS ===\n",
    "    'Pericyte': [\n",
    "        'pericyte', 'Pericyte', 'myofibroblast cell and pericyte', 'mural cell'\n",
    "    ],\n",
    "    \n",
    "    'Photoreceptor': [\n",
    "        'retinal pigment epithelial cell', 'retina - photoreceptor cell', 'eye photoreceptor cell'\n",
    "    ],\n",
    "    \n",
    "    'Alveolar_cell': [\n",
    "        'type ii pneumocyte', 'type i pneumocyte', 'capillary aerocyte'\n",
    "    ],\n",
    "    \n",
    "    'Enteroendocrine': [\n",
    "        'enteroendocrine cell of small intestine', 'type l enteroendocrine cell',\n",
    "        'enterochromaffin-like cell'\n",
    "    ],\n",
    "    \n",
    "    'Hematopoietic_Mature': [\n",
    "        'platelet', 'erythrocyte'\n",
    "    ],\n",
    "    \n",
    "    'Hematopoietic_Progenitor': [\n",
    "        'erythroid progenitor cell', 'hematopoietic stem cell', 'myeloid progenitor',\n",
    "        'common myeloid progenitor'\n",
    "    ],\n",
    "    \n",
    "    'Mesenchymal_Stem': [\n",
    "        'mesenchymal stem cell', 'mesenchymal stem cell of adipose tissue'\n",
    "    ],\n",
    "    \n",
    "    'Stem_Progenitor_Other': [\n",
    "        'oocyte', 'radial glia progenitor cell', 'intestinal crypt stem cell of small intestine',\n",
    "        'intestinal crypt stem cell of large intestine'\n",
    "    ],\n",
    "    \n",
    "    'Secretory_Gland': [\n",
    "        'acinar cell of salivary gland', 'lacrimal gland functional unit cell', 'myoepithelial cell'\n",
    "    ],\n",
    "    \n",
    "    'Pigment_cell': [\n",
    "        'melanocyte', 'melanocyte or limbal stem cell'\n",
    "    ],\n",
    "    \n",
    "    'Sensory_cell': [\n",
    "        'taste receptor cell'\n",
    "    ],\n",
    "    \n",
    "    'Skin_cell': [\n",
    "        'keratocyte'\n",
    "    ],\n",
    "    \n",
    "    'Myeloid_Other': [\n",
    "        'myeloid cell', 'mononuclear phagocyte'\n",
    "    ],\n",
    "    \n",
    "    'Immune_Other': [\n",
    "        'leukocyte', 'langerhans cell', 'immune cell'\n",
    "    ],\n",
    "    \n",
    "    'Unknown': [\n",
    "        'unknown'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# SANITY CHECK 7: Validate cell type mapping\n",
    "print(\"--- Cell Type Mapping Validation ---\")\n",
    "\n",
    "# Flatten the mapping\n",
    "def flatten_grouped_map(grouped_map):\n",
    "    flattened = {}\n",
    "    for broad_type, labels in grouped_map.items():\n",
    "        for label in labels:\n",
    "            if label in flattened:\n",
    "                print(f\"⚠️  WARNING: '{label}' appears in multiple categories: {flattened[label]} and {broad_type}\")\n",
    "            flattened[label] = broad_type\n",
    "    return flattened\n",
    "\n",
    "grouped_broad_map_flat = flatten_grouped_map(grouped_refined_map)\n",
    "print(f\"✅ Cell type mapping created: {len(grouped_broad_map_flat)} mappings\")\n",
    "\n",
    "# Apply mapping\n",
    "combined_metadata['broad_cell_type'] = (\n",
    "    combined_metadata['cell_type']\n",
    "    .map(grouped_broad_map_flat)\n",
    "    .fillna('Other')\n",
    ")\n",
    "\n",
    "# Handle unmapped cell types\n",
    "unmapped_mask = combined_metadata[\"broad_cell_type\"] == \"Other\"\n",
    "unmapped_count = unmapped_mask.sum()\n",
    "\n",
    "if unmapped_count > 0:\n",
    "    print(f\"⚠️  {unmapped_count} cells with unmapped cell types\")\n",
    "    unmapped_types = combined_metadata[unmapped_mask][\"cell_type\"].value_counts()\n",
    "    print(f\"Top unmapped cell types:\\n{unmapped_types.head(10)}\")\n",
    "    \n",
    "    # Use original cell_type for unmapped\n",
    "    combined_metadata.loc[unmapped_mask, \"broad_cell_type\"] = combined_metadata.loc[unmapped_mask, \"cell_type\"]\n",
    "    print(\"✅ Used original cell_type for unmapped cells\")\n",
    "\n",
    "# SANITY CHECK 8: Analyze broad cell type distribution\n",
    "print(\"\\n--- Broad Cell Type Distribution ---\")\n",
    "broad_type_counts = combined_metadata[\"broad_cell_type\"].value_counts()\n",
    "print(f\"Number of broad cell types: {len(broad_type_counts)}\")\n",
    "print(f\"Top 10 broad cell types:\\n{broad_type_counts.head(10)}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== SHARED CELL TYPE ANALYSIS ===\")\n",
    "\n",
    "# Determine shared cell types with at least 50 cells per dataset\n",
    "min_cells_per_dataset = 50\n",
    "\n",
    "print(f\"Finding cell types with ≥{min_cells_per_dataset} cells per dataset...\")\n",
    "\n",
    "broad_counts = (\n",
    "    combined_metadata.groupby([\"dataset\", \"broad_cell_type\"])\n",
    "    .size().reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "pivot_counts = broad_counts.pivot(\n",
    "    index=\"broad_cell_type\", \n",
    "    columns=\"dataset\", \n",
    "    values=\"count\"\n",
    ").fillna(0)\n",
    "\n",
    "# Find shared cell types meeting threshold\n",
    "shared_mask = (pivot_counts >= min_cells_per_dataset).all(axis=1)\n",
    "shared_broad_cell_types = pivot_counts[shared_mask].index.tolist()\n",
    "\n",
    "print(f\"✅ Shared broad cell types (≥{min_cells_per_dataset} per dataset): {len(shared_broad_cell_types)}\")\n",
    "print(f\"Shared cell types: {shared_broad_cell_types}\")\n",
    "\n",
    "# SANITY CHECK 9: Detailed shared cell type analysis\n",
    "print(\"\\n--- Detailed Shared Cell Type Analysis ---\")\n",
    "print(\"Cell counts for shared types:\")\n",
    "shared_counts_df = pivot_counts.loc[shared_broad_cell_types].round(0).astype(int)\n",
    "print(shared_counts_df)\n",
    "\n",
    "# Calculate total cells in shared types\n",
    "total_shared_cells = combined_metadata[\n",
    "    combined_metadata[\"broad_cell_type\"].isin(shared_broad_cell_types)\n",
    "].shape[0]\n",
    "total_cells = len(combined_metadata)\n",
    "shared_percentage = (total_shared_cells / total_cells) * 100\n",
    "\n",
    "print(f\"\\nShared cell type summary:\")\n",
    "print(f\"  Total cells: {total_cells:,}\")\n",
    "print(f\"  Cells in shared types: {total_shared_cells:,}\")\n",
    "print(f\"  Percentage in shared types: {shared_percentage:.1f}%\")\n",
    "\n",
    "# Show cells excluded from shared analysis\n",
    "excluded_types = pivot_counts[~shared_mask]\n",
    "if len(excluded_types) > 0:\n",
    "    print(f\"\\nExcluded cell types ({len(excluded_types)}):\")\n",
    "    for cell_type in excluded_types.index[:10]:  # Show first 10\n",
    "        ab_count = excluded_types.loc[cell_type, \"allen_brain\"]\n",
    "        ts_count = excluded_types.loc[cell_type, \"tabula_sapiens\"] \n",
    "        print(f\"  {cell_type}: AB={ab_count:.0f}, TS={ts_count:.0f}\")\n",
    "    if len(excluded_types) > 10:\n",
    "        print(f\"  ... and {len(excluded_types) - 10} more\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== SAVING METADATA ===\")\n",
    "\n",
    "# Output path\n",
    "output_path = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\"\n",
    "\n",
    "# Create output directory if needed\n",
    "output_dir = os.path.dirname(output_path)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# SANITY CHECK 10: Pre-save validation\n",
    "print(\"--- Pre-save Validation ---\")\n",
    "print(f\"Final metadata shape: {combined_metadata.shape}\")\n",
    "print(f\"Columns: {list(combined_metadata.columns)}\")\n",
    "\n",
    "# Check for missing values in critical columns\n",
    "critical_cols = [\"cell_id\", \"dataset\", \"broad_cell_type\"]\n",
    "for col in critical_cols:\n",
    "    missing = combined_metadata[col].isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"❌ {missing} missing values in critical column '{col}'\")\n",
    "    else:\n",
    "        print(f\"✅ No missing values in '{col}'\")\n",
    "\n",
    "# Check for duplicate cell IDs\n",
    "total_cell_ids = len(combined_metadata)\n",
    "unique_cell_ids = combined_metadata[\"cell_id\"].nunique()\n",
    "if total_cell_ids != unique_cell_ids:\n",
    "    duplicates = total_cell_ids - unique_cell_ids\n",
    "    print(f\"❌ {duplicates} duplicate cell IDs found!\")\n",
    "    \n",
    "    # Show duplicate examples\n",
    "    dup_ids = combined_metadata[combined_metadata[\"cell_id\"].duplicated()][\"cell_id\"].head(3)\n",
    "    print(f\"Example duplicates: {dup_ids.tolist()}\")\n",
    "else:\n",
    "    print(f\"✅ All {total_cell_ids:,} cell IDs are unique\")\n",
    "\n",
    "# Save metadata\n",
    "try:\n",
    "    combined_metadata.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "    file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
    "    print(f\"✅ Metadata saved to: {output_path}\")\n",
    "    print(f\"File size: {file_size:.1f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving metadata: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de94b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FILTERING JUNCTION FILES ===\n",
      "--- Junction File Validation ---\n",
      "✅ Allen Brain junction list file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_20250920.txt\n",
      "✅ Tabula Sapiens junction list file found: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_20250920.txt\n",
      "Valid cell IDs for filtering: 90,918\n",
      "\n",
      "--- Filtering Allen Brain Junction Files ---\n",
      "Total junction files in list: 50,625\n",
      "Junction filtering results for Allen Brain:\n",
      "  Original files: 50,625\n",
      "  Files with metadata: 49,356\n",
      "  Files excluded: 1,269\n",
      "  Retention rate: 97.5%\n",
      "  Example excluded cell IDs: ['F1S4_170302_092_B01', 'F1S4_160831_074_H01', 'F2S4_170405_052_C01']\n",
      "✅ Filtered Allen Brain list saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\n",
      "✅ Verification passed: 49356 lines saved correctly\n",
      "\n",
      "--- Filtering Tabula Sapiens Junction Files ---\n",
      "Total junction files in list: 93,994\n",
      "Junction filtering results for Tabula Sapiens:\n",
      "  Original files: 93,994\n",
      "  Files with metadata: 39,229\n",
      "  Files excluded: 54,765\n",
      "  Retention rate: 41.7%\n",
      "  Example excluded cell IDs: ['TSP3_TSP3_smartseq2_B114669_B133703_Eye_noCornea.multi_star.output_raw.output_raw_per_TSP3_smartseq2_B114669_G3_B133703_G3_Eye_noCornea_Epithelial', 'TSP14_TSP14_smartseq2_B134540_B002625_LI_proximal.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134540_L9_B002625_L9_LI_proximal_Immune', 'TSP14_TSP14_smartseq2_B134101_D102110_Salivary_Sublingual.multi_star.output_raw.output_raw_per_TSP14_smartseq2_B134101_K21_D102110_K21_Salivary_Sublingual_Stromal']\n",
      "✅ Filtered Tabula Sapiens list saved to: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\n",
      "✅ Verification passed: 39229 lines saved correctly\n",
      "\n",
      "=== POST-PROCESSING VERIFICATION ===\n",
      "--- Metadata Verification ---\n",
      "✅ Metadata file readable: (90918, 8)\n",
      "✅ Shape matches original\n",
      "✅ Columns match original\n",
      "✅ All cell IDs unique in saved file\n",
      "\n",
      "=== FINAL PROCESSING SUMMARY ===\n",
      "🎉 METADATA PROCESSING PIPELINE COMPLETE!\n",
      "📅 Processing date: 2025-09-20\n",
      "\n",
      "📊 DATASET SUMMARY:\n",
      "               cell_id   donor broad_cell_type age    \n",
      "                 count nunique         nunique min max\n",
      "dataset                                               \n",
      "allen_brain      49417       3               9  43  54\n",
      "tabula_sapiens   41501      17              56  22  74\n",
      "\n",
      "🔬 CELL TYPE SUMMARY:\n",
      "Total broad cell types: 60\n",
      "Shared cell types (≥50 cells/dataset): 1\n",
      "Cells in shared types: 806 (0.9%)\n",
      "\n",
      "📁 OUTPUT FILES:\n",
      "✅ Combined metadata: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/human_metadata_combined.tsv\n",
      "✅ Allen Brain junction list: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\n",
      "✅ Tabula Sapiens junction list: /gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\n",
      "\n",
      "📈 JUNCTION FILTERING SUMMARY:\n",
      "allen_brain:\n",
      "  Original: 50,625\n",
      "  Retained: 49,356\n",
      "  Retention rate: 97.5%\n",
      "tabula_sapiens:\n",
      "  Original: 93,994\n",
      "  Retained: 39,229\n",
      "  Retention rate: 41.7%\n",
      "\n",
      "🎯 NEXT STEPS:\n",
      "1. Use filtered junction files for Leaflet and ATSEmapper pipeline\n",
      "2. Filter expression data to shared cell types for cross-dataset analysis\n",
      "3. Validate junction file existence before running downstream analysis\n",
      "\n",
      "✅ ALL PROCESSING COMPLETE WITH COMPREHENSIVE VALIDATION!\n",
      "================================================================================\n",
      "\n",
      "=== FINAL METADATA SAMPLE ===\n",
      "First 5 rows:\n",
      "                                             cell_id  donor sex  age  \\\n",
      "0  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "1  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "2  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "3  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "4  TSP14_TSP14_smartseq2_B134547_D101532_LI_proxi...  TSP14   M   59   \n",
      "\n",
      "          dataset           tissue  \\\n",
      "0  tabula_sapiens  Large_Intestine   \n",
      "1  tabula_sapiens  Large_Intestine   \n",
      "2  tabula_sapiens  Large_Intestine   \n",
      "3  tabula_sapiens  Large_Intestine   \n",
      "4  tabula_sapiens  Large_Intestine   \n",
      "\n",
      "                                     cell_type broad_cell_type  \n",
      "0  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "1  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "2  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "3                         paneth cell of colon   GI_Epithelial  \n",
      "4  enterocyte of epithelium of large intestine   GI_Epithelial  \n",
      "\n",
      "Final metadata statistics:\n",
      "Shape: (90918, 8)\n",
      "Memory usage: 46.6 MB\n",
      "\n",
      "Data types:\n",
      "  cell_id: object (90,918 unique values)\n",
      "  donor: object (20 unique values)\n",
      "  sex: object (2 unique values)\n",
      "  age: int64 (18 unique values)\n",
      "  dataset: object (2 unique values)\n",
      "  tissue: object (33 unique values)\n",
      "  cell_type: object (219 unique values)\n",
      "  broad_cell_type: object (60 unique values)\n",
      "\n",
      "Sample values for key columns:\n",
      "  dataset: {'allen_brain': 49417, 'tabula_sapiens': 41501}\n",
      "  sex: {'M': 48045, 'F': 42873}\n",
      "  tissue: {'MTG': 16155, 'V1C': 8052, 'A1C': 6703}\n",
      "  broad_cell_type: {'Excitatory_Neuron': 31229, 'Inhibitory_Neuron': 11125, 'General_Fibroblast': 4223}\n",
      "\n",
      "📋 Processing complete - all data validated and ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"\\n=== FILTERING JUNCTION FILES ===\")\n",
    "\n",
    "# Junction file paths\n",
    "ab_junc_filelist = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_20250920.txt\"\n",
    "ts_junc_filelist = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_20250920.txt\"\n",
    "\n",
    "# Output paths\n",
    "clean_ts = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_TS_subset.txt\"\n",
    "clean_ab = \"/gpfs/commons/groups/knowles_lab/Karin/Leaflet-analysis-WD/HUMAN_SPLICING_FOUNDATION/ATSE_mapper/junction_files_AB_subset.txt\"\n",
    "\n",
    "# Validate junction file lists exist\n",
    "print(\"--- Junction File Validation ---\")\n",
    "for filepath, desc in [(ab_junc_filelist, \"Allen Brain\"), (ts_junc_filelist, \"Tabula Sapiens\")]:\n",
    "    try:\n",
    "        validate_file_exists(filepath, f\"{desc} junction list\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  {desc} junction list not found, skipping junction filtering\")\n",
    "        continue\n",
    "\n",
    "# Get valid cell IDs from metadata\n",
    "valid_cell_ids = set(combined_metadata[\"cell_id\"])\n",
    "print(f\"Valid cell IDs for filtering: {len(valid_cell_ids):,}\")\n",
    "\n",
    "def filter_junction_paths(filelist_path, output_path, valid_ids, dataset_name):\n",
    "    \"\"\"Filter junction file paths to only include cells with metadata.\"\"\"\n",
    "    print(f\"\\n--- Filtering {dataset_name} Junction Files ---\")\n",
    "    \n",
    "    if not os.path.exists(filelist_path):\n",
    "        print(f\"⚠️  {dataset_name} junction list not found: {filelist_path}\")\n",
    "        return\n",
    "    \n",
    "    # Read junction file list\n",
    "    with open(filelist_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    print(f\"Total junction files in list: {len(lines):,}\")\n",
    "    \n",
    "    # Function to extract cell ID from file path\n",
    "    def extract_cell_id_from_path(path):\n",
    "        fname = Path(path).name\n",
    "        return fname.replace(\"_junctions_with_barcodes.bed\", \"\")\n",
    "    \n",
    "    # Filter paths and track statistics\n",
    "    filtered_lines = []\n",
    "    missing_metadata = []\n",
    "    \n",
    "    for path in lines:\n",
    "        cell_id = extract_cell_id_from_path(path)\n",
    "        if cell_id in valid_ids:\n",
    "            filtered_lines.append(path)\n",
    "        else:\n",
    "            missing_metadata.append(cell_id)\n",
    "    \n",
    "    # SANITY CHECK 11: Junction filtering validation\n",
    "    print(f\"Junction filtering results for {dataset_name}:\")\n",
    "    print(f\"  Original files: {len(lines):,}\")\n",
    "    print(f\"  Files with metadata: {len(filtered_lines):,}\")\n",
    "    print(f\"  Files excluded: {len(missing_metadata):,}\")\n",
    "    print(f\"  Retention rate: {len(filtered_lines)/len(lines)*100:.1f}%\")\n",
    "    \n",
    "    if len(missing_metadata) > 0:\n",
    "        print(f\"  Example excluded cell IDs: {missing_metadata[:3]}\")\n",
    "    \n",
    "    # Save filtered list\n",
    "    try:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(filtered_lines))\n",
    "        print(f\"✅ Filtered {dataset_name} list saved to: {output_path}\")\n",
    "        \n",
    "        # Verify saved file\n",
    "        with open(output_path) as f:\n",
    "            saved_lines = f.read().splitlines()\n",
    "        \n",
    "        if len(saved_lines) != len(filtered_lines):\n",
    "            print(f\"❌ ERROR: Saved file has {len(saved_lines)} lines, expected {len(filtered_lines)}\")\n",
    "        else:\n",
    "            print(f\"✅ Verification passed: {len(saved_lines)} lines saved correctly\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving filtered {dataset_name} list: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return {\n",
    "        'original_count': len(lines),\n",
    "        'filtered_count': len(filtered_lines),\n",
    "        'excluded_count': len(missing_metadata),\n",
    "        'retention_rate': len(filtered_lines)/len(lines) if len(lines) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Filter both junction file lists\n",
    "filtering_results = {}\n",
    "\n",
    "# Filter Allen Brain junctions\n",
    "if os.path.exists(ab_junc_filelist):\n",
    "    filtering_results['allen_brain'] = filter_junction_paths(\n",
    "        ab_junc_filelist, clean_ab, valid_cell_ids, \"Allen Brain\"\n",
    "    )\n",
    "\n",
    "# Filter Tabula Sapiens junctions  \n",
    "if os.path.exists(ts_junc_filelist):\n",
    "    filtering_results['tabula_sapiens'] = filter_junction_paths(\n",
    "        ts_junc_filelist, clean_ts, valid_cell_ids, \"Tabula Sapiens\"\n",
    "    )\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== POST-PROCESSING VERIFICATION ===\")\n",
    "\n",
    "# Verify saved metadata can be read back\n",
    "print(\"--- Metadata Verification ---\")\n",
    "try:\n",
    "    test_metadata = pd.read_csv(output_path, sep=\"\\t\")\n",
    "    print(f\"✅ Metadata file readable: {test_metadata.shape}\")\n",
    "    \n",
    "    # Check key properties\n",
    "    if test_metadata.shape == combined_metadata.shape:\n",
    "        print(\"✅ Shape matches original\")\n",
    "    else:\n",
    "        print(f\"❌ Shape mismatch: saved {test_metadata.shape} vs original {combined_metadata.shape}\")\n",
    "    \n",
    "    # Check column consistency\n",
    "    if list(test_metadata.columns) == list(combined_metadata.columns):\n",
    "        print(\"✅ Columns match original\")\n",
    "    else:\n",
    "        print(\"❌ Column mismatch detected\")\n",
    "    \n",
    "    # Check cell ID uniqueness\n",
    "    if test_metadata[\"cell_id\"].nunique() == len(test_metadata):\n",
    "        print(\"✅ All cell IDs unique in saved file\")\n",
    "    else:\n",
    "        print(\"❌ Duplicate cell IDs found in saved file\")\n",
    "        \n",
    "    del test_metadata  # Free memory\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error reading saved metadata: {e}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n=== FINAL PROCESSING SUMMARY ===\")\n",
    "print(\"🎉 METADATA PROCESSING PIPELINE COMPLETE!\")\n",
    "print(f\"📅 Processing date: {today}\")\n",
    "\n",
    "print(f\"\\n📊 DATASET SUMMARY:\")\n",
    "dataset_summary = combined_metadata.groupby(\"dataset\").agg({\n",
    "    'cell_id': 'count',\n",
    "    'donor': 'nunique', \n",
    "    'broad_cell_type': 'nunique',\n",
    "    'age': ['min', 'max']\n",
    "}).round(1)\n",
    "\n",
    "print(dataset_summary)\n",
    "\n",
    "print(f\"\\n🔬 CELL TYPE SUMMARY:\")\n",
    "print(f\"Total broad cell types: {combined_metadata['broad_cell_type'].nunique():,}\")\n",
    "print(f\"Shared cell types (≥{min_cells_per_dataset} cells/dataset): {len(shared_broad_cell_types)}\")\n",
    "print(f\"Cells in shared types: {total_shared_cells:,} ({shared_percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT FILES:\")\n",
    "print(f\"✅ Combined metadata: {output_path}\")\n",
    "if 'allen_brain' in filtering_results:\n",
    "    print(f\"✅ Allen Brain junction list: {clean_ab}\")\n",
    "if 'tabula_sapiens' in filtering_results:\n",
    "    print(f\"✅ Tabula Sapiens junction list: {clean_ts}\")\n",
    "\n",
    "print(f\"\\n📈 JUNCTION FILTERING SUMMARY:\")\n",
    "for dataset, results in filtering_results.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Original: {results['original_count']:,}\")\n",
    "    print(f\"  Retained: {results['filtered_count']:,}\")\n",
    "    print(f\"  Retention rate: {results['retention_rate']*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n🎯 NEXT STEPS:\")\n",
    "print(\"1. Use filtered junction files for Leaflet and ATSEmapper pipeline\")\n",
    "print(\"2. Filter expression data to shared cell types for cross-dataset analysis\")\n",
    "print(\"3. Validate junction file existence before running downstream analysis\")\n",
    "\n",
    "print(\"\\n✅ ALL PROCESSING COMPLETE WITH COMPREHENSIVE VALIDATION!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %%\n",
    "# Optional: Display final metadata sample and statistics\n",
    "print(\"\\n=== FINAL METADATA SAMPLE ===\")\n",
    "print(\"First 5 rows:\")\n",
    "print(combined_metadata.head())\n",
    "\n",
    "print(f\"\\nFinal metadata statistics:\")\n",
    "print(f\"Shape: {combined_metadata.shape}\")\n",
    "print(f\"Memory usage: {combined_metadata.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Show data types\n",
    "print(f\"\\nData types:\")\n",
    "for col in combined_metadata.columns:\n",
    "    dtype = combined_metadata[col].dtype\n",
    "    unique_vals = combined_metadata[col].nunique()\n",
    "    print(f\"  {col}: {dtype} ({unique_vals:,} unique values)\")\n",
    "\n",
    "# Show sample values for categorical columns\n",
    "categorical_cols = ['dataset', 'sex', 'tissue', 'broad_cell_type']\n",
    "print(f\"\\nSample values for key columns:\")\n",
    "for col in categorical_cols:\n",
    "    if col in combined_metadata.columns:\n",
    "        values = combined_metadata[col].value_counts().head(3)\n",
    "        print(f\"  {col}: {dict(values)}\")\n",
    "\n",
    "print(f\"\\n📋 Processing complete - all data validated and ready for analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeafletSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
