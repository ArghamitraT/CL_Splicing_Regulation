_wandb:
    value:
        cli_version: 0.18.7
        m:
            - "1": lr-SGD
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
        python_version: 3.10.15
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 50
                - 55
                - 71
                - 106
            "2":
                - 1
                - 11
                - 41
                - 49
                - 50
                - 55
                - 71
                - 106
            "3":
                - 7
                - 13
                - 16
                - 23
                - 55
                - 66
            "4": 3.10.15
            "5": 0.18.7
            "6": 4.46.2
            "8":
                - 5
            "12": 0.18.7
            "13": linux-x86_64
callbacks:
    value:
        learning_rate_monitor:
            _target_: lightning.pytorch.callbacks.LearningRateMonitor
            logging_interval: step
        model_checkpoint:
            _target_: lightning.pytorch.callbacks.ModelCheckpoint
            dirpath: checkpoints/
            filename: introns_cl/ResNet1D/199/best-checkpoint
            mode: min
            monitor: val_loss
            save_last: true
            save_top_k: 1
            verbose: true
config:
    value: '{''wandb'': {''api_key'': ''6c6c3f0e63c48c1d9b78f03948c5eb5a4f828a66'', ''dir'': ''./wandb/''}, ''logger'': {''_target_'': ''lightning.pytorch.loggers.WandbLogger'', ''name'': ''cl_trial_20251019_235318'', ''id'': ''${task._name_}-${.name}'', ''project'': ''INTRONS_CL'', ''group'': ''${task._name_}'', ''save_dir'': ''${wandb.dir}'', ''log_model'': True, ''notes'': ''try'', ''settings'': {''init_timeout'': 600}}, ''embedder'': {''bp_per_token'': 1, ''embedding_dim'': 768, ''seq_len'': 201, ''vocab_size'': 11, ''rcps'': False, ''maxpooling'': True, ''size'': 50, ''_name_'': ''ResNet1D'', ''name_or_path'': ''ResNet1D''}, ''dataset'': {''seq_len'': 199, ''train_data_file'': ''/mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/train_5primeIntron_filtered.pkl'', ''val_data_file'': ''/mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/val_5primeIntron_filtered.pkl'', ''test_data_file'': ''/mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/test_5primeIntron_filtered.pkl'', ''batch_size_per_device'': ''${div_up:${task.global_batch_size}, ${eval:${trainer.devices}  * ${trainer.num_nodes}}}'', ''num_workers'': ''${optimal_workers:}'', ''train_ratio'': 0.8, ''val_ratio'': 0.1, ''test_ratio'': None, ''cache_dir'': ''../data'', ''n_augmentations'': 3, ''fixed_species'': False}, ''task'': {''_name_'': ''introns_cl'', ''metrics'': [''accuracy''], ''val_check_interval'': 0.5, ''global_batch_size'': 2048}, ''trainer'': {''_target_'': ''lightning.pytorch.Trainer'', ''max_epochs'': 2, ''callbacks'': None, ''devices'': 1, ''log_every_n_steps'': 1, ''limit_train_batches'': 1.0, ''limit_val_batches'': 1.0, ''val_check_interval'': 1.0, ''gradient_clip_val'': 1.0, ''precision'': ''16-mixed'', ''num_sanity_val_steps'': 0, ''num_nodes'': 1, ''accumulate_grad_batches'': ''${div_up:${task.global_batch_size}, ${eval:${trainer.devices} * ${dataset.batch_size_per_device} * ${trainer.num_nodes}}}''}, ''callbacks'': {''model_checkpoint'': {''_target_'': ''lightning.pytorch.callbacks.ModelCheckpoint'', ''dirpath'': ''checkpoints/'', ''filename'': ''${task._name_}/${embedder._name_}/${dataset.seq_len}/best-checkpoint'', ''save_top_k'': 1, ''save_last'': True, ''verbose'': True, ''monitor'': ''val_loss'', ''mode'': ''min''}, ''learning_rate_monitor'': {''_target_'': ''lightning.pytorch.callbacks.LearningRateMonitor'', ''logging_interval'': ''step''}}, ''tokenizer'': {''_target_'': ''src.tokenizers.custom.CustomTokenizer'', ''seq_len'': 400, ''model_max_length'': ''${.seq_len}'', ''padding'': ''longest''}, ''loss'': {''_target_'': ''src.loss.weighted_supcon.weightedSupConLoss'', ''temperature'': 0.5, ''correlation_dir'': ''${oc.env:CONTRASTIVE_ROOT}/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data''}, ''model'': {''name_or_path'': ''simclr'', ''hidden_dim'': 512, ''projection_dim'': 128}, ''optimizer'': {''_target_'': ''torch.optim.SGD'', ''lr'': 0.01, ''momentum'': 0.9, ''weight_decay'': 0.0}}'
dataset:
    value:
        batch_size_per_device: 2048
        cache_dir: ../data
        fixed_species: false
        n_augmentations: 3
        num_workers: 8
        seq_len: 199
        test_data_file: /mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/test_5primeIntron_filtered.pkl
        test_ratio: null
        train_data_file: /mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/train_5primeIntron_filtered.pkl
        train_ratio: 0.8
        val_data_file: /mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data/val_5primeIntron_filtered.pkl
        val_ratio: 0.1
embedder:
    value:
        _name_: ResNet1D
        bp_per_token: 1
        embedding_dim: 768
        maxpooling: true
        name_or_path: ResNet1D
        rcps: false
        seq_len: 201
        size: 50
        vocab_size: 11
logger:
    value:
        _target_: lightning.pytorch.loggers.WandbLogger
        group: introns_cl
        id: introns_cl-cl_trial_20251019_235318
        log_model: true
        name: cl_trial_20251019_235318
        notes: try
        project: INTRONS_CL
        save_dir: ./wandb/
        settings:
            init_timeout: 600
loss:
    value:
        _target_: src.loss.weighted_supcon.weightedSupConLoss
        correlation_dir: /mnt/home/at3836/Contrastive_Learning/data/final_data/intronExonSeq_multizAlignment_noDash/trainTestVal_data
        temperature: 0.5
model:
    value:
        hidden_dim: 512
        name_or_path: simclr
        projection_dim: 128
optimizer:
    value:
        _target_: torch.optim.SGD
        lr: 0.01
        momentum: 0.9
        weight_decay: 0
task:
    value:
        _name_: introns_cl
        global_batch_size: 2048
        metrics:
            - accuracy
        val_check_interval: 0.5
tokenizer:
    value:
        _target_: src.tokenizers.custom.CustomTokenizer
        model_max_length: 400
        padding: longest
        seq_len: 400
trainer:
    value:
        _target_: lightning.pytorch.Trainer
        accumulate_grad_batches: 1
        callbacks: null
        devices: 1
        gradient_clip_val: 1
        limit_train_batches: 1
        limit_val_batches: 1
        log_every_n_steps: 1
        max_epochs: 2
        num_nodes: 1
        num_sanity_val_steps: 0
        precision: 16-mixed
        val_check_interval: 1
wandb:
    value:
        api_key: 6c6c3f0e63c48c1d9b78f03948c5eb5a4f828a66
        dir: ./wandb/
