{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559c6f57-989f-427a-9ed1-2bd2bd1bf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Set a nice style for the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "import os\n",
    "\n",
    "def get_figures_path():\n",
    "    target_suffix = os.path.join(\"Contrastive_Learning\", \"code\", \"ML_model\", \"figures\")\n",
    "    cwd = os.path.abspath(os.getcwd())\n",
    "    parts = cwd.split(os.sep)\n",
    "    for i in range(len(parts), 0, -1):\n",
    "        candidate = os.sep.join(parts[:i])\n",
    "        test_path = os.path.join(candidate, target_suffix)\n",
    "        if os.path.isdir(test_path):\n",
    "            return test_path\n",
    "    raise FileNotFoundError(f\"Path ending with '{target_suffix}' not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da964eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_single_run_results(results_folder: str, run_name: str=None) -> pd.DataFrame:\n",
    "    \"\"\"Loads the Spearman correlation results for a single, specified run.\"\"\"\n",
    "\n",
    "    if run_name:\n",
    "        filepath = Path(results_folder) / run_name / \"tsplice_spearman_by_tissue.tsv\"\n",
    "    else:\n",
    "        filepath = Path(results_folder) / \"tsplice_spearman_by_tissue.tsv\"\n",
    "    print(f\"Loading single run results from: {filepath}\")\n",
    "    \n",
    "    # Load the tab-separated file\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    \n",
    "    # --- ADDED THIS STEP ---\n",
    "    # Standardize column names to match the expected format ('spearman_rho_...')\n",
    "    # This handles files that might have the older 'spearman_psi' naming.\n",
    "    rename_dict = {\n",
    "        'spearman_psi': 'spearman_rho_psi',\n",
    "        'spearman_delta': 'spearman_rho_delta_psi'\n",
    "    }\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c26ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_single_model_df(df, metric, model_name):\n",
    "    \"\"\"Internal helper to prepare one DataFrame for comparison.\"\"\"\n",
    "    is_averaged = f'mean_{metric}' in df.columns\n",
    "    metric_col = f'mean_{metric}' if is_averaged else metric\n",
    "    std_col = f'std_{metric}' if is_averaged else None\n",
    "\n",
    "    cols_to_select = ['tissue', metric_col]\n",
    "    if is_averaged and std_col and std_col in df.columns:\n",
    "        cols_to_select.append(std_col)\n",
    "    \n",
    "    plot_df = df[cols_to_select].copy()\n",
    "    plot_df.rename(columns={metric_col: model_name}, inplace=True)\n",
    "    return plot_df\n",
    "\n",
    "def prepare_grouped_plot_data(df1, df2, df3, metric, model1_name, model2_name, model3_name):\n",
    "    \"\"\"\n",
    "    Prepares and merges data from three models for a grouped bar plot.\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): DataFrame for the first model.\n",
    "        df2 (pd.DataFrame): DataFrame for the second model.\n",
    "        metric (str): The base metric name (e.g., 'spearman_rho_psi').\n",
    "        model1_name (str): Custom name for the first model.\n",
    "        model2_name (str): Custom name for the second model.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing:\n",
    "            - comparison_df: The merged, wide-format DataFrame.\n",
    "            - melted_df: The long-format DataFrame ready for seaborn.\n",
    "    \"\"\"\n",
    "    model1_plot_df = _prepare_single_model_df(df1, metric, model1_name)\n",
    "    model2_plot_df = _prepare_single_model_df(df2, metric, model2_name)\n",
    "    model3_plot_df = _prepare_single_model_df(df3, metric, model3_name)\n",
    "\n",
    "    # Merge the three prepared dataframes\n",
    "    comparison_df = (\n",
    "    pd.merge(model1_plot_df, model2_plot_df, on='tissue', how='inner')\n",
    "      .merge(model3_plot_df, on='tissue', how='inner')\n",
    ")\n",
    "    # \"Melt\" the dataframe for seaborn plotting\n",
    "    melted_df = comparison_df.melt(id_vars='tissue', value_vars=[model1_name, model2_name, model3_name], \n",
    "                                   var_name='Model', value_name='Spearman œÅ')\n",
    "    \n",
    "    return comparison_df, melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34bab0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_comparison(comparison_df, melted_df, title,\n",
    "                            model1_name, model2_name, model3_name,\n",
    "                            save_path=None):\n",
    "    \"\"\"\n",
    "    Generates a grouped bar plot with improved clarity and readable labels.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    ax = sns.barplot(\n",
    "        data=melted_df,\n",
    "        x='tissue', y='Spearman œÅ', hue='Model',\n",
    "        palette={\n",
    "            model1_name: 'lightgray',\n",
    "            model2_name: 'mediumseagreen',\n",
    "            model3_name: 'cornflowerblue'\n",
    "        },\n",
    "        # edgecolor='black', linewidth=0.3,  # crisper bars\n",
    "        linewidth=0.4,  # crisper bars\n",
    "        width=0.7                         # slightly wider bars\n",
    "    )\n",
    "\n",
    "    # --- Optional error bars if present ---\n",
    "    std_col = [col for col in comparison_df.columns if col.startswith('std_')]\n",
    "    if std_col:\n",
    "        error_map = comparison_df.set_index('tissue')[std_col[0]].to_dict()\n",
    "        for patch in ax.patches:\n",
    "            center_x = patch.get_x() + patch.get_width() / 2\n",
    "            height = patch.get_height()\n",
    "            tissue_idx = int(center_x // len(melted_df['Model'].unique()))\n",
    "            tissue_name = ax.get_xticklabels()[tissue_idx].get_text() if tissue_idx < len(ax.get_xticklabels()) else None\n",
    "            if tissue_name in error_map:\n",
    "                ax.errorbar(center_x, height, yerr=error_map[tissue_name],\n",
    "                            fmt='none', capsize=3, color='black', lw=0.8)\n",
    "\n",
    "    # --- Styling for clarity ---\n",
    "    ax.set_title(title, fontsize=16, pad=20, weight='bold')\n",
    "    ax.set_ylabel('Spearman œÅ', fontsize=13)\n",
    "    ax.set_xlabel('Tissue', fontsize=13)\n",
    "\n",
    "    # Rotate x-tick labels for readability\n",
    "    plt.xticks(rotation=90, ha='center', fontsize=9)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "    # Clean legend: move to top center, horizontal layout\n",
    "    plt.legend(title='Model', fontsize=10, title_fontsize=11,\n",
    "               loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3,\n",
    "               frameon=False)\n",
    "\n",
    "    # Add a subtle grid\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Figure saved to: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_average_across_tissues_2models(\n",
    "    df1, df2, df3, model1_name, model2_name, model3_name,\n",
    "    metric, save_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute and plot the average metric across all tissues for 2 models.\n",
    "    Each dataframe must contain 'tissue' and the target metric column.\n",
    "\n",
    "    Args:\n",
    "        df1, df2, df3: DataFrames containing per-tissue metric values.\n",
    "        model1_name, model2_name, model3_name: Model labels for legend.\n",
    "        metric: str, metric column name (e.g. 'spearman_rho_psi').\n",
    "        save_path: Optional path to save the figure.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "\n",
    "    # Compute averages\n",
    "    avg_df = pd.DataFrame({\n",
    "        'Model': [model1_name, model2_name, model3_name],\n",
    "        'Average': [\n",
    "            df1[metric].mean(),\n",
    "            df2[metric].mean(),\n",
    "            df3[metric].mean()\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Determine dynamic y-axis range\n",
    "    y_min = max(0, avg_df[\"Average\"].min() - 0.05)\n",
    "    y_max = min(1.0, avg_df[\"Average\"].max() + 0.1)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.barplot(data=avg_df, x='Model', y='Average', palette='viridis')\n",
    "\n",
    "    plt.ylabel(f\"Average {metric.replace('_', ' ').title()}\")\n",
    "    plt.title(f\"Average {metric.replace('_', ' ').title()} Across All Tissues\")\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xticks(rotation=25, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"‚úÖ Saved average plot: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################ 2 user inputs WITH Baseline ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea2810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assuming imports and previous helper functions are defined ---\n",
    "# Make sure load_Baseline_results, load_single_run_results, load_and_average_all_runs are available\n",
    "\n",
    "# --- Configuration ---\n",
    "# --- Folder 1 ---\n",
    "result_file_name1 = \"exprmnt_2025_11_05__01_50_41\" # EMPRAIPsi_TS_noCL_300bp_rerun_codeChange_2025_11_05__01_50_41\n",
    "model1_user_name_norun = 'TS_noCL_300bp_rerun_codeChange'\n",
    "model1_user_name = f'{model1_user_name_norun}_ensembled'\n",
    "model1_user_avg_name = f'{model1_user_name_norun}_avg'\n",
    "model1_runNumber = None\n",
    "\n",
    "\n",
    "# --- Folder 2 (Define paths and names for your second experiment) ---\n",
    "result_file_name2 =  \"exprmnt_2025_11_05__01_52_25\" # EMPRAIPsi_TS_CLSwpd_300bp_10Aug_rerun_codeChange_2025_11_05__01_52_25\n",
    "model2_user_name_norun = 'TS_CLSwpd_300bp_10Aug'\n",
    "model2_user_name = f'{model2_user_name_norun}_ensembled'\n",
    "model2_user_avg_name = f'{model2_user_name_norun}_avg'\n",
    "model2_runNumber = None\n",
    "\n",
    "\n",
    "# --- Folder 3 (Define paths and names for your second experiment) ---\n",
    "result_file_name3 =  \"exprmnt_2025_11_05__01_52_25\" # EMPRAIPsi_TS_CLSwpd_300bp_10Aug_rerun_codeChange_2025_11_05__01_52_25\n",
    "model3_user_name_norun = 'TS_CLSwpd_300bp_10Aug_ignore'\n",
    "model3_user_name = f'{model3_user_name_norun}_ensembled'\n",
    "model3_user_avg_name = f'{model3_user_name_norun}_avg'\n",
    "model3_runNumber = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbd665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Base Dirs ---\n",
    "main_dir = \"/gpfs/commons/home/atalukder/Contrastive_Learning/files/results/\"\n",
    "# main_dir = \"/mnt/home/at3836/Contrastive_Learning/files/results/\"\n",
    "fig_maindir = get_figures_path()\n",
    "trimester = time.strftime(\"_%Y_%m_%d__%H_%M_%S\")\n",
    "\n",
    "# --- Full Paths ---\n",
    "RESULTS_FOLDER_PATH1 = f\"{main_dir}/{result_file_name1}/ensemble_evaluation_from_valdiation/test_set_evaluation\" # <<< Path for Folder 1\n",
    "RESULTS_FOLDER_PATH2 = f\"{main_dir}/{result_file_name2}/ensemble_evaluation_from_valdiation/test_set_evaluation\" # <<< Path for Folder 2\n",
    "RESULTS_FOLDER_PATH3 = f\"{main_dir}/{result_file_name3}/ensemble_evaluation_from_valdiation/test_set_evaluation\" # <<< Path for Folder 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f139a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "Loading single run results from: /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/exprmnt_2025_11_05__01_50_41/ensemble_evaluation_from_valdiation/test_set_evaluation/tsplice_spearman_by_tissue.tsv\n",
      "Loaded Folder 1: exprmnt_2025_11_05__01_50_41\n",
      "Loading single run results from: /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/exprmnt_2025_11_05__01_52_25/ensemble_evaluation_from_valdiation/test_set_evaluation/tsplice_spearman_by_tissue.tsv\n",
      "Loaded Folder 2: exprmnt_2025_11_05__01_52_25\n",
      "Loading single run results from: /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/exprmnt_2025_11_05__01_52_25/ensemble_evaluation_from_valdiation/test_set_evaluation/tsplice_spearman_by_tissue.tsv\n",
      "Loaded Folder 3: exprmnt_2025_11_05__01_52_25\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "print(\"--- Loading Data ---\")\n",
    "try:\n",
    "    \n",
    "    single_run_1_results = load_single_run_results(RESULTS_FOLDER_PATH1)\n",
    "    # averaged_run_1_results = load_and_average_all_runs(RESULTS_FOLDER_PATH1)\n",
    "    print(f\"Loaded Folder 1: {result_file_name1}\")\n",
    "\n",
    "    # Results for Folder 2 (Single Run & Averaged)\n",
    "    single_run_2_results = load_single_run_results(RESULTS_FOLDER_PATH2)\n",
    "    # averaged_run_2_results = load_and_average_all_runs(RESULTS_FOLDER_PATH2)\n",
    "    print(f\"Loaded Folder 2: {result_file_name2}\")\n",
    "\n",
    "    # Results for Folder 3 (Single Run & Averaged)\n",
    "    single_run_3_results = load_single_run_results(RESULTS_FOLDER_PATH3)\n",
    "    # averaged_run_3_results = load_and_average_all_runs(RESULTS_FOLDER_PATH3)\n",
    "    print(f\"Loaded Folder 3: {result_file_name3}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during loading: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e12ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined DataFrame with 112 tissues\n",
      "                                              tissue  spearman_rho_delta_psi\n",
      "0  HR positive luminal epithelial cell of mammary...                0.119616\n",
      "1                      acinar cell of salivary gland                0.104541\n",
      "2          activated cd4-positive, alpha-beta t cell               -0.049255\n",
      "3                             adventitial fibroblast                0.060226\n",
      "4                          airway smooth muscle cell                0.110386\n",
      "‚úÖ Merged successfully: 112 matched tissues\n",
      "\n",
      "üìä Spearman correlation summary by sample-size class:\n",
      "\n",
      "  SampleClass  count     mean      std       min      max   median\n",
      "  High sample     19 0.042150 0.026167 -0.001402 0.085408 0.036928\n",
      "   Low sample     18 0.026949 0.051360 -0.062660 0.123697 0.020092\n",
      "Medium sample     75 0.030762 0.049647 -0.060862 0.119616 0.025050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load Spearman results ===\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load both series ---\n",
    "spearman_series = single_run_1_results[\"spearman_rho_delta_psi\"]\n",
    "tissue_series   = single_run_1_results.get(\"tissue\")  # or the correct key once confirmed\n",
    "\n",
    "if tissue_series is None:\n",
    "    raise KeyError(\"No tissue names found in single_run_1_results. Check available keys.\")\n",
    "\n",
    "# --- Build the dataframe ---\n",
    "spearman_df = pd.DataFrame({\n",
    "    \"tissue\": tissue_series,\n",
    "    \"spearman_rho_delta_psi\": spearman_series\n",
    "})\n",
    "print(f\"‚úÖ Combined DataFrame with {spearman_df.shape[0]} tissues\")\n",
    "print(spearman_df.head())\n",
    "\n",
    "# --- Load tissue class info ---\n",
    "tissue_class_df = pd.read_csv(\"/gpfs/commons/home/atalukder/Contrastive_Learning/data/TS_data/tabula_sapiens/final_data/tissue_counts_detailed_ExonBinPsi.csv\")[\n",
    "    [\"Tissue\", \"SampleClass\"]\n",
    "].rename(columns={\"Tissue\": \"tissue\", \"SampleClass\": \"SampleClass\"})\n",
    "\n",
    "# --- Merge on tissue name ---\n",
    "spearman_df[\"tissue\"] = spearman_df[\"tissue\"].astype(str).str.strip()\n",
    "tissue_class_df[\"tissue\"] = tissue_class_df[\"tissue\"].astype(str).str.strip()\n",
    "\n",
    "merged = pd.merge(spearman_df, tissue_class_df, on=\"tissue\", how=\"inner\")\n",
    "print(f\"‚úÖ Merged successfully: {merged.shape[0]} matched tissues\")\n",
    "\n",
    "# --- Compute summary stats ---\n",
    "summary = (\n",
    "    merged.groupby(\"SampleClass\")[\"spearman_rho_delta_psi\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\", \"median\"])\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nüìä Spearman correlation summary by sample-size class:\\n\")\n",
    "print(summary.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d449ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined DataFrame with 112 tissues\n",
      "                                              tissue  spearman_rho_delta_psi\n",
      "0  HR positive luminal epithelial cell of mammary...                0.141064\n",
      "1                      acinar cell of salivary gland                0.152143\n",
      "2          activated cd4-positive, alpha-beta t cell               -0.100472\n",
      "3                             adventitial fibroblast                0.111329\n",
      "4                          airway smooth muscle cell                0.132563\n",
      "‚úÖ Merged successfully: 112 matched tissues\n",
      "\n",
      "üìä Spearman correlation summary by sample-size class:\n",
      "\n",
      "  SampleClass  count      mean      std       min      max    median\n",
      "  High sample     19  0.093196 0.040231  0.017807 0.160429  0.099084\n",
      "   Low sample     18 -0.010300 0.062237 -0.132298 0.132563 -0.015184\n",
      "Medium sample     75  0.043853 0.095964 -0.107307 0.207166  0.058665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load Spearman results ===\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load both series ---\n",
    "spearman_series = single_run_2_results[\"spearman_rho_delta_psi\"]\n",
    "tissue_series   = single_run_2_results.get(\"tissue\")  # or the correct key once confirmed\n",
    "\n",
    "if tissue_series is None:\n",
    "    raise KeyError(\"No tissue names found in single_run_2_results. Check available keys.\")\n",
    "\n",
    "# --- Build the dataframe ---\n",
    "spearman_df = pd.DataFrame({\n",
    "    \"tissue\": tissue_series,\n",
    "    \"spearman_rho_delta_psi\": spearman_series\n",
    "})\n",
    "print(f\"‚úÖ Combined DataFrame with {spearman_df.shape[0]} tissues\")\n",
    "print(spearman_df.head())\n",
    "\n",
    "# --- Load tissue class info ---\n",
    "tissue_class_df = pd.read_csv(\"/gpfs/commons/home/atalukder/Contrastive_Learning/data/TS_data/tabula_sapiens/final_data/tissue_counts_detailed_ExonBinPsi.csv\")[\n",
    "    [\"Tissue\", \"SampleClass\"]\n",
    "].rename(columns={\"Tissue\": \"tissue\", \"SampleClass\": \"SampleClass\"})\n",
    "\n",
    "# --- Merge on tissue name ---\n",
    "spearman_df[\"tissue\"] = spearman_df[\"tissue\"].astype(str).str.strip()\n",
    "tissue_class_df[\"tissue\"] = tissue_class_df[\"tissue\"].astype(str).str.strip()\n",
    "\n",
    "merged = pd.merge(spearman_df, tissue_class_df, on=\"tissue\", how=\"inner\")\n",
    "print(f\"‚úÖ Merged successfully: {merged.shape[0]} matched tissues\")\n",
    "\n",
    "# --- Compute summary stats ---\n",
    "summary = (\n",
    "    merged.groupby(\"SampleClass\")[\"spearman_rho_delta_psi\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\", \"median\"])\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"\\nüìä Spearman correlation summary by sample-size class:\\n\")\n",
    "print(summary.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c974e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open(\"single_run_1_results_sp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(single_run_1_results, f)\n",
    "\n",
    "with open(\"single_run_2_results_sp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(single_run_2_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d31ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 20\u001b[0m baseline_df  \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_df\u001b[49m(single_run_1_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m clade_df     \u001b[38;5;241m=\u001b[39m prepare_df(single_run_2_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLADES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# === Step 2: Concatenate both ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 20\u001b[0m baseline_df  \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_df\u001b[49m(single_run_1_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m clade_df     \u001b[38;5;241m=\u001b[39m prepare_df(single_run_2_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLADES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# === Step 2: Concatenate both ===\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/Myjupyterenv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Myjupyterenv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/Myjupyterenv/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/Myjupyterenv/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import time\n",
    "# from plotnine.themes.elements import element_blank, margin\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# === Step 1: Load both results ===\n",
    "def prepare_df(results, label):\n",
    "    \"\"\"Return tidy dataframe with tissue, rho, and SampleClass.\"\"\"\n",
    "    spearman_series = results[\"spearman_rho_delta_psi\"]\n",
    "    tissue_series   = results.get(\"tissue\")\n",
    "    if tissue_series is None:\n",
    "        raise KeyError(\"No tissue names found in results.\")\n",
    "    df = pd.DataFrame({\n",
    "        \"tissue\": tissue_series,\n",
    "        \"spearman_rho_delta_psi\": spearman_series\n",
    "    })\n",
    "    df[\"Model\"] = label\n",
    "    return df\n",
    "\n",
    "baseline_df  = prepare_df(single_run_1_results, \"Baseline\")\n",
    "clade_df     = prepare_df(single_run_2_results, \"CLADES\")\n",
    "\n",
    "# === Step 2: Concatenate both ===\n",
    "all_df = pd.concat([baseline_df, clade_df], ignore_index=True)\n",
    "\n",
    "# === Step 3: Load tissue classification ===\n",
    "tissue_class_df = pd.read_csv(\n",
    "    \"/gpfs/commons/home/atalukder/Contrastive_Learning/data/TS_data/tabula_sapiens/final_data/tissue_counts_detailed_ExonBinPsi.csv\"\n",
    ")[[\"Tissue\", \"SampleClass\"]].rename(columns={\"Tissue\": \"tissue\"})\n",
    "\n",
    "# Clean merge keys\n",
    "all_df[\"tissue\"] = all_df[\"tissue\"].astype(str).str.strip()\n",
    "tissue_class_df[\"tissue\"] = tissue_class_df[\"tissue\"].astype(str).str.strip()\n",
    "\n",
    "# --- Normalize class names ---\n",
    "merged = pd.merge(all_df, tissue_class_df, on=\"tissue\", how=\"inner\")\n",
    "merged[\"SampleClass\"] = (\n",
    "    merged[\"SampleClass\"]\n",
    "    .str.replace(\" sample\", \"\", case=False)\n",
    "    .str.strip()\n",
    "    .str.capitalize()\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Merged successfully: {merged.shape[0]} entries\")\n",
    "\n",
    "# === Step 4: Compute mean ¬± std per class per model ===\n",
    "summary = (\n",
    "    merged.groupby([\"SampleClass\", \"Model\"])[\"spearman_rho_delta_psi\"]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure class order for x-axis\n",
    "summary[\"SampleClass\"] = pd.Categorical(\n",
    "    summary[\"SampleClass\"], categories=[\"Low\", \"Medium\", \"High\"], ordered=True\n",
    ")\n",
    "\n",
    "# Ensure model order\n",
    "summary[\"Model\"] = pd.Categorical(summary[\"Model\"], [\"Baseline\", \"CLADES\"], ordered=True)\n",
    "\n",
    "# === Step 5: Plot ===\n",
    "from plotnine import (\n",
    "    ggplot, aes, geom_bar, geom_errorbar, scale_x_discrete,\n",
    "    scale_fill_manual, labs, theme_bw, theme,\n",
    "    element_text, position_dodge,element_rect\n",
    ")\n",
    "from plotnine.themes.elements import element_blank\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = (\n",
    "    ggplot(summary, aes(x=\"SampleClass\", y=\"mean\", fill=\"Model\"))\n",
    "    + geom_bar(stat=\"identity\", position=position_dodge(width=0.5), width=0.5)  # ‚úÖ balanced\n",
    "    + geom_errorbar(\n",
    "        aes(ymin=summary[\"mean\"] - summary[\"std\"], ymax=summary[\"mean\"] + summary[\"std\"]),\n",
    "        width=0.05, position=position_dodge(width=0.45)\n",
    "    )\n",
    "    + scale_fill_manual(values={\"Baseline\": \"#c0c0c0\", \"CLADES\": \"#4daf4a\"})\n",
    "    + scale_x_discrete(expand=(0.08, 0.01))\n",
    "    + labs(x=\"Cell Category\", y=\"Mean œÅ(Œîœà)\", title=\"Mean œÅ by Category\", fill=None)\n",
    "    + theme_bw()\n",
    "    + theme(panel_background = element_rect(fill=\"white\"))\n",
    "    + theme(\n",
    "        figure_size=(4, 4),\n",
    "             legend_position=(0.45, 0.97),       # top-right corner\n",
    "            legend_justification=(1, 1),\n",
    "                legend_background=element_blank(),\n",
    "                legend_title=element_blank(),\n",
    "                legend_text=element_text(size=15),\n",
    "        axis_text_x=element_text(size=15, ha=\"center\", va=\"top\", color=\"#222222\"),\n",
    "        axis_text_y=element_text(size=15, color=\"#222222\"),\n",
    "        axis_title_x=element_text(margin={'t': 8}, size=18, weight=\"bold\"),\n",
    "        axis_title_y=element_text(size=18, weight=\"bold\"),\n",
    "        plot_title=element_text(size=18, weight=\"bold\", ha=\"center\"),\n",
    "        panel_border=element_blank(),\n",
    "        panel_grid_major_y=element_text(color=\"#dddddd\"),\n",
    "        panel_grid_minor_y=element_blank(),\n",
    "        panel_grid_major_x=element_blank(),\n",
    "        panel_grid_minor_x=element_blank(),\n",
    "        axis_line_x=element_text(color=\"black\"),\n",
    "        axis_line_y=element_text(color=\"black\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# === Step 6: Display & save ===\n",
    "p.show()\n",
    "\n",
    "out_path = f\"/gpfs/commons/home/atalukder/Contrastive_Learning/files/RECOMB_26/figures/fig_TissueWise_TS_meanSP_SOTA_vs_CLADE_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# --- Draw and save with consistent size ---\n",
    "fig = p.draw()\n",
    "\n",
    "# Force the figure to match notebook display ratio\n",
    "fig.set_size_inches(4, 4)  # same as theme figure_size\n",
    "\n",
    "formats = ['png', 'svg', 'pdf', 'eps']\n",
    "for fmt in formats:\n",
    "    save_path = f\"{out_path}.{fmt}\"\n",
    "    fig.savefig(\n",
    "    save_path,\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\"\n",
    "    )\n",
    "    print(f\"‚úÖ Saved: {save_path}\")\n",
    "\n",
    "\n",
    "plt.close(fig)\n",
    "print(\"‚úÖ Saved: fig_spearman_SOTA_vs_CLADE_consistent.png (same as notebook view)\")\n",
    "\n",
    "# p = (\n",
    "#     ggplot(summary, aes(x=\"SampleClass\", y=\"mean\", fill=\"Model\"))\n",
    "#     + geom_bar(stat=\"identity\", position=position_dodge(width=0.34), width=0.36)\n",
    "#     + geom_errorbar(\n",
    "#         aes(ymin=summary[\"mean\"] - summary[\"std\"], ymax=summary[\"mean\"] + summary[\"std\"]),\n",
    "#         width=0.06, position=position_dodge(width=0.34)\n",
    "#     )\n",
    "#     + scale_fill_manual(values={\"Baseline\": \"#c0c0c0\", \"CLADE\": \"#4daf4a\"})  # ‚úÖ updated label + color\n",
    "#     + scale_x_discrete(expand=(0.08, 0.01))\n",
    "#     + labs(x=\"Cell type class\", y=r\"Mean $\\boldsymbol{\\rho}$\", fill=None)\n",
    "#     + theme_bw()\n",
    "#     + theme(\n",
    "#         figure_size=(2.8, 3.0),\n",
    "#         legend_position=(0.05, 0.95),\n",
    "#         legend_justification=(0, 1),\n",
    "#         legend_background=element_blank(),\n",
    "#         legend_title=element_blank(),\n",
    "#         axis_text_x=element_text(size=12),\n",
    "#         axis_text_y=element_text(size=12),\n",
    "#         axis_title_x=element_text(margin={'t': 8}, size=13, weight=\"bold\"),\n",
    "#         axis_title_y=element_text(size=13, weight=\"bold\"),\n",
    "#         plot_title=element_blank()\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # === Step 6: Display & save ===\n",
    "# p.show()\n",
    "\n",
    "# main_dir = \"/gpfs/commons/home/atalukder/Contrastive_Learning/files/RECOMB_26/figures\"\n",
    "# out_path = f\"{main_dir}/fig_TS_spearman_SOTA_vs_CLADE_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# # --- Draw and save with consistent size ---\n",
    "# fig = p.draw()\n",
    "\n",
    "# # Force the figure to match notebook display ratio\n",
    "# fig.set_size_inches(2.8, 3.0)  # same as theme figure_size\n",
    "\n",
    "# formats = ['png', 'svg', 'pdf', 'eps']\n",
    "# for fmt in formats:\n",
    "#     save_path = f\"{out_path}.{fmt}\"\n",
    "#     fig.savefig(\n",
    "#     save_path,\n",
    "#     dpi=300,\n",
    "#     bbox_inches=\"tight\",\n",
    "#     facecolor=\"white\"\n",
    "#     )\n",
    "#     print(f\"‚úÖ Saved: {save_path}\")\n",
    "\n",
    "\n",
    "# print(\"‚úÖ Saved: fig_spearman_Baseline_vs_CLADE_consistent.png (same as notebook view)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_run_1_results['spearman_rho_psi'] or ['spearman_rho_delta_psi']\n",
    "spearman_df = single_run_2_results[\"spearman_rho_delta_psi\"]  # or \"spearman_rho_delta_psi\"\n",
    "# Columns: [\"tissue\", \"spearman_rho_psi\"]\n",
    "\n",
    "\n",
    "# === Step 3: Merge on tissue name ===\n",
    "merged = pd.merge(spearman_df, tissue_class_df, on=\"tissue\", how=\"inner\")\n",
    "\n",
    "# === Step 4: Compute mean Spearman per class ===\n",
    "summary = (\n",
    "    merged.groupby(\"SampleClass\")[spearman_df.columns[-1]]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\", \"median\"])\n",
    "    .reset_index()\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä {spearman_df.columns[-1]} Summary by Sample Class:\\n\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# === Optional: save to CSV ===\n",
    "summary.to_csv(f\"{spearman_df.columns[-1]}_summary_by_class.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ 2 user inputs ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dccb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Prepare the data SINGLE RUN 1 vs SINGLE RUN 2\n",
    "\n",
    "title_single = f\"{model1_user_name}_vs_{model2_user_name}vs_{model3_user_name}\"\n",
    "metric_psi = 'spearman_rho_psi'\n",
    "metric_delta = 'spearman_rho_delta_psi'\n",
    "\n",
    "import time\n",
    "trimester = time.strftime(\"_%Y_%m_%d__%H_%M_%S\")\n",
    "fig_maindir = get_figures_path()\n",
    "\n",
    "comp_df_1, melt_df_1 = prepare_grouped_plot_data(\n",
    "    df1=single_run_1_results,\n",
    "    df2=single_run_2_results,\n",
    "    df3=single_run_3_results,\n",
    "    metric=metric_psi,\n",
    "    model1_name=model1_user_name,\n",
    "    model2_name=model2_user_name,\n",
    "    model3_name=model3_user_name\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plot_grouped_comparison(\n",
    "    comp_df_1, melt_df_1,\n",
    "    title=f'{metric_psi}: {title_single}',\n",
    "    model1_name=model1_user_name,\n",
    "    model2_name=model2_user_name,\n",
    "    model3_name=model3_user_name,\n",
    "    save_path=f\"{fig_maindir}/spearman_rho_psi_{title_single}{trimester}.png\"\n",
    ")\n",
    "\n",
    "# Prepare the data\n",
    "comp_df_1, melt_df_1 = prepare_grouped_plot_data(\n",
    "    df1=single_run_1_results,\n",
    "    df2=single_run_2_results,\n",
    "    df3=single_run_3_results,\n",
    "    metric=metric_delta,\n",
    "    model1_name=model1_user_name,\n",
    "    model2_name=model2_user_name,\n",
    "    model3_name=model3_user_name\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plot_grouped_comparison(\n",
    "    comp_df_1, melt_df_1,\n",
    "    title=f'{metric_delta}: {title_single}',\n",
    "    model1_name=model1_user_name,\n",
    "    model2_name=model2_user_name,\n",
    "    model3_name=model3_user_name,\n",
    "    save_path=f\"{fig_maindir}/spearman_rho_delta_psi_{title_single}{trimester}.png\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Plotting Average Spearman Correlations Across All Tissues ---\")\n",
    "\n",
    "avg_psi = plot_average_across_tissues_2models(\n",
    "   single_run_1_results, single_run_2_results, single_run_3_results,\n",
    "model1_user_name, model2_user_name, model3_user_name,\n",
    "    metric='spearman_rho_psi',\n",
    "    save_path=f\"{fig_maindir}/avg_{metric_psi}_{title_single}{trimester}.png\"\n",
    ")\n",
    "\n",
    "avg_delta = plot_average_across_tissues_2models(\n",
    "    single_run_1_results, single_run_2_results, single_run_3_results,\n",
    "    model1_user_name, model2_user_name, model3_user_name,\n",
    "    metric='spearman_rho_delta_psi',\n",
    "    save_path=f\"{fig_maindir}/avg_{metric_delta}_{title_single}{trimester}.png\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Average Summary ---\")\n",
    "print(avg_psi)\n",
    "print(avg_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_stratified_average(\n",
    "    model_results_df,\n",
    "    imbalance_file_path,\n",
    "    metric,\n",
    "    low_lim,\n",
    "    high_lim,\n",
    "    model_name=\"Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the average of a metric for a single model,\n",
    "    stratified by the \"Up\" vs. \"Down\" imbalance categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Load Imbalance Data ---\n",
    "    try:\n",
    "        imbalance_df = pd.read_csv(imbalance_file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Imbalance file not found at {imbalance_file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 2. Define Binning Logic ---\n",
    "    def categorize_imbalance(percent_up):\n",
    "        if pd.isna(percent_up):\n",
    "            return \"N/A\"\n",
    "        # Using the bins we found worked best:\n",
    "        if percent_up < low_lim:\n",
    "            return f\"1. Slightly Down-Heavy (< {low_lim})\"\n",
    "        elif low_lim <= percent_up <= high_lim:\n",
    "            return f\"2. Highly Balanced ({low_lim} - {high_lim})\"\n",
    "        else: # percent_up > high_lim\n",
    "            return f\"3. Slightly Up-Heavy (> {high_lim})\"\n",
    "\n",
    "    imbalance_df['granular_category'] = imbalance_df['percent_up'].apply(categorize_imbalance)\n",
    "\n",
    "    # --- 3. Merge Data ---\n",
    "    imbalance_categories = imbalance_df[['tissue', 'granular_category']]\n",
    "    merged_df = model_results_df.merge(imbalance_categories, on=\"tissue\")\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        print(f\"Error: No tissues matched between results and imbalance file.\")\n",
    "        return pd.DataFrame()\n",
    "    if metric not in merged_df.columns:\n",
    "        print(f\"Error: Metric '{metric}' not found in the results DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 4. Calculate Stratified Average ---\n",
    "    stratified_avg = merged_df.groupby('granular_category')[metric].mean().reset_index()\n",
    "    stratified_avg = stratified_avg.rename(columns={metric: f'average_{metric}'})\n",
    "    stratified_avg['model'] = model_name\n",
    "    \n",
    "    return stratified_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ASSUMING YOUR DATA IS LOADED ---\n",
    "# single_run_1_results (your DataFrame with metrics)\n",
    "# model1_user_name (your model's name)\n",
    "# root_path (from your script)\n",
    "\n",
    "# --- 1. Define file paths and metric ---\n",
    "imbalance_file = f\"/gpfs/commons/home/atalukder/Contrastive_Learning/data/TS_data/tabula_sapiens/final_data/test_upDown_imbalance.csv\"\n",
    "low_lim = 0.15\n",
    "high_lim = 0.25\n",
    "metric_to_calc = 'spearman_rho_delta_psi' # or 'f1', 'auprc', etc.\n",
    "\n",
    "# --- 2. Run the function for just model 1 ---\n",
    "avg_model1_stratified = get_stratified_average(\n",
    "    model_results_df=single_run_1_results,\n",
    "    imbalance_file_path=imbalance_file,\n",
    "    metric=metric_to_calc,\n",
    "    low_lim=low_lim,\n",
    "    high_lim=high_lim,\n",
    "    model_name=model1_user_name\n",
    ")\n",
    "print(f\"Stratified {metric_to_calc} for: {model1_user_name}\")\n",
    "print(avg_model1_stratified)\n",
    "\n",
    "avg_model2_stratified = get_stratified_average(\n",
    "    model_results_df=single_run_2_results,\n",
    "    imbalance_file_path=imbalance_file,\n",
    "    metric=metric_to_calc,\n",
    "    low_lim=low_lim,\n",
    "    high_lim=high_lim,\n",
    "    model_name=model2_user_name\n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. Print the results ---\n",
    "print(f\"Stratified {metric_to_calc} for: {model2_user_name}\")\n",
    "print(avg_model2_stratified)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5246c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myjupyterenv_EAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
