{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08bd5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CONTRASTIVE_ROOT set to: /gpfs/commons/home/atalukder/Contrastive_Learning\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "# exon-specific Î”logit\n",
    "from helper import (\n",
    "    load_and_align_for_delta_logit, pull_vectors_from_row,\n",
    "    delta_logit_scores, curve_score_from_dlogit, hard_preds_from_dlogit,\n",
    "    binary_metrics, find_contrastive_root, get_prediction_file,pull_pm1_vectors_from_row,\n",
    "    pull_pm1_vectors_from_row_predfilter,pull_vectors_from_row_predFilter,\n",
    ")\n",
    "import time\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# --- Detect and set CONTRASTIVE_ROOT environment variable ---\n",
    "root_path = str(find_contrastive_root())\n",
    "os.environ[\"CONTRASTIVE_ROOT\"] = root_path\n",
    "print(f\"âœ… CONTRASTIVE_ROOT set to: {root_path}\")\n",
    "\n",
    "# --- Root Paths ---\n",
    "ROOT_RESULTS = f\"{root_path}/files/results\"\n",
    "DATA_BASE = f\"{root_path}/data/ASCOT\"\n",
    "\n",
    "# --- Ground Truth Binary Files ---\n",
    "GT_HIGH = f\"{DATA_BASE}/variable_cassette_exons_with_binary_labels_HIGH_TissueBinPsi.csv\"\n",
    "GT_LOW  = f\"{DATA_BASE}/variable_cassette_exons_with_binary_labels_LOW_TissueBinPsi.csv\"\n",
    "\n",
    "# --- Output directory ---\n",
    "OUT_DIR = f\"{ROOT_RESULTS}/../classification_eval\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986459a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_metrics_per_exon_logitdelta(\n",
    "    gt_file: str,\n",
    "    pred_file: str,\n",
    "    model_name: str,\n",
    "    expression_type: str,  # \"HIGH\" or \"LOW\"\n",
    "    pred_filter: bool = True,\n",
    "):\n",
    "    merged, tissue_cols = load_and_align_for_delta_logit(\n",
    "        gt_file=gt_file,\n",
    "        pred_file=pred_file,\n",
    "        require_cols=[\"logit_mean_psi\"]\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for _, row in merged.iterrows():\n",
    "        # 0/1 GT over tissues for this exon; PSI over tissues\n",
    "        if pred_filter:\n",
    "            y_true, y_psi = pull_vectors_from_row_predFilter(row, tissue_cols, expression_type)\n",
    "        else:   \n",
    "            y_true, y_psi = pull_vectors_from_row(row, tissue_cols)\n",
    "        if y_true.size == 0 or np.unique(y_true).size < 2:\n",
    "            continue\n",
    "\n",
    "        # Î”logit per tissue relative to this exonâ€™s baseline\n",
    "        muL = float(row[\"logit_mean_psi\"])\n",
    "        dlogit = delta_logit_scores(y_psi, muL)\n",
    "\n",
    "        # Scores & hard predictions\n",
    "        score_for_curve = curve_score_from_dlogit(dlogit, expression_type)\n",
    "        y_pred = hard_preds_from_dlogit(dlogit, expression_type)\n",
    "\n",
    "        m = binary_metrics(y_true, y_pred, score_for_curve)\n",
    "        m.update({\n",
    "            \"model\": model_name,\n",
    "            \"expression_type\": expression_type,\n",
    "            \"exon_id\": row[\"exon_id\"],\n",
    "        })\n",
    "        results.append(m)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        return df, f\"âš ï¸ No valid exons found for {model_name} ({expression_type})\\n\"\n",
    "\n",
    "    mean_metrics = df[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"auroc\",\"auprc\"]].mean().round(4)\n",
    "    summary_text = (\n",
    "        f\"\\nðŸ“Š {model_name} ({expression_type} exons)\\n\"\n",
    "        f\"   n_exons   : {len(df)}\\n\" +\n",
    "        \"\\n\".join([f\"   {k:<10}: {v:.4f}\" for k,v in mean_metrics.items()]) + \"\\n\"\n",
    "    )\n",
    "    # Print only the averages you care about\n",
    "    avg_auprc = df[\"auprc\"].mean(skipna=True)\n",
    "    avg_auroc = df[\"auroc\"].mean(skipna=True)\n",
    "    print(f\"ðŸ“ˆ {model_name} [{expression_type}] â€” mean AUPRC = {avg_auprc:.4f}, mean AUROC = {avg_auroc:.4f}\")\n",
    "\n",
    "    return df, summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a9b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tissue_binary_pm1_logitdelta_per_tissue_exonloop(\n",
    "    gt_file: str,            # wide GT with {-1,0,+1} and 'logit_mean_psi'\n",
    "    pred_file: str,          # predictions (PSI; % OK)\n",
    "    model_name: str = \"\",\n",
    "    filter_pred: bool = False,\n",
    "    tissue_subset: list | None = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Binary tissue-specific evaluation:\n",
    "      - Uses GT âˆˆ {-1,0,+1}; drops 0 and NaN; maps (-1 -> 0, +1 -> 1)\n",
    "      - Score = Î”logit = logit(PSI_pred) âˆ’ logit(mean_psi)\n",
    "      - Hard label at 0: (Î”logit > 0) â†’ 1\n",
    "      - Aggregates per tissue across all exons in one exon-wise pass\n",
    "    \"\"\"\n",
    "    merged, tissue_cols = load_and_align_for_delta_logit(\n",
    "        gt_file=gt_file,\n",
    "        pred_file=pred_file,\n",
    "        require_cols=[\"logit_mean_psi\"]\n",
    "    )\n",
    "    if tissue_subset is not None:\n",
    "        tissue_cols = [t for t in tissue_cols if t in tissue_subset]\n",
    "\n",
    "    # per-tissue accumulators\n",
    "    acc = {t: {\"y_true\": [], \"y_score\": [], \"y_pred\": []} for t in tissue_cols}\n",
    "    \n",
    "    valid_exon = 0\n",
    "    valid_sample = 0\n",
    "    x = 0\n",
    "    for _, row in merged.iterrows():\n",
    "        # pull vectors for this exon (drop 0/NA, map -1/+1 -> 0/1)\n",
    "        if not filter_pred:\n",
    "            y_true_bin, y_psi, valid_mask = pull_pm1_vectors_from_row(row, tissue_cols)\n",
    "        else:\n",
    "            y_true_bin, y_psi, valid_mask = pull_pm1_vectors_from_row_predfilter(row, tissue_cols)\n",
    "        if y_true_bin.size == 0:\n",
    "            continue\n",
    "        \n",
    "        valid_exon+=1\n",
    "        valid_sample += len(valid_mask)\n",
    "        # per-position Î”logit relative to this exonâ€™s baseline\n",
    "        muL = float(row[\"logit_mean_psi\"])\n",
    "        dlogit = delta_logit_scores(y_psi, muL)  # higher â‡’ more +1\n",
    "\n",
    "        # hard preds at Î”logit=0\n",
    "        y_pred = (dlogit > 0).astype(int)\n",
    "\n",
    "        # scatter back to tissues using the maskâ€™s positions\n",
    "        pos = 0\n",
    "        for j, t in enumerate(tissue_cols):\n",
    "            if valid_mask[j]:\n",
    "                acc[t][\"y_true\"].append(int(y_true_bin[pos]))\n",
    "                acc[t][\"y_score\"].append(float(dlogit[pos]))\n",
    "                acc[t][\"y_pred\"].append(int(y_pred[pos]))\n",
    "                pos += 1\n",
    "                x += 1\n",
    "\n",
    "    # compute metrics per tissue\n",
    "    rows = []\n",
    "    y = 0\n",
    "    for t in tissue_cols:\n",
    "        yt = np.asarray(acc[t][\"y_true\"], dtype=int)\n",
    "        ys = np.asarray(acc[t][\"y_score\"], dtype=float)\n",
    "        yp = np.asarray(acc[t][\"y_pred\"], dtype=int)\n",
    "        if yt.size == 0 or np.unique(yt).size < 2 or not np.isfinite(ys).all():\n",
    "            rows.append({\"tissue\": t, \"model\": model_name, \"n\": int(yt.size),\n",
    "                         \"accuracy\": np.nan, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan,\n",
    "                         \"auroc\": np.nan, \"auprc\": np.nan})\n",
    "            continue\n",
    "        m = binary_metrics(yt, yp, ys)\n",
    "        y+= yt.size\n",
    "        m.update({\"tissue\": t, \"model\": model_name, \"n\": int(yt.size)})\n",
    "        rows.append(m)\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values([\"tissue\",\"model\"]).reset_index(drop=True)\n",
    "\n",
    "def extract_valid_vectors(row, tissue_cols, gt_suffix=\"_gt\", pred_suffix=\"_pred\"):\n",
    "    \"\"\"Return (gt, pred, valid_mask) arrays for a merged exon row.\"\"\"\n",
    "    g = pd.to_numeric(row[[f\"{t}{gt_suffix}\" for t in tissue_cols]], errors=\"coerce\").to_numpy(float)\n",
    "    p = pd.to_numeric(row[[f\"{t}{pred_suffix}\" for t in tissue_cols]], errors=\"coerce\").to_numpy(float)\n",
    "    valid = np.isfinite(g) & np.isfinite(p)\n",
    "    return g, p, valid\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def safe_auc_prc(y_true_bin, score):\n",
    "    try:\n",
    "        return (\n",
    "            roc_auc_score(y_true_bin, score),\n",
    "            average_precision_score(y_true_bin, score)\n",
    "        )\n",
    "    except ValueError:\n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "def evaluate_tissue_triclass_margin_per_tissue_exonloop(\n",
    "    gt_file: str,\n",
    "    pred_file: str,\n",
    "    model_name: str = \"\",\n",
    "    tissue_subset: list | None = None,\n",
    "    margin_psi: float = 0.10,\n",
    "    psi_bar_col: str = \"mean_psi\",\n",
    "    use_logit_thresholds: bool = False,\n",
    "    eps: float = 1e-6\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Three-class tissue-specific evaluation aligned to GT rule:\n",
    "      Class +1: psi_pred > psi_bar + m\n",
    "      Class  0: psi_pred < psi_bar - m\n",
    "      Class -1: |psi_pred - psi_bar| <= m\n",
    "\n",
    "    If use_logit_thresholds = True, thresholds are applied in Î”logit-space\n",
    "    using equivalent tau_pos / tau_neg derived from the Â±margin_psi band.\n",
    "\n",
    "    Metrics per tissue:\n",
    "      accuracy, macro-F1, weighted-F1, AUROC(-1), AUPRC(-1)\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "    )\n",
    "\n",
    "    # helper functions reused\n",
    "    def sigmoid(z): return 1.0 / (1.0 + np.exp(-z))\n",
    "    def logit(p):   return np.log(p) - np.log1p(-p)\n",
    "\n",
    "    # --- load data ---\n",
    "    merged, tissue_cols = load_and_align_for_delta_logit(\n",
    "        gt_file=gt_file,\n",
    "        pred_file=pred_file,\n",
    "        require_cols=[\"logit_mean_psi\"]\n",
    "    )\n",
    "    if psi_bar_col not in merged.columns:\n",
    "        merged[psi_bar_col] = sigmoid(merged[\"logit_mean_psi\"].astype(float))\n",
    "    if tissue_subset is not None:\n",
    "        tissue_cols = [t for t in tissue_cols if t in tissue_subset]\n",
    "\n",
    "    acc = {t: {\"y_true\": [], \"y_pred\": [], \"score\": []} for t in tissue_cols}\n",
    "\n",
    "    total_valid = 0\n",
    "    x = 0\n",
    "    total = 0\n",
    "    # --- iterate over exons ---\n",
    "    for _, row in merged.iterrows():\n",
    "        g, p, valid = extract_valid_vectors(row, tissue_cols)\n",
    "        total_valid += valid.sum()\n",
    "    # print(\"Total valid tissueâ€“exon pairs:\", total_valid)\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "\n",
    "        psi_bar = float(row[psi_bar_col])\n",
    "        psi_bar_clip = np.clip(psi_bar, eps, 1 - eps)\n",
    "        muL = float(row[\"logit_mean_psi\"])\n",
    "\n",
    "        if use_logit_thresholds:\n",
    "            # convert PSI thresholds to Î”logit thresholds\n",
    "            psi_hi = np.clip(psi_bar + margin_psi, eps, 1 - eps)\n",
    "            psi_lo = np.clip(psi_bar - margin_psi, eps, 1 - eps)\n",
    "            tau_pos = logit(psi_hi) - muL\n",
    "            tau_neg = logit(psi_lo) - muL\n",
    "            dlogit = delta_logit_scores(p[valid], muL)\n",
    "            x += len(dlogit)\n",
    "            y_pred = np.where(\n",
    "                dlogit > tau_pos,  1,\n",
    "                np.where(dlogit < tau_neg, 0, -1)\n",
    "            )\n",
    "            score = -np.abs(dlogit)  # smaller magnitude â‡’ more â€œwithin-rangeâ€\n",
    "    \n",
    "        else:\n",
    "            pv = p[valid]\n",
    "            y_pred = np.where(\n",
    "                pv > psi_bar + margin_psi,  1,\n",
    "                np.where(pv < psi_bar - margin_psi, 0, -1)\n",
    "            )\n",
    "            score = -np.abs(pv - psi_bar)  # inverse distance from mean\n",
    "\n",
    "        # --- scatter to tissues ---\n",
    "        \n",
    "        pos = 0\n",
    "        for j, t in enumerate(tissue_cols):\n",
    "            if valid[j]:\n",
    "                acc[t][\"y_true\"].append(int(g[j]))\n",
    "                acc[t][\"y_pred\"].append(int(y_pred[pos]))\n",
    "                acc[t][\"score\"].append(float(score[pos]))\n",
    "                pos += 1\n",
    "                total += 1\n",
    "\n",
    "    # --- compute metrics per tissue ---\n",
    "    rows = []\n",
    "    y_total = 0\n",
    "    y_invalid = 0\n",
    "    y_total2 = 0\n",
    "    for t in tissue_cols:\n",
    "        yt = np.asarray(acc[t][\"y_true\"], dtype=int)\n",
    "        yp = np.asarray(acc[t][\"y_pred\"], dtype=int)\n",
    "        sc = np.asarray(acc[t][\"score\"], dtype=float)\n",
    "        y_total += yt.size\n",
    "        if yt.size == 0 or np.unique(yt).size < 2:\n",
    "            y_invalid += yt.size\n",
    "            print(f\"âš ï¸ Tissue {t} has no valid samples or only one class; skipping metrics.\")\n",
    "            rows.append({\n",
    "                \"tissue\": t, \"model\": model_name, \"n\": int(yt.size),\n",
    "                \"accuracy\": np.nan, \"macro_f1\": np.nan, \"weighted_f1\": np.nan,\n",
    "                \"auroc_within(-1)\": np.nan, \"auprc_within(-1)\": np.nan\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # --- AUROC & AUPRC for class -1 ---\n",
    "        # ---- 1 vs -1 ----\n",
    "        mask_1 = np.isin(yt, [1, -1])\n",
    "        if np.any(mask_1):\n",
    "            y1_bin = (yt[mask_1] == 1).astype(int)\n",
    "            s1 = sc[mask_1]\n",
    "            auroc_1vsm1, auprc_1vsm1 = safe_auc_prc(y1_bin, s1)\n",
    "        else:\n",
    "            auroc_1vsm1, auprc_1vsm1 = np.nan, np.nan\n",
    "\n",
    "        # ---- 0 vs -1 ----\n",
    "        mask_0 = np.isin(yt, [0, -1])\n",
    "        if np.any(mask_0):\n",
    "            y0_bin = (yt[mask_0] == 0).astype(int)\n",
    "            s0 = sc[mask_0]\n",
    "            auroc_0vsm1, auprc_0vsm1 = safe_auc_prc(y0_bin, s0)\n",
    "        else:\n",
    "            auroc_0vsm1, auprc_0vsm1 = np.nan, np.nan\n",
    "        \n",
    "        # print(f\"Tissue {t}: sample_size={yt.size}\")\n",
    "        y_total2 += yt.size\n",
    "        rows.append({\n",
    "        \"tissue\": t,\n",
    "        \"model\": model_name,\n",
    "        \"n\": int(yt.size),\n",
    "        \"accuracy\": accuracy_score(yt, yp),\n",
    "        \"macro_f1\": f1_score(yt, yp, average=\"macro\"),\n",
    "        \"weighted_f1\": f1_score(yt, yp, average=\"weighted\"),\n",
    "        \"auroc_1_vs_-1\": auroc_1vsm1,\n",
    "        \"auprc_1_vs_-1\": auprc_1vsm1,\n",
    "        \"auroc_0_vs_-1\": auroc_0vsm1,\n",
    "        \"auprc_0_vs_-1\": auprc_0vsm1\n",
    "})\n",
    "\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values([\"tissue\", \"model\"]).reset_index(drop=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27c85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exonSpecific_classification(result_file_name, model_user_name_norun):\n",
    "    pred_file = get_prediction_file(ROOT_RESULTS, result_file_name)\n",
    "    print(f\"ðŸ“‚ Found predictions for {model_user_name_norun} â†’ {pred_file}\")\n",
    "\n",
    "    df_high, txt_high = compute_classification_metrics_per_exon_logitdelta(\n",
    "        GT_HIGH, pred_file, model_user_name_norun, \"HIGH\"\n",
    "    )\n",
    "    df_low,  txt_low  = compute_classification_metrics_per_exon_logitdelta(\n",
    "        GT_LOW,  pred_file, model_user_name_norun, \"LOW\"\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([df_high, df_low], ignore_index=True)\n",
    "    out_csv = f\"{OUT_DIR}/{model_user_name_norun}_classification_metrics_logitdelta_{timestamp}.csv\"\n",
    "    combined.to_csv(out_csv, index=False)\n",
    "    print(f\"âœ… Saved classification metrics â†’ {out_csv}\")\n",
    "    return combined, txt_high + txt_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e92dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Paths you likely already have ---\n",
    "GT_CLASS3_WIDE = f\"{DATA_BASE}/variable_cassette_exons_with_binary_labels_ExonBinPsi.csv\"  # {-1,0,+1} wide\n",
    "\n",
    "def evaluate_tissueSpecific_classification(result_file_name: str, model_user_name_norun: str, filter_pred: bool = False):\n",
    "    \"\"\"\n",
    "    Tissue-specific classification evaluation.\n",
    "    1ï¸âƒ£ Binary: GT {-1,+1} only (drops 0/NA) via Î”logit threshold at 0.\n",
    "    2ï¸âƒ£ Tri-class: GT {-1,0,+1} using Â±margin_psi rule (Î”logit or PSI thresholds).\n",
    "\n",
    "    Both produce per-tissue CSVs and print summary stats.\n",
    "    Returns (combined_df, summary_text)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1ï¸âƒ£ Locate prediction file\n",
    "    pred_file = get_prediction_file(ROOT_RESULTS, result_file_name)\n",
    "    print(f\"ðŸ“‚ Found predictions for {model_user_name_norun} â†’ {pred_file}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 2ï¸âƒ£ Run Binary tissue-specific evaluation\n",
    "    per_tissue_bin = evaluate_tissue_binary_pm1_logitdelta_per_tissue_exonloop(\n",
    "        gt_file=GT_CLASS3_WIDE,\n",
    "        pred_file=pred_file,\n",
    "        model_name=model_user_name_norun,\n",
    "        tissue_subset=None,\n",
    "        filter_pred=filter_pred\n",
    "    )\n",
    "\n",
    "    out_bin_csv = f\"{OUT_DIR}/{model_user_name_norun}_tissue_metrics_logitdelta_binary_{timestamp}.csv\"\n",
    "    per_tissue_bin.to_csv(out_bin_csv, index=False)\n",
    "    print(f\"âœ… Saved binary tissue metrics â†’ {out_bin_csv}\")\n",
    "\n",
    "    # --- Binary summary\n",
    "    n_tissues = per_tissue_bin[\"tissue\"].nunique()\n",
    "    macro_bin = per_tissue_bin[[\"accuracy\",\"precision\",\"recall\",\"f1\",\"auprc\", \"auroc\"]].mean(skipna=True).round(4)\n",
    "    summary_bin = (\n",
    "        f\"\\nðŸ§ª {model_user_name_norun} (Binary)\\n\"\n",
    "        f\"   n_tissues : {n_tissues}\\n\" +\n",
    "        \"\\n\".join([f\"   {k:<10}: {v:.4f}\" for k,v in macro_bin.items()]) + \"\\n\"\n",
    "    )\n",
    "    print(summary_bin)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 3ï¸âƒ£ Run Tri-class tissue-specific evaluation\n",
    "    per_tissue_tri = evaluate_tissue_triclass_margin_per_tissue_exonloop(\n",
    "    gt_file=GT_CLASS3_WIDE,\n",
    "    pred_file=pred_file,\n",
    "    model_name=model_user_name_norun,\n",
    "    tissue_subset=None,          # restrict to certain tissues if needed\n",
    "    margin_psi=0.10,             # matches GT Â±0.1 rule\n",
    "    use_logit_thresholds=True    # set False to use PSI space thresholds\n",
    ")\n",
    "\n",
    "    out_tri_csv = f\"{OUT_DIR}/{model_user_name_norun}_tissue_metrics_triclass_{timestamp}.csv\"\n",
    "    per_tissue_tri.to_csv(out_tri_csv, index=False)\n",
    "    print(f\"âœ… Saved tri-class tissue metrics â†’ {out_tri_csv}\")\n",
    "\n",
    "    # --- Tri-class summary ---\n",
    "    n_tissues_tri = per_tissue_tri[\"tissue\"].nunique()\n",
    "    macro_tri = per_tissue_tri[\n",
    "        [\"accuracy\", \"macro_f1\", \"weighted_f1\",\n",
    "        \"auroc_1_vs_-1\", \"auprc_1_vs_-1\",\n",
    "        \"auroc_0_vs_-1\", \"auprc_0_vs_-1\"]\n",
    "    ].mean(skipna=True).round(4)\n",
    "\n",
    "    summary_tri = (\n",
    "        f\"\\nðŸ§¬ {model_user_name_norun} (Tri-class)\\n\"\n",
    "        f\"   n_tissues : {n_tissues_tri}\\n\"\n",
    "        f\"   accuracy    : {macro_tri['accuracy']:.4f}\\n\"\n",
    "        f\"   macro_f1    : {macro_tri['macro_f1']:.4f}\\n\"\n",
    "        f\"   weighted_f1 : {macro_tri['weighted_f1']:.4f}\\n\"\n",
    "        f\"   auprc(1vs-1): {macro_tri['auprc_1_vs_-1']:.4f}\\n\"\n",
    "        f\"   auroc(1vs-1): {macro_tri['auroc_1_vs_-1']:.4f}\\n\"\n",
    "         f\"   auprc(0vs-1): {macro_tri['auprc_0_vs_-1']:.4f}\\n\"\n",
    "        f\"   auroc(0vs-1): {macro_tri['auroc_0_vs_-1']:.4f}\\n\"\n",
    "    )\n",
    "    print(summary_tri)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 4ï¸âƒ£ Combined summary\n",
    "    print(f\"ðŸ“Š {model_user_name_norun}: \"\n",
    "        f\"Binary F1={macro_bin['f1']:.4f}, \"\n",
    "        f\"Tri-class macroF1={macro_tri['macro_f1']:.4f}\")\n",
    "\n",
    "    combined_summary = summary_bin + \"\\n\" + summary_tri\n",
    "\n",
    "\n",
    "    # For backward compatibility with your existing code\n",
    "    combined_df = pd.concat([\n",
    "        per_tissue_bin.assign(eval_type=\"binary\"),\n",
    "        per_tissue_tri.assign(eval_type=\"triclass\")\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    return combined_df, combined_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8308292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_summary(results_df, metric=\"auprc\", out_name=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(\n",
    "        data=results_df,\n",
    "        x=\"expression_type\",\n",
    "        y=metric,\n",
    "        hue=\"model\",\n",
    "        showfliers=False\n",
    "    )\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.title(f\"Per-exon {metric.upper()} distribution across models (HIGH/LOW exons)\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    if out_name:\n",
    "        out_path = f\"{OUT_DIR}/{out_name}.png\"\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"ðŸ“Š Saved figure â†’ {out_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f7d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Using SOTA file â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/mtsplice_originalTFweight_results/intron_300bp_results/variable_all_tissues_predicted_psi.tsv\n"
     ]
    }
   ],
   "source": [
    "time_stamp = time.strftime(\"%Y_%m_%d__%H_%M_%S\", time.localtime())\n",
    "SUMMARY_TXT = f\"{OUT_DIR}/ExonSpecific_classification_summary_{time_stamp}.txt\"\n",
    "summary_lines = [\"===== MODEL CLASSIFICATION SUMMARY =====\"]\n",
    "\n",
    "# --- Model 1 ---\n",
    "result_file_name1 = \"exprmnt_2025_11_07__00_21_05\" # EMPRAIPsi_ASCOT_IntronONLY_NoCL_200bp_3p5pCut_2025_11_07__00_21_05\n",
    "model1_user_name_norun =  'IntronONLY_NoCL_200bp_3p5pCut'\n",
    "\n",
    "# --- Model 2 ---\n",
    "result_file_name2 =  \"exprmnt_2025_11_07__00_20_33\" # EMPRAIPsi_ASCOT_IntronONLY_NoCL_300bp_3p5pCut_2025_11_07__00_20_33\n",
    "model2_user_name_norun = 'IntronONLY_NoCL_300bp_3p5pCut'\n",
    "\n",
    "# --- SOTA ---\n",
    "sota_result_dir = \"mtsplice_originalTFweight_results/intron_300bp_results\"\n",
    "sota_model_name_norun = \"MTSplice_original_SOTA\"\n",
    "sota_pred_file = f\"{ROOT_RESULTS}/{sota_result_dir}/variable_all_tissues_predicted_psi.tsv\"\n",
    "print(f\"ðŸ“‚ Using SOTA file â†’ {sota_pred_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e896263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Found predictions for IntronONLY_NoCL_200bp_3p5pCut â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/exprmnt_2025_11_07__00_21_05/ensemble_evaluation_from_valdiation/test_set_evaluation/tsplice_final_predictions_all_tissues.tsv\n",
      "âœ… Saved binary tissue metrics â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/IntronONLY_NoCL_200bp_3p5pCut_tissue_metrics_logitdelta_binary_20251113-004409.csv\n",
      "\n",
      "ðŸ§ª IntronONLY_NoCL_200bp_3p5pCut (Binary)\n",
      "   n_tissues : 56\n",
      "   accuracy  : 0.5664\n",
      "   precision : 0.6462\n",
      "   recall    : 0.6869\n",
      "   f1        : 0.5653\n",
      "   auprc     : 0.6391\n",
      "   auroc     : 0.6066\n",
      "\n",
      "âœ… Saved tri-class tissue metrics â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/IntronONLY_NoCL_200bp_3p5pCut_tissue_metrics_triclass_20251113-004409.csv\n",
      "\n",
      "ðŸ§¬ IntronONLY_NoCL_200bp_3p5pCut (Tri-class)\n",
      "   n_tissues : 56\n",
      "   accuracy    : 0.7759\n",
      "   macro_f1    : 0.3238\n",
      "   weighted_f1 : 0.7122\n",
      "   auprc(1vs-1): 0.1396\n",
      "   auroc(1vs-1): 0.4975\n",
      "   auprc(0vs-1): 0.1171\n",
      "   auroc(0vs-1): 0.5042\n",
      "\n",
      "ðŸ“Š IntronONLY_NoCL_200bp_3p5pCut: Binary F1=0.5653, Tri-class macroF1=0.3238\n",
      "ðŸ“‚ Found predictions for IntronONLY_NoCL_300bp_3p5pCut â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/exprmnt_2025_11_07__00_20_33/ensemble_evaluation_from_valdiation/test_set_evaluation/tsplice_final_predictions_all_tissues.tsv\n",
      "âœ… Saved binary tissue metrics â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/IntronONLY_NoCL_300bp_3p5pCut_tissue_metrics_logitdelta_binary_20251113-004409.csv\n",
      "\n",
      "ðŸ§ª IntronONLY_NoCL_300bp_3p5pCut (Binary)\n",
      "   n_tissues : 56\n",
      "   accuracy  : 0.5500\n",
      "   precision : 0.6501\n",
      "   recall    : 0.6873\n",
      "   f1        : 0.5423\n",
      "   auprc     : 0.6506\n",
      "   auroc     : 0.6153\n",
      "\n",
      "âœ… Saved tri-class tissue metrics â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/IntronONLY_NoCL_300bp_3p5pCut_tissue_metrics_triclass_20251113-004409.csv\n",
      "\n",
      "ðŸ§¬ IntronONLY_NoCL_300bp_3p5pCut (Tri-class)\n",
      "   n_tissues : 56\n",
      "   accuracy    : 0.7648\n",
      "   macro_f1    : 0.3269\n",
      "   weighted_f1 : 0.7076\n",
      "   auprc(1vs-1): 0.1481\n",
      "   auroc(1vs-1): 0.4987\n",
      "   auprc(0vs-1): 0.1165\n",
      "   auroc(0vs-1): 0.5035\n",
      "\n",
      "ðŸ“Š IntronONLY_NoCL_300bp_3p5pCut: Binary F1=0.5423, Tri-class macroF1=0.3269\n",
      "MTSplice_original_SOTA  [Binary]  AUPRC=0.6999 AUROC=0.6701\n",
      "âœ… Saved binary SOTA results â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/MTSplice_original_SOTA_tissue_metrics_binary_20251113-004409.csv\n",
      "\n",
      "ðŸ§¬ MTSplice_original_SOTA (Tri-class)\n",
      "   n_tissues : 56\n",
      "   accuracy   : 0.7931\n",
      "   macro_f1   : 0.3297\n",
      "   weighted_f1: 0.7213\n",
      "   auprc(1vs-1): 0.1207\n",
      "   auroc(1vs-1): 0.4830\n",
      "   auprc(0vs-1): 0.1232\n",
      "   auroc(0vs-1): 0.5330\n",
      "\n",
      "âœ… Saved tri-class SOTA results â†’ /gpfs/commons/home/atalukder/Contrastive_Learning/files/results/../classification_eval/MTSplice_original_SOTA_tissue_metrics_triclass_20251113-004409.csv\n"
     ]
    }
   ],
   "source": [
    "# tissue specific classification evaluation\n",
    "# 1ï¸âƒ£ Binary (existing)\n",
    "\n",
    "# --- Model 1 ---\n",
    "df_model1, txt_model1 = evaluate_tissueSpecific_classification(result_file_name1, model1_user_name_norun, filter_pred=False)\n",
    "summary_lines += [txt_model1]\n",
    "\n",
    "# --- Model 2 ---'\n",
    "df_model2, txt_model2 = evaluate_tissueSpecific_classification(result_file_name2, model2_user_name_norun, filter_pred=False)\n",
    "summary_lines += [txt_model2]\n",
    "\n",
    "# # --- SOTA ---\n",
    "\n",
    "# 1ï¸âƒ£ Binary (existing)\n",
    "df_sota_bin = evaluate_tissue_binary_pm1_logitdelta_per_tissue_exonloop(\n",
    "    gt_file=GT_CLASS3_WIDE,\n",
    "    pred_file=sota_pred_file,\n",
    "    model_name=sota_model_name_norun,\n",
    "    filter_pred=False\n",
    ")\n",
    "\n",
    "auroc_bin = df_sota_bin[\"auroc\"].mean(skipna=True)\n",
    "auprc_bin = df_sota_bin[\"auprc\"].mean(skipna=True)\n",
    "print(f\"{sota_model_name_norun}  [Binary]  AUPRC={auprc_bin:.4f} AUROC={auroc_bin:.4f}\")\n",
    "\n",
    "metric_cols_bin = [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auroc\",\"auprc\"]\n",
    "macro_bin = df_sota_bin[metric_cols_bin].mean(skipna=True).round(4)\n",
    "txt_sota_bin = (\n",
    "    f\"\\nðŸ§ª {sota_model_name_norun} (Binary)\\n\"\n",
    "    f\"   n_tissues : {df_sota_bin['tissue'].nunique()}\\n\" +\n",
    "    \"\\n\".join(f\"   {k:<10}: {v:.4f}\" for k, v in macro_bin.items()) + \"\\n\"\n",
    ")\n",
    "summary_lines += [txt_sota_bin]\n",
    "\n",
    "# Optionally save\n",
    "df_sota_bin.to_csv(f\"{OUT_DIR}/{sota_model_name_norun}_tissue_metrics_binary_{timestamp}.csv\", index=False)\n",
    "print(f\"âœ… Saved binary SOTA results â†’ {OUT_DIR}/{sota_model_name_norun}_tissue_metrics_binary_{timestamp}.csv\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# 2ï¸âƒ£ Tri-class (new)\n",
    "df_sota_tri = evaluate_tissue_triclass_margin_per_tissue_exonloop(\n",
    "    gt_file=GT_CLASS3_WIDE,\n",
    "    pred_file=sota_pred_file,\n",
    "    model_name=sota_model_name_norun,\n",
    "    tissue_subset=None,\n",
    "    margin_psi=0.10,\n",
    "    use_logit_thresholds=True  # same Î”logit thresholds rule\n",
    ")\n",
    "\n",
    "# --- Compute macro means ---\n",
    "macro_tri = df_sota_tri[\n",
    "    [\"accuracy\", \"macro_f1\", \"weighted_f1\",\n",
    "     \"auroc_1_vs_-1\", \"auprc_1_vs_-1\",\n",
    "     \"auroc_0_vs_-1\", \"auprc_0_vs_-1\"]\n",
    "].mean(skipna=True).round(4)\n",
    "\n",
    "# --- Build formatted summary string ---\n",
    "txt_sota_tri = (\n",
    "    f\"\\nðŸ§¬ {sota_model_name_norun} (Tri-class)\\n\"\n",
    "    f\"   n_tissues : {df_sota_tri['tissue'].nunique()}\\n\"\n",
    "    f\"   accuracy   : {macro_tri['accuracy']:.4f}\\n\"\n",
    "    f\"   macro_f1   : {macro_tri['macro_f1']:.4f}\\n\"\n",
    "    f\"   weighted_f1: {macro_tri['weighted_f1']:.4f}\\n\"\n",
    "    f\"   auprc(1vs-1): {macro_tri['auprc_1_vs_-1']:.4f}\\n\"\n",
    "    f\"   auroc(1vs-1): {macro_tri['auroc_1_vs_-1']:.4f}\\n\"\n",
    "    f\"   auprc(0vs-1): {macro_tri['auprc_0_vs_-1']:.4f}\\n\"\n",
    "    f\"   auroc(0vs-1): {macro_tri['auroc_0_vs_-1']:.4f}\\n\"\n",
    ")\n",
    "# Append to summary list and print\n",
    "summary_lines += [txt_sota_tri]\n",
    "print(txt_sota_tri)\n",
    "\n",
    "# Save CSV\n",
    "out_tri_csv = f\"{OUT_DIR}/{sota_model_name_norun}_tissue_metrics_triclass_{timestamp}.csv\"\n",
    "df_sota_tri.to_csv(out_tri_csv, index=False)\n",
    "print(f\"âœ… Saved tri-class SOTA results â†’ {out_tri_csv}\")\n",
    "\n",
    "with open(SUMMARY_TXT, \"w\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT ERASE (AT)\n",
    "\n",
    "# # Exon specifidic classification evaluation\n",
    "\n",
    "# # --- Model 1 ---\n",
    "# df_model1, txt_model1 = evaluate_exonSpecific_classification(result_file_name1, model1_user_name_norun)\n",
    "# summary_lines += [txt_model1]\n",
    "\n",
    "# # --- Model 2 ---'\n",
    "# df_model2, txt_model2 = evaluate_exonSpecific_classification(result_file_name2, model2_user_name_norun)\n",
    "# summary_lines += [txt_model2]\n",
    "\n",
    "# # --- SOTA ---\n",
    "# df_sota_high, txt_sota_high = compute_classification_metrics_per_exon_logitdelta(GT_HIGH, sota_pred_file, sota_model_name_norun, \"HIGH\")\n",
    "# df_sota_low, txt_sota_low  = compute_classification_metrics_per_exon_logitdelta(GT_LOW,  sota_pred_file, sota_model_name_norun, \"LOW\")\n",
    "# summary_lines += [txt_sota_high, txt_sota_low]\n",
    "\n",
    "# df_sota = pd.concat([df_sota_high, df_sota_low], ignore_index=True)\n",
    "# df_sota.to_csv(f\"{OUT_DIR}/{sota_model_name_norun}_classification_metrics_{timestamp}.csv\", index=False)\n",
    "\n",
    "# # with open(SUMMARY_TXT, \"w\") as f:\n",
    "# #     f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "# combined_all = pd.concat([df_sota, df_model1, df_model2], ignore_index=True)\n",
    "# combined_all.to_csv(f\"{OUT_DIR}/combined_classification_summary_{timestamp}.csv\", index=False)\n",
    "# print(f\"âœ… Combined summary saved â†’ {OUT_DIR}/combined_classification_summary_{timestamp}.csv\")\n",
    "\n",
    "# plot_classification_summary(combined_all, metric=\"auprc\", out_name=\"AUPRC_SOTA_vs_models\")\n",
    "# plot_classification_summary(combined_all, metric=\"auroc\", out_name=\"AUROC_SOTA_vs_models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_tissue_classification_box(results_df, metric=\"auprc\", out_name=None,\n",
    "                                       model_order=None, palette=None, show_points=True):\n",
    "    \"\"\"\n",
    "    Boxplot of per-tissue metrics across models (no pre-aggregation).\n",
    "    Expects columns: ['tissue', 'model', <metric>].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Keep only finite metric values; no groupby needed\n",
    "    df = results_df.replace([np.inf, -np.inf], np.nan).dropna(subset=[metric, \"model\"])\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"model\",\n",
    "        y=metric,\n",
    "        order=model_order,\n",
    "         hue=\"model\",\n",
    "        showfliers=False\n",
    "    )\n",
    "\n",
    "    if show_points:\n",
    "        sns.stripplot(\n",
    "            data=df,\n",
    "            x=\"model\",\n",
    "            y=metric,\n",
    "            order=model_order,\n",
    "            dodge=False,\n",
    "            jitter=0.12,\n",
    "            size=3,\n",
    "            alpha=0.65,\n",
    "            color=\"k\"  # keep legend clean\n",
    "        )\n",
    "\n",
    "    if metric.lower() in {\"auprc\", \"auroc\"}:\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.title(f\"Per-tissue {metric.upper()} distribution across models\")\n",
    "    plt.xlabel(\"model\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if out_name:\n",
    "        out_path = f\"{OUT_DIR}/{out_name}.png\"\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"ðŸ“Š Saved figure â†’ {out_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6906208",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all = pd.concat([df_sota, df_model1, df_model2], ignore_index=True)\n",
    "combined_all.to_csv(f\"{OUT_DIR}/combined_tissue_classification_summary.csv\", index=False)\n",
    "print(f\"âœ… Combined summary saved â†’ {OUT_DIR}/combined_tissue_classification_summary.csv\")\n",
    "\n",
    "# Use the tissue plotter (not the exon HIGH/LOW plotter)\n",
    "# plot_tissue_classification_summary(combined_all, metric=\"auprc\", out_name=\"AUPRC_tissue_SOTA_vs_models\")\n",
    "# plot_tissue_classification_summary(combined_all, metric=\"auroc\", out_name=\"AUROC_tissue_SOTA_vs_models\")\n",
    "\n",
    "plot_tissue_classification_box(combined_all, metric=\"auprc\", out_name=\"AUPRC_tissue_box_SOTA_vs_models\")\n",
    "plot_tissue_classification_box(combined_all, metric=\"auroc\", out_name=\"AUROC_tissue_box_SOTA_vs_models\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myjupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
