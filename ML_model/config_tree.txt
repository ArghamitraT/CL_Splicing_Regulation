CONFIG
├── wandb
│   └── api_key: 6c6c3f0e63c48c1d9b78f03948c5eb5a4f828a66                                                                                                                                                         
│       dir: ./wandb/                                                                                                                                                                                             
│                                                                                                                                                                                                                 
├── logger
│   └── _target_: lightning.pytorch.loggers.WandbLogger                                                                                                                                                           
│       name: ResNet1D-199                                                                                                                                                                                        
│       id: introns_cl-ResNet1D-199                                                                                                                                                                               
│       project: INTRONS_CL                                                                                                                                                                                       
│       group: introns_cl                                                                                                                                                                                         
│       save_dir: ./wandb/                                                                                                                                                                                        
│       log_model: true                                                                                                                                                                                           
│       notes: ''                                                                                                                                                                                                 
│       settings:                                                                                                                                                                                                 
│         init_timeout: 600                                                                                                                                                                                       
│                                                                                                                                                                                                                 
├── embedder
│   └── name_or_path: InstaDeepAI/nucleotide-transformer-v2-50m-multi-species                                                                                                                                     
│       bp_per_token: 1                                                                                                                                                                                           
│       embedding_dim: 768                                                                                                                                                                                        
│       vocab_size: 11                                                                                                                                                                                            
│       rcps: false                                                                                                                                                                                               
│       maxpooling: true                                                                                                                                                                                          
│       _name_: ResNet1D                                                                                                                                                                                          
│                                                                                                                                                                                                                 
├── dataset
│   └── seq_len: 199                                                                                                                                                                                              
│       data_file: /gpfs/commons/home/atalukder/Contrastive_Learning/data/final_data/intronSeq_multizAlignment_noDash/merged_intron_sequences.pkl                                                                 
│       exon_names_path: /gpfs/commons/home/atalukder/Contrastive_Learning/data/final_data/intronSeq_multizAlignment_noDash/all_exon_names.txt                                                                    
│       batch_size_per_device: 683                                                                                                                                                                                
│       num_workers: 16                                                                                                                                                                                           
│       train_ratio: 0.8                                                                                                                                                                                          
│       val_ratio: 0.1                                                                                                                                                                                            
│       test_ratio: null                                                                                                                                                                                          
│       cache_dir: ../data                                                                                                                                                                                        
│                                                                                                                                                                                                                 
├── task
│   └── _name_: introns_cl                                                                                                                                                                                        
│       metrics:                                                                                                                                                                                                  
│       - accuracy                                                                                                                                                                                                
│       val_check_interval: 0.5                                                                                                                                                                                   
│       global_batch_size: 2048                                                                                                                                                                                   
│                                                                                                                                                                                                                 
├── trainer
│   └── _target_: lightning.pytorch.Trainer                                                                                                                                                                       
│       max_epochs: 2                                                                                                                                                                                             
│       callbacks: null                                                                                                                                                                                           
│       devices: 3                                                                                                                                                                                                
│       log_every_n_steps: 1                                                                                                                                                                                      
│       limit_train_batches: 1.0                                                                                                                                                                                  
│       limit_val_batches: 1.0                                                                                                                                                                                    
│       val_check_interval: 0.5                                                                                                                                                                                   
│       gradient_clip_val: 1.0                                                                                                                                                                                    
│       precision: 16-mixed                                                                                                                                                                                       
│       num_sanity_val_steps: 0                                                                                                                                                                                   
│       num_nodes: 1                                                                                                                                                                                              
│       accumulate_grad_batches: 1                                                                                                                                                                                
│                                                                                                                                                                                                                 
├── callbacks
│   └── model_checkpoint:                                                                                                                                                                                         
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                                                                                                   
│         dirpath: checkpoints/                                                                                                                                                                                   
│         filename: introns_cl/ResNet1D/199/best-checkpoint                                                                                                                                                       
│         save_top_k: 1                                                                                                                                                                                           
│         save_last: true                                                                                                                                                                                         
│         verbose: true                                                                                                                                                                                           
│         monitor: val_loss                                                                                                                                                                                       
│         mode: min                                                                                                                                                                                               
│       learning_rate_monitor:                                                                                                                                                                                    
│         _target_: lightning.pytorch.callbacks.LearningRateMonitor                                                                                                                                               
│         logging_interval: step                                                                                                                                                                                  
│                                                                                                                                                                                                                 
├── tokenizer
│   └── _target_: src.tokenizers.custom.CustomTokenizer                                                                                                                                                           
│       model_max_length: 201                                                                                                                                                                                     
│       padding: longest                                                                                                                                                                                          
│                                                                                                                                                                                                                 
├── loss
│   └── _target_: lightly.loss.NTXentLoss                                                                                                                                                                         
│       temperature: 0.5                                                                                                                                                                                          
│                                                                                                                                                                                                                 
├── model
│   └── name_or_path: simclr                                                                                                                                                                                      
│       hidden_dim: 512                                                                                                                                                                                           
│       projection_dim: 128                                                                                                                                                                                       
│                                                                                                                                                                                                                 
└── optimizer
    └── _target_: torch.optim.AdamW                                                                                                                                                                               
        lr: 0.01                                                                                                                                                                                                  
        weight_decay: 0.0                                                                                                                                                                                         
        betas:                                                                                                                                                                                                    
        - 0.9                                                                                                                                                                                                     
        - 0.999                                                                                                                                                                                                   
                                                                                                                                                                                                                  
